diff --git a/.gitignore b/.gitignore
index e9bbc006d3..6ced0c98e8 100644
--- a/.gitignore
+++ b/.gitignore
@@ -161,3 +161,7 @@ trace-dtrace-root.dtrace
 trace-ust-all.h
 trace-ust-all.c
 /target/arm/decode-sve.inc.c
+
+# For variable-fpu
+build*/
+.vscode/
\ No newline at end of file
diff --git a/Makefile.target b/Makefile.target
index 5e916230c4..701e1134b3 100644
--- a/Makefile.target
+++ b/Makefile.target
@@ -113,7 +113,7 @@ obj-$(CONFIG_TCG) += tcg/tcg.o tcg/tcg-op.o tcg/tcg-op-vec.o tcg/tcg-op-gvec.o
 obj-$(CONFIG_TCG) += tcg/tcg-common.o tcg/optimize.o
 obj-$(CONFIG_TCG_INTERPRETER) += tcg/tci.o
 obj-$(CONFIG_TCG_INTERPRETER) += disas/tci.o
-obj-$(CONFIG_TCG) += fpu/softfloat.o
+obj-$(CONFIG_TCG) += fpu/softfloat.o fpu/flexfloat.o fpu/axspike.o
 obj-y += target/$(TARGET_BASE_ARCH)/
 obj-y += disas.o
 obj-$(call notempty,$(TARGET_XML_FILES)) += gdbstub-xml.o
diff --git a/Python_on_QEMU.png b/Python_on_QEMU.png
new file mode 100644
index 0000000000..587e9acc06
Binary files /dev/null and b/Python_on_QEMU.png differ
diff --git a/Python_on_QEMU_result.png b/Python_on_QEMU_result.png
new file mode 100644
index 0000000000..38d46afaf1
Binary files /dev/null and b/Python_on_QEMU_result.png differ
diff --git a/README.NOUR.MD b/README.NOUR.MD
new file mode 100644
index 0000000000..f6ca083dac
--- /dev/null
+++ b/README.NOUR.MD
@@ -0,0 +1,181 @@
+# QEMU with variable-precision FPU capability
+
+## Install 
+
+Print available targets
+```
+../configure --help
+```
+
+For our case
+```bash
+cd build
+../configure --target-list=riscv64-softmmu,riscv64-linux-user
+make
+```
+
+In order to make debugging QEMU itself using GDB (on x86) possible:
+```
+../configure --target-list=riscv64-linux-user --enable-debug
+```
+
+
+## Usage
+
+### To be sourced/defined
+- First source the following
+```
+BUILDROOT_OUTPUT=/home/aitsaidn/PhD/playground/axspike/buildroot-2019.08/output
+
+QEMU_SOFTMMU=/home/aitsaidn/PhD/playground/axspike/qemu/build/riscv64-softmmu/qemu-system-riscv64
+QEMU_LINUX_USER=/home/aitsaidn/PhD/playground/axspike/qemu/build/riscv64-linux-user/qemu-riscv64
+
+GDB_LINUX=/home/aitsaidn/PhD/playground/axspike/gdb-8.3.1-riscv64-linux-gnu
+
+export RISCV="$BUILDROOT_OUTPUT/host"
+export PATH=$PATH:$RISCV/bin
+export PATH=$PATH:$GDB_LINUX/bin
+export MAKEFLAGS="$MAKEFLAGS -j`nproc`"
+```
+
+### Running a RISC-V Linux Program
+- Compiling and running
+Compile
+```bash
+riscv64-linux-gcc -ggdb -o3 -g fpu.c -o fpu
+riscv64-linux-objdump -s -S --endian=big fpu > fpu-dump.asm
+```
+
+run
+```bash 
+$QEMU_LINUX_USER -L $BUILDROOT_OUTPUT/images/rootfs -D logfile.log -d in_asm,cpu,fpu fpu
+```
+
+- Launch with GDB
+```bash
+$QEMU_LINUX_USER -g 1234 -L $BUILDROOT_OUTPUT/images/rootfs -D logfile.log -d in_asm,cpu,fpu fpu
+```     
+
+### Running a RISC-V Bare-Metal Program
+- Baremetal, for example the hello-world example from ZephyrOS
+```bash
+./qemu-system-riscv64 -nographic -machine sifive_e -net none -pidfile qemu.pid -serial mon:stdio -kernel /home/aitsaidn/PhD/playground/axspike/axspike-next/zephyr.elf
+```
+with dumps:
+```bash
+./qemu-system-riscv64 -nographic -machine sifive_e -net none -pidfile qemu.pid -serial mon:stdio -kernel /home/aitsaidn/PhD/playground/axspike/axspike-next/zephyr.elf -D logfile.log -d in_asm,cpu,fpu
+```
+
+- More about linker, qemu, virt machine ...
+https://twilco.github.io/riscv-from-scratch/2019/04/27/riscv-from-scratch-2.html
+
+- Proxy-kernel
+Programs compiled for the proxy kernel using the NewLib (libgloss) library can still work using the Linux mode. i.e. the linux mode can also play the role of the proxy kernel.
+
+## Logging Test Vectors from AXQEMU
+
+To activate instruction testVector dumps (to be used in HW testbenches), activate the `ENABLE_TEST_VECTOR` macro in `fpu_helper.c` then rebuild.
+The dump is output at the STDERR, so you will have to reorient STDERR to an external file of course.
+
+## Variable FPU QEMU development conventions
+
+**@AXSPIKE** or **@AXQEMU** : means that the note is related to AXSPIKE development process
+**@TODO**    : something should be revisited/corrected/enhanced.
+**@AXSPIKE_TEST** : lines inserted to test AXSPIKE-related functionalities.
+
+We defined **USE_AXSPIKE** flag in `softfloat.c` that will choose if we should use **softfloat** or **flexfloat**.
+
+# DELETED LEGACY STUFF
+
+## (OLD + Non functional) Logging Test Vectors from AXQEMU
+
+Test vector logging is done through the STDERR.
+
+### Logging the OPCODE
+
+To do that, you should activate it at compile time by going to the `target/riscv/translate.c` file and activate the following macro or define it as being empty (a comment for example)
+```C
+// Activate dumping Test Vectors in the STDERR
+#define LOG_TEST_VECTOR                 fprintf(stderr, "%X", (uint32_t)(ctx->opcode))
+// DeActivate dumping Test Vectors in the STDERR
+#define LOG_TEST_VECTOR                 /* fprintf(stderr, "%X", (uint32_t)(ctx->opcode)) */
+```
+
+Then add `LOG_TEST_VECTOR` wherever you want inside the `trans_*` functions. Example:
+
+```C
+static bool trans_fmadd_s(DisasContext *ctx, arg_fmadd_s *a)
+{
+    REQUIRE_FPU;
+    REQUIRE_EXT(ctx, RVF);
+    gen_set_rm(ctx, a->rm);
+    gen_helper_fmadd_s(cpu_fpr[a->rd], cpu_env, cpu_fpr[a->rs1],
+                       cpu_fpr[a->rs2], cpu_fpr[a->rs3]);
+    // @AXQEMU added for test vector logging
+    LOG_TEST_VECTOR;
+    mark_fs_dirty(ctx);
+    return true;
+}
+```
+
+### Logging the inputs + expected output [+ expected flag ?]
+
+This part is coded in the `fpu_helper.c` file
+
+```C
+#define LOG_TEST_VECTOR_3    fprintf(stderr, " %lX %lX %lX %lX %X\n", frs1, frs2, frs3, final_result, env->fp_status.float_exception_flags)
+#define LOG_TEST_VECTOR_2    fprintf(stderr, " %lX %lX 0 %lX %X\n", frs1, frs2, final_result, env->fp_status.float_exception_flags)
+#define LOG_TEST_VECTOR_1    fprintf(stderr, " %lX 0 0 %lX %X\n", frs1, final_result, env->fp_status.float_exception_flags)
+```
+
+### Putting it all together
+
+```bash
+aitsaidn@marseille:~/PhD/playground/ctest/test_vector_generator$ ./compile_linux_qemu.sh 1> /dev/null 
+# AXQEMU[ linux user mode ]: Exp_Bits_d = 11         Frac_Bits_d = 52
+#                           Exp_Bits_f = 8         Frac_Bits_f = 23
+02E7F7D3 4010000000000000 405EDD3C07EE0B0B 0 405FDD3C07EE0B0B 0
+0AE7F7D3 4010000000000000 405EDD3C07EE0B0B 0 C05DDD3C07EE0B0B 0
+12E7F7D3 4010000000000000 405EDD3C07EE0B0B 0 407EDD3C07EE0B0B 0
+72D7F7C3 4010000000000000 405EDD3C07EE0B0B 402E3EF9DB22D0E5 407FCF33D6C72192 1
+58057453 42F6E9E0 0 0 4131C71C 1
+1AE7F7D3 402E3EF9DB22D0E5 405EDD3C07EE0B0B 0 3FBF5BEAE72B2E49 1
+72D7F7CF 4010000000000000 405EDD3C07EE0B0B 402E3EF9DB22D0E5 C07FCF33D6C72192 1
+```
+
+
+# V5.0: Variable Precision in Time
+
+
+# Running Python programs within RISC-V QEMU
+
+- First Compile QEMU statically, using the following commands:
+
+```bash
+cd build
+../configure --target-list=riscv64-linux-user
+make
+```
+- Second, create a `rootfs` using Buildroot
+
+- Extract that rootfs or mount its image somewhere, for example
+```bash
+# Goto working dir
+cd /home/aitsaidn/PhD/playground/axspike/buildroot-2019.08/output/images
+mkdir try
+
+# Mount the rootfs to the folder try
+sudo mount -t ext2 -o rw,loop rootfs.ext2 try
+
+# Copy the statically linked QEMU inside the new rootfs (Because it will be excuted within that context, QEMU should be present somewhere inside that new rootfs)
+sudo cp /home/aitsaidn/PhD/playground/axspike/axspike-next/qemu-next/build-v5.0-variable-prec-in-time/riscv64-linux-user/qemu-riscv64 bin/
+
+# Chroot into the `try` folder, and execute qemu-riscv64 (the one we just copied into the new rootfs)
+
+```
+
+![alt text](Python_on_QEMU.png "Python executed inside QEMU in User Mode with a buildroot-generated rootfs")
+
+The resulting binary test vector stimuli file:
+
+![alt text](Python_on_QEMU_result.png "Python executed inside QEMU in User Mode with a buildroot-generated rootfs")
diff --git a/accel/tcg/translator.c b/accel/tcg/translator.c
index 70c66c538c..b2f76edca6 100644
--- a/accel/tcg/translator.c
+++ b/accel/tcg/translator.c
@@ -119,7 +119,9 @@ void translator_loop(const TranslatorOps *ops, DisasContextBase *db,
     if (qemu_loglevel_mask(CPU_LOG_TB_IN_ASM)
         && qemu_log_in_addr_range(db->pc_first)) {
         qemu_log_lock();
-        qemu_log("----------------\n");
+        // @AXQEMU disabling this line, in order to be able
+        // to print opcodes correctly
+        // qemu_log("----------------\n");
         ops->disas_log(db, cpu);
         qemu_log("\n");
         qemu_log_unlock();
diff --git a/configure b/configure
index 30aad233d1..6e3faa61ec 100755
--- a/configure
+++ b/configure
@@ -299,7 +299,7 @@ libs_softmmu=""
 libs_tools=""
 audio_pt_int=""
 audio_win_int=""
-libs_qga=""
+libs_qga="$SIFIVE_LIBS_QGA"
 debug_info="yes"
 stack_protector=""
 
diff --git a/fpu/axspike.c b/fpu/axspike.c
new file mode 100644
index 0000000000..ecb09e77b9
--- /dev/null
+++ b/fpu/axspike.c
@@ -0,0 +1,522 @@
+#include "qemu/osdep.h"
+
+#include "cpu.h"
+
+#include <stdio.h>
+#include <stdlib.h>
+
+#include "fpu/flexfloat.h"
+#include "fpu/axspike.h"
+#include "fpu/softfloat.h"
+
+#include <math.h> // SQRT uses the qrt function.
+
+uint8_t exp_bits_d = 11;
+uint8_t frac_bits_d = 52;
+
+uint8_t exp_bits_f = 8;
+uint8_t frac_bits_f = 23;
+
+FILE    *binary_test_vector_file = NULL;
+
+uint64_t non_approx_region_start = 0;
+uint64_t non_approx_region_size = 0;
+
+// uint8_t shift_bits = 0;
+// uint64_t input_mask  = 0xFFFFFFFFFFFFFFFF;
+// uint64_t output_mask = 0xFFFFFFFFFFFFFFFF;
+
+#define USE_CONV_COMP_CONV_METHOD 1
+// #define USE_TRUNCATION_METHOD     1
+
+// updates the fflags from fenv exceptions
+static inline void update_fflags_fenv(CPURISCVState *cpuenv)
+{
+  int ex = fetestexcept(FE_ALL_EXCEPT);
+  int flags = (!!(ex & FE_INEXACT)) |
+              (!!(ex & FE_UNDERFLOW) << 1) |
+              (!!(ex & FE_OVERFLOW)  << 2) |
+              (!!(ex & FE_DIVBYZERO) << 3) |
+              (!!(ex & FE_INVALID)   << 4);
+
+  // set_fflags(s, flags);
+  set_float_exception_flags(flags, &cpuenv->fp_status);
+}
+
+static inline void restoreFFRoundingMode(int mode)
+{
+  fesetround(mode);
+}
+
+/* We set the hardware FPU of the host to use the appropriate rounding mode,
+  depending on the RM field of the instruction */
+/*
+  when helper functions are called, the context FRM and fp_status were alredy set !! 
+  so this function here, only needs to copy the actual FRM to the Hardware FPU,
+  which will be used in the FlexFloat computation.
+*/
+static inline unsigned int setFFRoundingMode(CPURISCVState *cpuenv, unsigned int mode)
+{
+  int old = fegetround();
+  switch (mode) {
+    case 0: fesetround(FE_TONEAREST); break;
+    case 1: fesetround(FE_TOWARDZERO); break;
+    case 2: fesetround(FE_DOWNWARD); break;
+    case 3: fesetround(FE_UPWARD); break;
+    case 4: printf("Unimplemented roudning mode nearest ties to max magnitude"); exit(-1); break;
+    case 7: // DYNamic rounding case
+    {
+      switch (cpuenv->frm) { //s->fcsr.frm) {
+        case 0: fesetround(FE_TONEAREST); break;
+        case 1: fesetround(FE_TOWARDZERO); break;
+        case 2: fesetround(FE_DOWNWARD); break;
+        case 3: fesetround(FE_UPWARD); break;
+        case 4: printf("Unimplemented roudning mode nearest ties to max magnitude"); exit(-1); break;
+      }
+    }
+  }
+  return old; // Just in case.
+}
+
+// Elementaries
+static inline uint64_t lib_flexfloat_madd(CPURISCVState *cpuenv, uint64_t a, uint64_t b, uint64_t c, uint8_t e, uint8_t m, uint8_t original_length) {
+
+#if defined( USE_CONV_COMP_CONV_METHOD )
+  if( likely(original_length == 64) )
+  {
+    FF_EXEC_3_double(cpuenv, ff_fma, a, b, c, e, m)
+  }
+  else // (original_length == 32)
+  {
+    FF_EXEC_3_float(cpuenv, ff_fma, a, b, c, e, m)
+  }
+#elif defined( USE_TRUNCATION_METHOD )
+  FF_EXEC_3_shift(cpuenv, ff_fma, a, b, c, e, m, original_length)
+#else
+  fprintf(stderr, "Not implemented #else directive %d", __LINE__);
+  exit(-1);
+#endif
+
+}
+
+static inline uint64_t lib_flexfloat_msub(CPURISCVState *cpuenv, uint64_t a, uint64_t b, uint64_t c, uint8_t e, uint8_t m, uint8_t original_length) {
+
+#if defined( USE_CONV_COMP_CONV_METHOD )
+  if( likely(original_length == 64) )
+  {
+    FF_INIT_3_double(a, b, c, e, m)
+    ff_inverse(&ff_c, &ff_c);
+    feclearexcept(FE_ALL_EXCEPT);
+    ff_fma(&ff_res, &ff_a, &ff_b, &ff_c);
+    update_fflags_fenv(cpuenv);
+    double res_double = ff_get_double(&ff_res);
+    return (*(uint64_t *)( &res_double )); 
+  }
+  else // (original_length == 32)
+  {
+    FF_INIT_3_float(a, b, c, e, m)
+    ff_inverse(&ff_c, &ff_c);
+    feclearexcept(FE_ALL_EXCEPT);
+    ff_fma(&ff_res, &ff_a, &ff_b, &ff_c);
+    update_fflags_fenv(cpuenv);
+    float res_float = ff_get_float(&ff_res);
+    return (*(uint32_t *)( &res_float ));
+  }
+
+#elif defined( USE_TRUNCATION_METHOD )
+  FF_INIT_3_shift(a, b, c, e, m, original_length)
+  ff_inverse(&ff_c, &ff_c);
+  feclearexcept(FE_ALL_EXCEPT);
+  ff_fma(&ff_res, &ff_a, &ff_b, &ff_c);
+  update_fflags_fenv(cpuenv);
+  return (flexfloat_get_bits(&ff_res) << shift_bits); /* [1|   e  |  m  |  ... zeroes ...] */
+
+#else
+  fprintf(stderr, "Not implemented #else directive %d", __LINE__);
+  exit(-1);
+
+#endif
+
+}
+
+static inline uint64_t lib_flexfloat_nmsub(CPURISCVState *cpuenv, uint64_t a, uint64_t b, uint64_t c, uint8_t e, uint8_t m, uint8_t original_length) {
+
+#if defined( USE_CONV_COMP_CONV_METHOD )
+  if( likely(original_length == 64) )
+  {
+    FF_INIT_3_double(a, b, c, e, m)
+    ff_inverse(&ff_a, &ff_a);
+    feclearexcept(FE_ALL_EXCEPT);
+    ff_fma(&ff_res, &ff_a, &ff_b, &ff_c);
+    update_fflags_fenv(cpuenv);
+    double res_double = ff_get_double(&ff_res);
+    return (*(uint64_t *)( &res_double )); 
+  }
+  else // (original_length == 32)
+  {
+    FF_INIT_3_float(a, b, c, e, m)
+    ff_inverse(&ff_a, &ff_a);
+    feclearexcept(FE_ALL_EXCEPT);
+    ff_fma(&ff_res, &ff_a, &ff_b, &ff_c);
+    update_fflags_fenv(cpuenv);
+    float res_float = ff_get_float(&ff_res);
+    return (*(uint32_t *)( &res_float ));
+  }
+
+#elif defined( USE_TRUNCATION_METHOD )
+  FF_INIT_3_shift(a, b, c, e, m, original_length)
+  ff_inverse(&ff_a, &ff_a);
+  feclearexcept(FE_ALL_EXCEPT);
+  ff_fma(&ff_res, &ff_a, &ff_b, &ff_c);
+  update_fflags_fenv(cpuenv);
+  return (flexfloat_get_bits(&ff_res) << shift_bits);
+
+#else
+  fprintf(stderr, "Not implemented #else directive %d", __LINE__);
+  exit(-1);
+#endif
+
+}
+
+static inline uint64_t lib_flexfloat_nmadd(CPURISCVState *cpuenv, uint64_t a, uint64_t b, uint64_t c, uint8_t e, uint8_t m, uint8_t original_length) {
+
+#if defined( USE_CONV_COMP_CONV_METHOD )
+  if( likely(original_length == 64) )
+  {
+    FF_INIT_3_double(a, b, c, e, m)
+    feclearexcept(FE_ALL_EXCEPT);
+    ff_fma(&ff_res, &ff_a, &ff_b, &ff_c);
+    update_fflags_fenv(cpuenv);
+    ff_inverse(&ff_res, &ff_res);
+    double res_double = ff_get_double(&ff_res);
+    return (*(uint64_t *)( &res_double ));
+  }
+  else // (original_length == 32)
+  {
+    FF_INIT_3_float(a, b, c, e, m)
+    feclearexcept(FE_ALL_EXCEPT);
+    ff_fma(&ff_res, &ff_a, &ff_b, &ff_c);
+    update_fflags_fenv(cpuenv);
+    ff_inverse(&ff_res, &ff_res);
+    float res_float = ff_get_float(&ff_res);
+    return (*(uint32_t *)( &res_float ));
+  }
+
+#elif defined( USE_TRUNCATION_METHOD )
+  FF_INIT_3_shift(a, b, c, e, m, original_length)
+  feclearexcept(FE_ALL_EXCEPT);
+  ff_fma(&ff_res, &ff_a, &ff_b, &ff_c);
+  update_fflags_fenv(cpuenv);
+  ff_inverse(&ff_res, &ff_res);
+  return (flexfloat_get_bits(&ff_res) << shift_bits);
+
+#else
+  fprintf(stderr, "Not implemented #else directive %d", __LINE__);
+  exit(-1);
+#endif
+
+}
+
+static inline uint64_t lib_flexfloat_add(CPURISCVState *cpuenv, uint64_t a, uint64_t b, uint8_t e, uint8_t m, uint8_t original_length) {
+
+#if defined( USE_CONV_COMP_CONV_METHOD )
+  if( likely(original_length == 64) )
+  {
+    FF_EXEC_2_double(cpuenv, ff_add, a, b, e, m)
+  }
+  else // (original_length == 32)
+  {
+    FF_EXEC_2_float(cpuenv, ff_add, a, b, e, m)
+  }
+#elif defined( USE_TRUNCATION_METHOD )
+  FF_EXEC_2_shift(cpuenv, ff_add, a, b, e, m, original_length)
+#else
+  fprintf(stderr, "Not implemented #else directive %d", __LINE__);
+  exit(-1);
+#endif
+
+}
+
+static inline uint64_t lib_flexfloat_sub(CPURISCVState *cpuenv, uint64_t a, uint64_t b, uint8_t e, uint8_t m, uint8_t original_length) {
+
+#if defined( USE_CONV_COMP_CONV_METHOD )
+  if( likely(original_length == 64) )
+  {
+    FF_EXEC_2_double(cpuenv, ff_sub, a, b, e, m)
+  }
+  else // (original_length == 32)
+  {
+    FF_EXEC_2_float(cpuenv, ff_sub, a, b, e, m)
+  }
+#elif defined( USE_TRUNCATION_METHOD )
+  FF_EXEC_2_shift(cpuenv, ff_sub, a, b, e, m, original_length)
+#else
+  fprintf(stderr, "Not implemented #else directive %d", __LINE__);
+  exit(-1);
+#endif
+
+}
+
+static inline uint64_t lib_flexfloat_mul(CPURISCVState *cpuenv, uint64_t a, uint64_t b, uint8_t e, uint8_t m, uint8_t original_length) {
+
+#if defined( USE_CONV_COMP_CONV_METHOD )
+  if( likely(original_length == 64) )
+  {
+    FF_EXEC_2_double(cpuenv, ff_mul, a, b, e, m)
+  }
+  else // (original_length == 32)
+  {
+    FF_EXEC_2_float(cpuenv, ff_mul, a, b, e, m)
+  }
+#elif defined( USE_TRUNCATION_METHOD )
+  FF_EXEC_2_shift(cpuenv, ff_mul, a, b, e, m, original_length)
+#else
+  fprintf(stderr, "Not implemented #else directive %d", __LINE__);
+  exit(-1);
+#endif
+
+}
+
+static inline uint64_t lib_flexfloat_div(CPURISCVState *cpuenv, uint64_t a, uint64_t b, uint8_t e, uint8_t m, uint8_t original_length) {
+#if defined( USE_CONV_COMP_CONV_METHOD )
+  if( likely(original_length == 64) )
+  {
+    FF_EXEC_2_double(cpuenv, ff_div, a, b, e, m)
+  }
+  else // (original_length == 32)
+  {
+    FF_EXEC_2_float(cpuenv, ff_div, a, b, e, m)
+  }
+#elif defined( USE_TRUNCATION_METHOD )
+  FF_EXEC_2_shift(cpuenv, ff_div, a, b, e, m, original_length)
+#else
+  fprintf(stderr, "Not implemented #else directive %d", __LINE__);
+  exit(-1);
+#endif
+}
+
+// Wrapers for fpu-helper.c
+
+uint64_t QEMU_FLATTEN 
+lib_flexfloat_madd_round(uint64_t a, uint64_t b, uint64_t c, CPURISCVState *cpuenv, uint8_t e, uint8_t m, uint8_t original_length) {
+  int old = setFFRoundingMode(cpuenv, cpuenv->fp_status.float_rounding_mode);
+  uint64_t result = lib_flexfloat_madd(cpuenv, a, b, c, e, m, original_length);
+  restoreFFRoundingMode(old);
+  return result;
+}
+
+uint64_t QEMU_FLATTEN 
+lib_flexfloat_msub_round(uint64_t a, uint64_t b, uint64_t c, CPURISCVState *cpuenv, uint8_t e, uint8_t m, uint8_t original_length) {
+  int old = setFFRoundingMode(cpuenv, cpuenv->fp_status.float_rounding_mode);
+  uint64_t result = lib_flexfloat_msub(cpuenv, a, b, c, e, m, original_length);
+  restoreFFRoundingMode(old);
+  return result;
+}
+
+uint64_t QEMU_FLATTEN 
+lib_flexfloat_nmsub_round(uint64_t a, uint64_t b, uint64_t c, CPURISCVState *cpuenv, uint8_t e, uint8_t m, uint8_t original_length) {
+  int old = setFFRoundingMode(cpuenv, cpuenv->fp_status.float_rounding_mode);
+  uint64_t result = lib_flexfloat_nmsub(cpuenv, a, b, c, e, m, original_length);
+  restoreFFRoundingMode(old);
+  return result;
+}
+
+uint64_t QEMU_FLATTEN 
+lib_flexfloat_nmadd_round(uint64_t a, uint64_t b, uint64_t c, CPURISCVState *cpuenv, uint8_t e, uint8_t m, uint8_t original_length) {
+  int old = setFFRoundingMode(cpuenv, cpuenv->fp_status.float_rounding_mode);
+  uint64_t result = lib_flexfloat_nmadd(cpuenv, a, b, c, e, m, original_length);
+  restoreFFRoundingMode(old);
+  return result;
+}
+
+uint64_t QEMU_FLATTEN 
+lib_flexfloat_add_round(uint64_t a, uint64_t b, CPURISCVState *cpuenv, uint8_t e, uint8_t m, uint8_t original_length) {
+  int old = setFFRoundingMode(cpuenv, cpuenv->fp_status.float_rounding_mode);
+  uint64_t result = lib_flexfloat_add(cpuenv, a, b, e, m, original_length);
+  restoreFFRoundingMode(old);
+  return result;
+}
+
+uint64_t QEMU_FLATTEN 
+lib_flexfloat_sub_round(uint64_t a, uint64_t b, CPURISCVState *cpuenv, uint8_t e, uint8_t m, uint8_t original_length) {
+  int old = setFFRoundingMode(cpuenv, cpuenv->fp_status.float_rounding_mode);
+  uint64_t result = lib_flexfloat_sub(cpuenv, a, b, e, m, original_length);
+  restoreFFRoundingMode(old);
+  return result;
+}
+
+uint64_t QEMU_FLATTEN 
+lib_flexfloat_mul_round(uint64_t a, uint64_t b, CPURISCVState *cpuenv, uint8_t e, uint8_t m, uint8_t original_length) {
+  int old = setFFRoundingMode(cpuenv, cpuenv->fp_status.float_rounding_mode);
+  uint64_t result = lib_flexfloat_mul(cpuenv, a, b, e, m, original_length);
+  restoreFFRoundingMode(old);
+  return result;
+}
+
+uint64_t QEMU_FLATTEN 
+lib_flexfloat_div_round(uint64_t a, uint64_t b, CPURISCVState *cpuenv, uint8_t e, uint8_t m, uint8_t original_length) {
+  int old = setFFRoundingMode(cpuenv, cpuenv->fp_status.float_rounding_mode);
+  uint64_t result = lib_flexfloat_div(cpuenv, a, b, e, m, original_length);
+  restoreFFRoundingMode(old);
+  return result;
+}
+
+uint64_t QEMU_FLATTEN 
+lib_flexfloat_sqrt_round(uint64_t a, CPURISCVState *cpuenv, uint8_t e, uint8_t m, uint8_t original_length) {
+  int old = setFFRoundingMode(cpuenv, cpuenv->fp_status.float_rounding_mode);
+  /* // Original one, using get bits to get the results in LSB 1+e+m bits
+  FF_INIT_1(a, e, m, original_length) */
+
+#if defined( USE_CONV_COMP_CONV_METHOD )
+  FF_INIT_1_double(a, e, m)
+
+  feclearexcept(FE_ALL_EXCEPT);
+  ff_init_double(&ff_res, sqrt(ff_get_double(&ff_a)), env);
+  update_fflags_fenv(cpuenv);
+  restoreFFRoundingMode(old);
+
+  /* // original one using get_bits
+  return flexfloat_get_bits(&ff_res); */
+  double res_double = ff_get_double(&ff_res);
+  return (*(uint64_t *)( &res_double ));
+
+#elif defined( USE_TRUNCATION_METHOD )
+
+  FF_INIT_1_shift(a, e, m, original_length)
+
+  feclearexcept(FE_ALL_EXCEPT);
+  ff_init_double(&ff_res, sqrt(ff_get_double(&ff_a)), env);
+  update_fflags_fenv(cpuenv);
+  restoreFFRoundingMode(old);
+
+  return (flexfloat_get_bits(&ff_res) << shift_bits);
+
+#else
+  fprintf(stderr, "Not implemented #else directive %d", __LINE__);
+  exit(-1);
+#endif
+
+}
+
+// Same as lib_flexfloat_sqrt_round, but the precise value is computed using SQRTF(float) instead of SQRT(double)
+uint64_t QEMU_FLATTEN 
+lib_flexfloat_sqrtf_round(uint64_t a, CPURISCVState *cpuenv, uint8_t e, uint8_t m, uint8_t original_length) {
+  int old = setFFRoundingMode(cpuenv, cpuenv->fp_status.float_rounding_mode);
+  /* // Original one, using get bits to get the results in LSB 1+e+m bits
+  FF_INIT_1(a, e, m, original_length) */
+
+#if defined( USE_CONV_COMP_CONV_METHOD )
+
+    FF_INIT_1_float(a, e, m)
+
+  feclearexcept(FE_ALL_EXCEPT);
+  ff_init_float(&ff_res, sqrtf((float)ff_get_float(&ff_a)), env);
+  update_fflags_fenv(cpuenv);
+  restoreFFRoundingMode(old);
+
+  /* // original one using get_bits
+  return flexfloat_get_bits(&ff_res); */
+  float res_float = ff_get_float(&ff_res);
+  return (*(uint32_t *)( &res_float ));  
+
+#elif defined( USE_TRUNCATION_METHOD )
+
+  FF_INIT_1_shift(a, e, m, original_length)
+
+  feclearexcept(FE_ALL_EXCEPT);
+  ff_init_double(&ff_res, sqrtf((float)ff_get_double(&ff_a)), env);
+  update_fflags_fenv(cpuenv);
+  restoreFFRoundingMode(old);
+
+  return (flexfloat_get_bits(&ff_res) << shift_bits);
+
+#else
+  fprintf(stderr, "Not implemented #else directive %d", __LINE__);
+  exit(-1);
+#endif
+
+}
+
+
+
+
+
+
+
+
+
+// uint64_t QEMU_FLATTEN 
+// lib_flexfloat_add_round(uint64_t a, uint64_t b, CPURISCVState *cpuenv, uint8_t e, uint8_t m, uint8_t original_length) {
+//   int old = setFFRoundingMode(cpuenv, cpuenv->fp_status.float_rounding_mode);
+
+//   uint64_t aa =a, bb=b;
+//   printf("[ qemu:  a  ]   = 0x%lX\n", *(uint64_t *)( &aa ));
+//   printf("[ qemu:  b  ]   = 0x%lX\n", *(uint64_t *)( &bb ));
+
+//   // uint64_t result = lib_flexfloat_add(cpuenv, a, b, e, m, original_length);
+//   // FF_INIT_2(a, b, e, m, original_length) 
+
+//   flexfloat_t ff_a, ff_b, ff_res; 
+//   flexfloat_desc_t env = (flexfloat_desc_t) {11,51}; 
+
+//   ff_init_double(&ff_a, *(double *)(&a), env); 
+//   ff_init_double(&ff_b, *(double *)(&b), env); 
+//   ff_init_double(&ff_res, 0.0, env); 
+
+//   // ff_init(&ff_a, env); 
+//   // ff_init(&ff_b, env); 
+//   // ff_init(&ff_res, env); 
+//   // flexfloat_set_bits(&ff_a, a); 
+//   // flexfloat_set_bits(&ff_b, b);
+
+//     uint64_t reduced_a = flexfloat_get_bits(&ff_a);
+//     uint64_t reduced_b = flexfloat_get_bits(&ff_b);
+
+//   printf("[ qemu: reduced a  ]   = 0x%lX\n", *(uint64_t *)( &reduced_a ));
+//   printf("[ qemu: reduced b  ]   = 0x%lX\n", *(uint64_t *)( &reduced_b ));
+
+//   feclearexcept(FE_ALL_EXCEPT); 
+//   ff_add(&ff_res, &ff_a, &ff_b); 
+//   update_fflags_fenv(cpuenv); 
+//   // return flexfloat_get_bits(&ff_res);
+
+//   uint64_t result = flexfloat_get_bits(&ff_res);
+//   double res_d = ff_get_double(&ff_res);
+
+//   printf("[ qemu:  r  ]   = 0x%lX\n", *(uint64_t *)( &result ));
+//   printf("[ qemu:  r  ]   = 0x%lX\n", *(uint64_t *)( &res_d ));
+
+//   restoreFFRoundingMode(old);
+//   return result;
+// }
+
+// uint64_t QEMU_FLATTEN 
+// lib_flexfloat_add_round(uint64_t a, uint64_t b, CPURISCVState *cpuenv, uint8_t e, uint8_t m, uint8_t original_length) {
+//   int old = setFFRoundingMode(cpuenv, cpuenv->fp_status.float_rounding_mode);
+//   double result; // = lib_flexfloat_add(cpuenv, a, b, e, m, original_length);
+
+//   // Init
+//   uint64_t aa = a; uint64_t bb = b; 
+//   flexfloat_t ff_a, ff_b, ff_res; 
+//   flexfloat_desc_t env = (flexfloat_desc_t) {11,52}; 
+//   ff_init_double(&ff_a, *(double *)( &aa ), env); 
+//   ff_init_double(&ff_b, *(double *)( &bb ), env); 
+//   ff_init_double(&ff_res, 0.0, env);
+
+//   // Compute
+//   feclearexcept(FE_ALL_EXCEPT); 
+
+//   printf("a->exp = %d \n", ff_a.desc.exp_bits);
+//   printf("a->frac = %d \n", ff_a.desc.frac_bits);
+//   printf("b->exp = %d \n", ff_b.desc.exp_bits);
+//   printf("b->frac = %d \n", ff_b.desc.frac_bits);
+
+
+
+//   ff_add(&ff_res, &ff_a, &ff_b); 
+//   update_fflags_fenv(cpuenv); 
+//   result = ff_get_double(&ff_res);
+
+//   restoreFFRoundingMode(old);
+//   return (*(uint64_t *)( &result ));
+// }
\ No newline at end of file
diff --git a/fpu/axspike.c_BCKP b/fpu/axspike.c_BCKP
new file mode 100644
index 0000000000..e83916240b
--- /dev/null
+++ b/fpu/axspike.c_BCKP
@@ -0,0 +1,365 @@
+#include "qemu/osdep.h"
+
+// #include <stdio.h>
+// #include <stdlib.h>
+
+#include "fpu/flexfloat.h"
+#include "fpu/axspike.h"
+#include "fpu/softfloat.h"
+
+// #if defined( CONFIG_USER_ONLY )
+// Getting EXP and FRAC from ARGS
+
+#define FLEXFLOAT_ALWAYS_INEXACT
+
+
+uint8_t exp_bits = 11;
+uint8_t frac_bits = 52;
+
+// #define exp_bits     11
+// #define frac_bits    25
+
+
+// #else
+// // For now, just hard-code it when run in softmmu mode.
+// static uint8_t exp_bits = 7;
+// static uint8_t frac_bits = 21;
+// #endif
+
+float64_t QEMU_FLATTEN
+f64_add_d_custom(float64_t frs1, float64_t frs2, float_status *status)
+{
+  float64_t f64_a, f64_b, f64_out;
+  f64_a = frs1;
+  f64_b = frs2;
+
+  // translate f64 to double then to flexfloat < Exp , Frac >
+  double dRS1, dRS2;
+  dRS1 = *(double *)&f64_a;
+  dRS2 = *(double *)&f64_b;
+
+  // do addition in flexfloat < Exp , Frac >
+  flexfloat_t reduced_a, reduced_b, reduced_out;
+  ff_init_double(&reduced_a, dRS1, (flexfloat_desc_t){exp_bits, frac_bits});
+  ff_init_double(&reduced_b, dRS2, (flexfloat_desc_t){exp_bits, frac_bits});
+  ff_init_double(&reduced_out, 0.0, (flexfloat_desc_t){exp_bits, frac_bits});
+  ff_add(&reduced_out, &reduced_a, &reduced_b);
+
+  ///////////////////////////////////
+  // @TODO test vectors collection.
+  ///////////////////////////////////
+  // if (this->fpu_dump_enabled)
+  //   fprintf(this->fpu_dump_files["FADD_D"], "%016" PRIX64 " %016" PRIX64 " %016" PRIX64 "\r\n", flexfloat_get_bits(&reduced_a), flexfloat_get_bits(&reduced_b), flexfloat_get_bits(&reduced_out));
+
+  // translate back to double (get double)
+  double dRD = ff_get_double(&reduced_out);
+
+  // then to f64()
+  f64_out = *(float64_t *)&dRD;
+
+#if defined( FLEXFLOAT_ALWAYS_INEXACT )
+  // We suppose that all our computations are inexact, this is a very conservative approach
+  status->float_exception_flags |= float_flag_inexact;
+#endif
+
+  return f64_out;
+}
+
+float64_t QEMU_FLATTEN
+f64_sub_d_custom(float64_t frs1, float64_t frs2, float_status *status)
+{
+  float64_t f64_a, f64_b, f64_out;
+  f64_a = frs1;
+  f64_b = frs2;
+
+  // translate f64 to double then to flexfloat < Exp , Frac >
+  double dRS1, dRS2;
+  dRS1 = *(double *)&f64_a;
+  dRS2 = *(double *)&f64_b;
+
+  // do addition in flexfloat < Exp , Frac >
+  flexfloat_t reduced_a, reduced_b, reduced_out;
+  ff_init_double(&reduced_a, dRS1, (flexfloat_desc_t){exp_bits, frac_bits});
+  ff_init_double(&reduced_b, dRS2, (flexfloat_desc_t){exp_bits, frac_bits});
+  ff_init_double(&reduced_out, 0.0, (flexfloat_desc_t){exp_bits, frac_bits});
+  ff_sub(&reduced_out, &reduced_a, &reduced_b);
+
+  // Export test vectors
+  //   printf("Done FSUB_D");
+  // if (this->fpu_dump_enabled)
+  //   fprintf(this->fpu_dump_files["FSUB_D"], "%016" PRIX64 " %016" PRIX64 " %016" PRIX64 "\r\n", flexfloat_get_bits(&reduced_a), flexfloat_get_bits(&reduced_b), flexfloat_get_bits(&reduced_out));
+
+  // translate back to double (get double)
+  double dRD = ff_get_double(&reduced_out);
+
+  // then to f64()
+  f64_out = *(float64_t *)&dRD;
+
+#if defined( FLEXFLOAT_ALWAYS_INEXACT )
+  // We suppose that all our computations are inexact, this is a very conservative approach
+  status->float_exception_flags |= float_flag_inexact;
+#endif
+
+  return f64_out;
+}
+
+float64_t QEMU_FLATTEN
+f64_mul_d_custom(float64_t frs1, float64_t frs2, float_status *status)
+{
+  float64_t f64_a, f64_b, f64_out;
+  f64_a = frs1;
+  f64_b = frs2;
+
+  // translate f64 to double then to flexfloat < Exp , Frac >
+  double dRS1, dRS2;
+  dRS1 = *(double *)&f64_a;
+  dRS2 = *(double *)&f64_b;
+
+  // do addition in flexfloat < Exp , Frac >
+  flexfloat_t reduced_a, reduced_b, reduced_out;
+  ff_init_double(&reduced_a, dRS1, (flexfloat_desc_t){exp_bits, frac_bits});
+  ff_init_double(&reduced_b, dRS2, (flexfloat_desc_t){exp_bits, frac_bits});
+  ff_init_double(&reduced_out, 0.0, (flexfloat_desc_t){exp_bits, frac_bits});
+  ff_mul(&reduced_out, &reduced_a, &reduced_b);
+
+  // Export test vectors
+  // if (this->fpu_dump_enabled)
+  //   fprintf(this->fpu_dump_files["FMUL_D"], "%016" PRIX64 " %016" PRIX64 " %016" PRIX64 "\r\n", flexfloat_get_bits(&reduced_a), flexfloat_get_bits(&reduced_b), flexfloat_get_bits(&reduced_out));
+
+  // translate back to double (get double)
+  double dRD = ff_get_double(&reduced_out);
+
+  // then to f64()
+  f64_out = *(float64_t *)&dRD;
+
+#if defined( FLEXFLOAT_ALWAYS_INEXACT )
+  // We suppose that all our computations are inexact, this is a very conservative approach
+  status->float_exception_flags |= float_flag_inexact;
+#endif
+
+  return f64_out;
+}
+
+float64_t QEMU_FLATTEN
+f64_div_d_custom(float64_t frs1, float64_t frs2, float_status *status)
+{
+  float64_t f64_a, f64_b, f64_out;
+  f64_a = frs1;
+  f64_b = frs2;
+
+  // translate f64 to double then to flexfloat < Exp , Frac >
+  double dRS1, dRS2;
+  dRS1 = *(double *)&f64_a;
+  dRS2 = *(double *)&f64_b;
+
+  // do addition in flexfloat < Exp , Frac >
+  flexfloat_t reduced_a, reduced_b, reduced_out;
+  ff_init_double(&reduced_a, dRS1, (flexfloat_desc_t){exp_bits, frac_bits});
+  ff_init_double(&reduced_b, dRS2, (flexfloat_desc_t){exp_bits, frac_bits});
+  ff_init_double(&reduced_out, 0.0, (flexfloat_desc_t){exp_bits, frac_bits});
+  ff_div(&reduced_out, &reduced_a, &reduced_b);
+
+  // Export test vectors
+  // if (this->fpu_dump_enabled)
+  //   fprintf(this->fpu_dump_files["FDIV_D"], "%016" PRIX64 " %016" PRIX64 " %016" PRIX64 "\r\n", flexfloat_get_bits(&reduced_a), flexfloat_get_bits(&reduced_b), flexfloat_get_bits(&reduced_out));
+
+  // translate back to double (get double)
+  double dRD = ff_get_double(&reduced_out);
+
+  // then to f64()
+  f64_out = *(float64_t *)&dRD;
+
+#if defined( FLEXFLOAT_ALWAYS_INEXACT )
+  // We suppose that all our computations are inexact, this is a very conservative approach
+  status->float_exception_flags |= float_flag_inexact;
+#endif
+
+  return f64_out;
+}
+
+/* @TODO: DIVision is still being done using float64_t
+  */
+float64_t QEMU_FLATTEN
+f64_sqrt_d_custom(float64_t frs1, float_status *status)
+{
+  // Copy in the input
+  float64_t f64_a;  f64_a = frs1;
+
+  // Input pre-processing: reducing input precision
+  flexfloat_t reduced_in;
+  double Din, Din_reduced;
+  Din = *(double *)&(f64_a.v);
+  // Reduced Input
+  ff_init_double(&reduced_in, Din, (flexfloat_desc_t){exp_bits, frac_bits});
+  Din_reduced = ff_get_double(&reduced_in);
+
+  // printf("-- Reducing the Input precision --\n");
+  // printf("Din         = %.18f\n", Din);
+  // printf("Din_reduced = %.18f\n", Din_reduced);
+  // printf("Din         = 0x%0lX\n", *(uint64_t *)&(Din));
+  // printf("Din_reduced = 0x%0lX\n",  *(uint64_t *)&(Din_reduced));
+  // printf("-----------------------------------------------------------\n");
+
+  // Do the operation with reduced precision inputs.
+
+  // perform the sqrt on the reduced value.
+  f64_a.v = float64_sqrt(*(uint64_t *)&(Din_reduced), status);
+  // perform the sqrt on the original value.
+  // f64_a.v = float64_sqrt(frs1.v, status);
+
+  // // Reducing the result USING GET_BITS =====>   NOK
+  flexfloat_t reduced_out;
+  double Dout, Dout_reduced;
+  Dout = *(double *)&(f64_a.v);
+
+  // Reduced Output
+  ff_init_double(&reduced_out, Dout, (flexfloat_desc_t){exp_bits, frac_bits});
+  Dout_reduced = ff_get_double(&reduced_out);
+
+  // printf("-- Reducing the output precision --\n");
+  // printf("Dout         = %.18f\n", Dout);
+  // printf("Dout_reduced = %.18f\n", Dout_reduced);
+  // printf("Dout         = 0x%0lX\n", *(uint64_t *)&(Dout));
+  // printf("Dout_reduced = 0x%0lX\n",  *(uint64_t *)&(Dout_reduced));
+
+  float64_t fRd; fRd.v = *(uint64_t *)&(Dout_reduced);  
+
+#if defined( FLEXFLOAT_ALWAYS_INEXACT )
+  // We suppose that all our computations are inexact, this is a very conservative approach
+  status->float_exception_flags |= float_flag_inexact;
+#endif
+
+  return fRd; //f64_a;
+}
+/*
+float64_t QEMU_FLATTEN
+f64_sqrt_d_custom(float64_t frs1, float_status *status)
+{
+    float64_t f64_a, f64_out;
+    flexfloat_t reduced_in;
+    double Din;
+    f64_a = frs1;
+    Din = *(double *)&f64_a;
+    ff_init_double(&reduced_in, Din, (flexfloat_desc_t){exp_bits, frac_bits});
+
+    f64_a.v = float64_sqrt(frs1.v, status);
+
+    // translate f64 to double then to flexfloat < Exp , Frac >
+    double dRS1;
+    dRS1 = *(double *)&f64_a;
+
+    // do addition in flexfloat < Exp , Frac >
+    flexfloat_t reduced_out;
+    ff_init_double(&reduced_out, dRS1, (flexfloat_desc_t){exp_bits, frac_bits});
+
+    // if (fpu_dump_enabled)
+    //   fprintf(fpu_dump_files["FSQRT_D"], "%016" PRIX64 " %016" PRIX64 "\r\n", flexfloat_get_bits(&reduced_in),
+    //                                                                               flexfloat_get_bits(&reduced_out));
+
+
+    // translate back to double (get double)
+    double dRD = ff_get_double(&reduced_out);
+
+    // then to f64()
+    f64_out = *(float64_t *)&dRD;
+
+#if defined( FLEXFLOAT_ALWAYS_INEXACT )
+  // We suppose that all our computations are inexact, this is a very conservative approach
+  status->float_exception_flags |= float_flag_inexact;
+#endif
+
+    return f64_out;
+}
+*/
+
+// @TODO use the flags and the status
+float64_t QEMU_FLATTEN
+f64_madd_d_custom(float64_t frs1, float64_t frs2, float64_t frs3, float_status *status)
+{
+  float64_t f64_a, f64_b, f64_c, f64_out;
+  f64_a = frs1;
+  f64_b = frs2;
+  f64_c = frs3;
+
+  // translate f64 to double then to flexfloat < Exp , Frac >
+  double dRS1, dRS2, dRS3;
+  dRS1 = *(double *)&f64_a;
+  dRS2 = *(double *)&f64_b;
+  dRS3 = *(double *)&f64_c;
+
+  // do addition in flexfloat < Exp , Frac >
+  flexfloat_t reduced_a, reduced_b, reduced_c, reduced_out;
+  ff_init_double(&reduced_a, dRS1, (flexfloat_desc_t){exp_bits, frac_bits});
+  ff_init_double(&reduced_b, dRS2, (flexfloat_desc_t){exp_bits, frac_bits});
+  ff_init_double(&reduced_c, dRS3, (flexfloat_desc_t){exp_bits, frac_bits});
+  ff_init_double(&reduced_out, 0.0, (flexfloat_desc_t){exp_bits, frac_bits});
+  ff_fma(&reduced_out, &reduced_a, &reduced_b, &reduced_c);
+
+  // Export test vectors
+  // printf("Done FMADD_D");
+  // if (this->fpu_dump_enabled)
+  //   fprintf(this->fpu_dump_files["FMADD_D"], "%016" PRIX64 " %016" PRIX64 " %016" PRIX64 " %016" PRIX64 "\r\n", flexfloat_get_bits(&reduced_a),
+  //                                                                                              flexfloat_get_bits(&reduced_b),
+  //                                                                                              flexfloat_get_bits(&reduced_c),
+  //                                                                                              flexfloat_get_bits(&reduced_out));
+
+  // translate back to double (get double)
+  double dRD = ff_get_double(&reduced_out);
+
+  // then to f64()
+  f64_out = *(float64_t *)&dRD;
+
+#if defined( FLEXFLOAT_ALWAYS_INEXACT )
+  // We suppose that all our computations are inexact, this is a very conservative approach
+  status->float_exception_flags |= float_flag_inexact;
+#endif
+
+  return f64_out;
+}
+
+// typedef enum ax_mode
+// {
+//   AX_MODE_PRECISE = 0,
+//   AX_MODE_ACCEPTABLE_1 = 1,
+//   AX_MODE_ACCEPTABLE_2 = 2,
+//   AX_MODE_CUSTOM = 3,
+//   AX_MODE_DEGRADED = 4
+// } ax_mode_t;
+
+// typedef struct FPUClass {
+//     /*< private >*/
+
+//     /*< public >*/
+
+//     /* Keep non-pointer data at the end to minimize holes.  */
+//     ax_mode_t ax_mode;
+//     uint8_t exp_bits;
+//     uint8_t frac_bits;
+
+//     // Addresses
+//     // uint32_t _approx_start;
+//     // uint32_t _approx_end;
+//     // uint32_t _eval_start;
+//     // uint32_t _eval_end;
+
+//     // Insn stats
+//     uint64_t executed_insns;
+//     bool insn_stats_enabled;
+//     const char *insn_stats_filename;
+
+//     // FPU in/out dump
+//     bool fpu_dump_enabled;
+//     const char *fpu_dump_filename_prefix;
+
+//     // @TODO Port these to C
+//     // std::map<std::string, uint64_t> axspike_histogram;
+//     // std::map<std::string, FILE*> fpu_dump_files;
+//     // std::vector<std::string> fpu_insns = {"FADD_D" ,
+//     //                                     "FDIV_D" ,
+//     //                                     "FMUL_D" ,
+//     //                                     "FMADD_D" ,
+//     //                                     "FSUB_D" ,
+//     //                                     "FMSUB_D" ,
+//     //                                     "FSQRT_D"};
+
+// } FPUClass;
diff --git a/fpu/flexfloat.c b/fpu/flexfloat.c
new file mode 100644
index 0000000000..86e2dc6a52
--- /dev/null
+++ b/fpu/flexfloat.c
@@ -0,0 +1,794 @@
+/*
+   Copyright 2018 - The OPRECOMP Project Consortium, Alma Mater Studiorum
+   Universit√† di Bologna. All rights reserved.
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
+*/
+
+#include "fpu/flexfloat.h"
+// To avoid manually discerning backend-type for calls from math.h
+#include <tgmath.h>
+
+#if defined(FLEXFLOAT_ROUNDING)|| defined(FLEXFLOAT_FLAGS)
+#include <fenv.h>
+// #pragma STDC FENV_ACCESS ON
+#endif
+
+#include "assert.h"
+
+int_fast16_t flexfloat_exp(const flexfloat_t *a)
+{
+    int_fast16_t a_exp   = EXPONENT(CAST_TO_INT(a->value));
+
+    int_fast16_t bias    = flexfloat_bias(a->desc);
+
+    if(a_exp == 0 || a_exp == INF_EXP)
+        return a_exp;
+    else
+        return (a_exp - BIAS) + bias;
+}
+
+uint_t flexfloat_frac(const flexfloat_t *a)
+{
+    return (CAST_TO_INT(a->value) & MASK_FRAC) >> (NUM_BITS_FRAC - a->desc.frac_bits);
+}
+
+uint_t flexfloat_denorm_frac(const flexfloat_t *a, int_fast16_t exp)
+{
+    if(EXPONENT(CAST_TO_INT(a->value)) == 0) // Denormalized backend value
+    {
+        return (CAST_TO_INT(a->value) & MASK_FRAC) >> (NUM_BITS_FRAC - a->desc.frac_bits);
+    }
+    else // Denormalized target value (in normalized backend value)
+    {
+        unsigned short shift = NUM_BITS_FRAC - a->desc.frac_bits - exp + 1;
+        if(shift >= NUM_BITS) return 0;
+        return (((CAST_TO_INT(a->value) & MASK_FRAC) | MASK_FRAC_MSB) >> shift);
+    }
+}
+
+// Pack normalized desc-fraction with desc-relative exponent to backend float
+uint_t flexfloat_pack(flexfloat_desc_t desc, bool sign, int_fast16_t exp, uint_t frac)
+{
+    int_fast16_t bias    = flexfloat_bias(desc);
+    int_fast16_t inf_exp = flexfloat_inf_exp(desc);
+
+    if(exp == inf_exp)   // Inf or NaN
+    {
+        exp = INF_EXP;
+    }
+    else
+    {
+        exp = (exp - bias) + BIAS;
+    }
+    return PACK(sign, exp, frac << (NUM_BITS_FRAC - desc.frac_bits));
+}
+
+uint_t flexfloat_denorm_pack(flexfloat_desc_t desc, bool sign, uint_t frac)
+{
+    // int_fast16_t bias    = flexfloat_bias(desc);
+    return PACK(sign, 0, frac << (NUM_BITS_FRAC - desc.frac_bits));
+}
+
+uint_t flexfloat_pack_bits(flexfloat_desc_t desc, uint_t bits)
+{
+    bool sign = (bits >> (desc.exp_bits + desc.frac_bits)) & 0x1;
+    int_fast16_t exp = (bits >> desc.frac_bits) & ((0x1<<desc.exp_bits) - 1);
+    uint_t frac = bits & ((UINT_C(1)<<desc.frac_bits) - 1);
+
+    if(exp == 0 && frac == 0)
+    {
+        return PACK(sign, 0, 0);
+    }
+    else if(exp <= 0) // denormal
+    {
+        // printf("[ff_pack_bits] normalizing 0x%016lx, exp %d\n", frac, exp);
+        while (frac && !((frac <<= 1) & (UINT_C(1) << desc.frac_bits))) // normalize
+            exp--;
+        frac &= ((UINT_C(1) << desc.frac_bits) - 1); // remove implicit bit
+        // printf("[ff_pack_bits] done normalizing 0x%016lx, exp %d\n", frac, exp);
+        return flexfloat_pack(desc, sign, exp, frac);
+    }
+    else
+    {
+        return flexfloat_pack(desc, sign, exp, frac);
+    }
+}
+
+void flexfloat_set_bits(flexfloat_t *a, uint_t bits)
+{
+    CAST_TO_INT(a->value) = flexfloat_pack_bits(a->desc, bits);
+}
+
+uint_t flexfloat_get_bits(flexfloat_t *a)
+{
+    int_fast16_t exp = flexfloat_exp(a);
+    uint_t frac = flexfloat_frac(a);
+
+    if(exp == INF_EXP) exp = flexfloat_inf_exp(a->desc);
+    else if(exp <= 0) {
+        frac = flexfloat_denorm_frac(a, exp);
+        exp = 0;
+    }
+
+    return ((uint_t)flexfloat_sign(a) << (a->desc.exp_bits + a->desc.frac_bits))
+           + ((uint_t)exp << a->desc.frac_bits)
+           + frac;
+}
+
+#ifdef FLEXFLOAT_ROUNDING
+
+// get rounding bit from backend value (first bit after represented LSB)
+bool flexfloat_round_bit(const flexfloat_t *a, int_fast16_t exp)
+{
+    if(exp <= 0 && EXPONENT(CAST_TO_INT(a->value)) != 0)
+    {
+        int shift = (- exp + 1);
+        uint_t denorm = 0;
+        if(shift < NUM_BITS)  // @TODO i added parentheses around |
+            denorm = ((CAST_TO_INT(a->value) & MASK_FRAC) | MASK_FRAC_MSB) >> shift;
+        return denorm & (UINT_C(0x1) << (NUM_BITS_FRAC - a->desc.frac_bits - 1));
+    }
+    else
+    {
+        return CAST_TO_INT(a->value) & (UINT_C(0x1) << (NUM_BITS_FRAC - a->desc.frac_bits - 1));
+    }
+}
+
+// get sticky bit from backend value (logic OR of all bits after represented LSB except the round bit)
+bool flexfloat_sticky_bit(const flexfloat_t *a, int_fast16_t exp)
+{
+    if(exp <= 0 && EXPONENT(CAST_TO_INT(a->value)) != 0)
+    {
+        int shift = (- exp + 1);
+        uint_t denorm = 0;
+        if(shift < NUM_BITS)
+            denorm = ((CAST_TO_INT(a->value) & MASK_FRAC) | MASK_FRAC_MSB) >> shift;
+        return (denorm & (MASK_FRAC >> (a->desc.frac_bits + 1))) ||
+               ( ((denorm & MASK_FRAC) == 0)  && (CAST_TO_INT(a->value)!=0) );
+    }
+    else
+    {
+        return CAST_TO_INT(a->value) & (MASK_FRAC >> (a->desc.frac_bits + 1));
+    }
+}
+
+// check if rounding to nearest is required (the most significant bit of the discarded ones is 1)
+bool flexfloat_nearest_rounding(const flexfloat_t *a, int_fast16_t exp)
+{
+    if (flexfloat_round_bit(a, exp))
+    {
+        if (flexfloat_sticky_bit(a, exp)) // > ulp/2 away
+        {
+            return 1;
+        }
+        else // = ulp/2 away, round towards even result, decided by LSB of mantissa
+        {
+            if (exp <= 0) // denormal
+                return flexfloat_denorm_frac(a, exp) & 0x1;
+            return flexfloat_frac(a) & 0x1;
+        }
+    }
+    return 0; // < ulp/2 away
+}
+
+// check if rounding to +inf/-inf is required (at least one bit of the discarded ones is 1)
+bool flexfloat_inf_rounding(const flexfloat_t *a, int_fast16_t exp, bool sign, bool plus)
+{
+    if (flexfloat_round_bit(a, exp) || flexfloat_sticky_bit(a, exp))
+        return (plus ^ sign);
+    return 0;
+}
+
+// return a value to sum in order to apply rounding
+int_t flexfloat_rounding_value(const flexfloat_t *a, int_fast16_t exp, bool sign)
+{
+    if(EXPONENT(CAST_TO_INT(a->value)) == 0) // Denorm backend format
+    {
+        return flexfloat_denorm_pack(a->desc, sign, 0x1);
+    }
+    else if(exp <= 0) // Denorm target format
+    {
+        return flexfloat_pack(a->desc, sign, - a->desc.frac_bits + 1 , 0);
+    }
+    else
+    {
+        return flexfloat_pack(a->desc, sign, exp - a->desc.frac_bits , 0);
+    }
+
+}
+
+#endif // FLEXFLOAT_ROUNDING
+
+void flexfloat_sanitize(flexfloat_t *a)
+{
+    bool sign;
+    int_fast16_t exp;
+    int_fast16_t inf_exp;
+    uint_t frac;
+
+    // This case does not require to be sanitized
+    if(a->desc.exp_bits  == NUM_BITS_EXP  &&
+       a->desc.frac_bits == NUM_BITS_FRAC)
+        return;
+
+    // Sign
+    sign = flexfloat_sign(a);
+
+    // Exponent
+    exp = flexfloat_exp(a);
+
+#ifdef FLEXFLOAT_ROUNDING
+    // In these cases no rounding is needed
+    if (!(exp == INF_EXP  || a->desc.frac_bits == NUM_BITS_FRAC))
+    {
+#ifdef FLEXFLOAT_FLAGS
+        // Inexact results raise an exception
+        if(flexfloat_round_bit(a, exp) || flexfloat_sticky_bit(a, exp))
+            feraiseexcept(FE_INEXACT);
+        // As rounding uses FP operations, we don't want to tarnish the accrued flags
+        fexcept_t flags;
+        fegetexceptflag(&flags, FE_ALL_EXCEPT);
+#endif
+        // Rounding mode
+        int mode = fegetround();
+        if(mode == FE_TONEAREST && flexfloat_nearest_rounding(a, exp))
+        {
+            int_t rounding_value = flexfloat_rounding_value(a, exp, sign);
+            a->value +=  CAST_TO_FP(rounding_value);
+        }
+        else if(mode == FE_UPWARD && flexfloat_inf_rounding(a, exp, sign, 1))
+        {
+            int_t rounding_value = flexfloat_rounding_value(a, exp, sign);
+            a->value +=  CAST_TO_FP(rounding_value);
+        }
+        else if(mode == FE_DOWNWARD && flexfloat_inf_rounding(a, exp, sign, 0))
+        {
+            int_t rounding_value = flexfloat_rounding_value(a, exp, sign);
+            a->value +=  CAST_TO_FP(rounding_value);
+        }
+#ifdef FLEXFLOAT_FLAGS
+        // Restore flags from before
+        fesetexceptflag(&flags, FE_ALL_EXCEPT);
+#endif
+        //a->value = a->value;
+        __asm__ __volatile__ ("" ::: "memory");
+
+        // Recompute exponent value after rounding
+        exp = flexfloat_exp(a);
+    }
+#endif
+
+    // Exponent of NaN and Inf (target format)
+    inf_exp = flexfloat_inf_exp(a->desc);
+
+    // Mantissa
+    frac = flexfloat_frac(a);
+
+    if(EXPONENT(CAST_TO_INT(a->value)) == 0) // Denorm backend format - represented format also denormal
+    {
+        CAST_TO_INT(a->value) = flexfloat_denorm_pack(a->desc, sign, frac);
+        return;
+    }
+
+   if(exp <= 0) // Denormalized value in the target format (saved in normalized format in the backend value)
+    {
+#ifdef FLEXFLOAT_FLAGS
+        // Raise the underflow exception
+        feraiseexcept(FE_UNDERFLOW);
+#endif
+        uint_t denorm = flexfloat_denorm_frac(a, exp);
+        if(denorm == 0) // value too low to be represented, return zero
+        {
+            CAST_TO_INT(a->value) = PACK(sign, 0, 0);
+            return;
+        }
+        else if(a->desc.frac_bits < NUM_BITS_FRAC) // Remove additional precision
+        {
+            int shift = - exp + 1;
+            if(shift < NUM_BITS_FRAC)
+            {
+              frac >>= shift;
+              frac <<= shift;
+            }
+            else
+            {
+              frac = UINT_C(0);
+            }
+        }
+    }
+    else if(exp == INF_EXP && (CAST_TO_INT(a->value) & MASK_FRAC)) // NaN
+    {
+        exp  = inf_exp;
+        // Sanitize to canonical NaN (positive sign, quiet bit set)
+        sign = 0;
+        frac = UINT_C(1) << (a->desc.frac_bits-1);
+    }
+    else if(exp == INF_EXP) // Inf
+    {
+#ifdef FLEXFLOAT_FLAGS
+        // Raise the proper overflow exception, unless a DIV/0 exception had occured
+        if (!fetestexcept(FE_DIVBYZERO))
+            feraiseexcept(FE_OVERFLOW | FE_INEXACT);
+#endif
+        exp = inf_exp;
+    }
+    else if(exp >= inf_exp) // Out of bounds for target format: set infinity
+    {
+#ifdef FLEXFLOAT_FLAGS
+        // Raise the proper overflow exception
+        feraiseexcept(FE_OVERFLOW | FE_INEXACT);
+#endif
+        exp = inf_exp;
+        frac = UINT_C(0);
+    }
+
+    // printf("ENCODING: %d %d %lu\n", sign, exp, frac);
+    CAST_TO_INT(a->value) = flexfloat_pack(a->desc, sign, exp, frac);
+}
+
+// Constructors
+
+INLINE void ff_init(flexfloat_t *obj, flexfloat_desc_t desc) {
+    obj->value = 0.0;
+    #ifdef FLEXFLOAT_TRACKING
+    obj->exact_value = 0.0;
+    obj->tracking_fn = 0;
+    obj->tracking_arg = 0;
+    #endif
+    obj->desc = desc;
+}
+
+INLINE void ff_init_float(flexfloat_t *obj, float value, flexfloat_desc_t desc) {
+    obj->value = (fp_t)value;
+    #ifdef FLEXFLOAT_TRACKING
+    obj->exact_value = (fp_t)value;
+    obj->tracking_fn = 0;
+    obj->tracking_arg = 0;
+    #endif
+    obj->desc = desc;
+    flexfloat_sanitize(obj);
+}
+
+INLINE void ff_init_double(flexfloat_t *obj, double value, flexfloat_desc_t desc) {
+    obj->value = (fp_t)value;
+    #ifdef FLEXFLOAT_TRACKING
+    obj->exact_value = (fp_t)value;
+    obj->tracking_fn = 0;
+    obj->tracking_arg = 0;
+    #endif
+    obj->desc = desc;
+    flexfloat_sanitize(obj);
+}
+
+
+INLINE void ff_init_longdouble(flexfloat_t *obj, long double value, flexfloat_desc_t desc) {
+    obj->value = (fp_t)value;
+    #ifdef FLEXFLOAT_TRACKING
+    obj->exact_value = (fp_t)value;;
+    obj->tracking_fn = 0;
+    obj->tracking_arg = 0;
+    #endif
+    obj->desc = desc;
+    flexfloat_sanitize(obj);
+}
+
+INLINE void ff_init_float128(flexfloat_t *obj, __float128 value, flexfloat_desc_t desc) {
+    obj->value = (fp_t)value;
+    #ifdef FLEXFLOAT_TRACKING
+    obj->exact_value = (fp_t)value;;
+    obj->tracking_fn = 0;
+    obj->tracking_arg = 0;
+    #endif
+    obj->desc = desc;
+    flexfloat_sanitize(obj);
+}
+
+INLINE void ff_init_int(flexfloat_t *obj, int value, flexfloat_desc_t desc) {
+    obj->value = (fp_t)value;
+    #ifdef FLEXFLOAT_TRACKING
+    obj->exact_value = (fp_t)value;
+    obj->tracking_fn = 0;
+    obj->tracking_arg = 0;
+    #endif
+    obj->desc = desc;
+    flexfloat_sanitize(obj);
+}
+
+
+INLINE void ff_init_long(flexfloat_t *obj, long value, flexfloat_desc_t desc) {
+    obj->value = (fp_t)value;
+    #ifdef FLEXFLOAT_TRACKING
+    obj->exact_value = (fp_t)value;
+    obj->tracking_fn = 0;
+    obj->tracking_arg = 0;
+    #endif
+    obj->desc = desc;
+    flexfloat_sanitize(obj);
+}
+
+
+
+INLINE void ff_cast(flexfloat_t *obj, const flexfloat_t *source, flexfloat_desc_t desc ) {
+    obj->value = source->value;
+    #ifdef FLEXFLOAT_TRACKING
+    obj->exact_value = source->exact_value;
+    obj->tracking_fn = 0;
+    obj->tracking_arg = 0;
+    #endif
+    obj->desc  = desc;
+    if(desc.exp_bits != source->desc.exp_bits || desc.frac_bits != source->desc.frac_bits)
+        flexfloat_sanitize(obj);
+    #ifdef FLEXFLOAT_STATS
+    if(StatsEnabled) getCastStats(source->desc, desc)->total += 1;
+    #endif
+}
+
+
+// Casts
+
+INLINE float ff_get_float(const flexfloat_t *obj) {
+    return (float)(*((const fp_t *)(&(obj->value))));
+}
+
+INLINE double ff_get_double(const flexfloat_t *obj) {
+    return (double)(*((const fp_t *)(&(obj->value))));
+}
+
+INLINE long double ff_get_longdouble(const flexfloat_t *obj) {
+    return (long double)(*((const fp_t *)(&(obj->value))));
+}
+
+INLINE __float128 ff_get_float128(const flexfloat_t *obj) {
+    return (__float128)(*((const fp_t *)(&(obj->value))));
+}
+
+
+// Arithmetics
+
+INLINE void ff_inverse(flexfloat_t *dest, const flexfloat_t *a) {
+    assert((dest->desc.exp_bits == a->desc.exp_bits) && (dest->desc.frac_bits == a->desc.frac_bits));
+    dest->value = - a->value;
+    #ifdef FLEXFLOAT_TRACKING
+    dest->exact_value = - a->exact_value;
+    if(dest->tracking_fn) (dest->tracking_fn)(dest, dest->tracking_arg);
+    #endif
+    #ifdef FLEXFLOAT_STATS
+    if(StatsEnabled) getOpStats(dest->desc)->minus += 1;
+    #endif
+}
+
+
+INLINE void ff_add(flexfloat_t *dest, const flexfloat_t *a, const flexfloat_t *b) {
+    assert((dest->desc.exp_bits == a->desc.exp_bits) && (dest->desc.frac_bits == a->desc.frac_bits) &&
+           (a->desc.exp_bits == b->desc.exp_bits) && (a->desc.frac_bits == b->desc.frac_bits));
+    dest->value = a->value + b->value;
+    #ifdef FLEXFLOAT_TRACKING
+    dest->exact_value = a->exact_value + b->exact_value;
+    if(dest->tracking_fn) (dest->tracking_fn)(dest, dest->tracking_arg);
+    #endif
+    flexfloat_sanitize(dest);
+    #ifdef FLEXFLOAT_STATS
+    if(StatsEnabled) getOpStats(dest->desc)->add += 1;
+    #endif
+}
+
+INLINE void ff_sub(flexfloat_t *dest, const flexfloat_t *a, const flexfloat_t *b) {
+    assert((dest->desc.exp_bits == a->desc.exp_bits) && (dest->desc.frac_bits == a->desc.frac_bits) &&
+           (a->desc.exp_bits == b->desc.exp_bits) && (a->desc.frac_bits == b->desc.frac_bits));
+    dest->value = a->value - b->value;
+    #ifdef FLEXFLOAT_TRACKING
+    dest->exact_value = a->exact_value - b->exact_value;
+    if(dest->tracking_fn) (dest->tracking_fn)(dest, dest->tracking_arg);
+    #endif
+    flexfloat_sanitize(dest);
+    #ifdef FLEXFLOAT_STATS
+    if(StatsEnabled) getOpStats(dest->desc)->sub += 1;
+    #endif
+}
+
+INLINE void ff_mul(flexfloat_t *dest, const flexfloat_t *a, const flexfloat_t *b) {
+    assert((dest->desc.exp_bits == a->desc.exp_bits) && (dest->desc.frac_bits == a->desc.frac_bits) &&
+           (a->desc.exp_bits == b->desc.exp_bits) && (a->desc.frac_bits == b->desc.frac_bits));
+    dest->value = a->value * b->value;
+    #ifdef FLEXFLOAT_TRACKING
+    dest->exact_value = a->exact_value * b->exact_value;
+    if(dest->tracking_fn) (dest->tracking_fn)(dest, dest->tracking_arg);
+    #endif
+    flexfloat_sanitize(dest);
+    #ifdef FLEXFLOAT_STATS
+    if(StatsEnabled) getOpStats(dest->desc)->mul += 1;
+    #endif
+}
+
+INLINE void ff_div(flexfloat_t *dest, const flexfloat_t *a, const flexfloat_t *b) {
+    assert((dest->desc.exp_bits == a->desc.exp_bits) && (dest->desc.frac_bits == a->desc.frac_bits) &&
+           (a->desc.exp_bits == b->desc.exp_bits) && (a->desc.frac_bits == b->desc.frac_bits));
+    dest->value = a->value / b->value;
+    #ifdef FLEXFLOAT_TRACKING
+    dest->exact_value = a->exact_value / b->exact_value;
+    if(dest->tracking_fn) (dest->tracking_fn)(dest, dest->tracking_arg);
+    #endif
+    flexfloat_sanitize(dest);
+    #ifdef FLEXFLOAT_STATS
+    if(StatsEnabled) getOpStats(dest->desc)->div += 1;
+    #endif
+}
+
+INLINE void ff_acc(flexfloat_t *dest, const flexfloat_t *a) {
+    assert((dest->desc.exp_bits == a->desc.exp_bits) && (dest->desc.frac_bits == a->desc.frac_bits));
+    dest->value += a->value;
+    #ifdef FLEXFLOAT_TRACKING
+    dest->exact_value += a->exact_value;
+    if(dest->tracking_fn) (dest->tracking_fn)(dest, dest->tracking_arg);
+    #endif
+    flexfloat_sanitize(dest);
+    #ifdef FLEXFLOAT_STATS
+    if(StatsEnabled) getOpStats(dest->desc)->minus += 1;
+    #endif
+}
+
+INLINE void ff_min(flexfloat_t *dest, const flexfloat_t *a, const flexfloat_t *b) {
+    assert((dest->desc.exp_bits == a->desc.exp_bits) && (dest->desc.frac_bits == a->desc.frac_bits) &&
+           (a->desc.exp_bits == b->desc.exp_bits) && (a->desc.frac_bits == b->desc.frac_bits));
+    dest->value = fmin(a->value,b->value);
+    // fmin's zero sign handling is implementation defined! Check for 0 cases and ensure -0 is chosen
+    if ((a->value == 0) && (a->value == b->value))
+        CAST_TO_INT(dest->value) = (UINT_C(0x1) << (NUM_BITS-1));
+    #ifdef FLEXFLOAT_TRACKING
+    dest->exact_value = fmin(a->exact_value,b->exact_value);
+    if ((a->exact_value == 0) && (a->exact_value == b->exact_value))
+        CAST_TO_INT(dest->exact_value) = (UINT_C(0x1) << (NUM_BITS-1));
+    if(dest->tracking_fn) (dest->tracking_fn)(dest, dest->tracking_arg);
+    #endif
+    flexfloat_sanitize(dest);
+    #ifdef FLEXFLOAT_STATS
+    if(StatsEnabled) getOpStats(dest->desc)->minmax += 1;
+    #endif
+}
+
+INLINE void ff_max(flexfloat_t *dest, const flexfloat_t *a, const flexfloat_t *b) {
+    assert((dest->desc.exp_bits == a->desc.exp_bits) && (dest->desc.frac_bits == a->desc.frac_bits) &&
+           (a->desc.exp_bits == b->desc.exp_bits) && (a->desc.frac_bits == b->desc.frac_bits));
+    dest->value = fmax(a->value,b->value);
+    // fmax' zero sign handling is implementation defined! Check for 0 cases and ensure +0 is chosen
+    if ((a->value == 0) && (a->value == b->value))
+        CAST_TO_INT(dest->value) = 0;
+    #ifdef FLEXFLOAT_TRACKING
+    dest->exact_value = fmax(a->exact_value,b->exact_value);
+    if ((a->exact_value == 0) && (a->exact_value == b->exact_value))
+        CAST_TO_INT(dest->exact_value) = 0;
+    if(dest->tracking_fn) (dest->tracking_fn)(dest, dest->tracking_arg);
+    #endif
+    flexfloat_sanitize(dest);
+    #ifdef FLEXFLOAT_STATS
+    if(StatsEnabled) getOpStats(dest->desc)->minmax += 1;
+    #endif
+}
+
+INLINE void ff_fma(flexfloat_t *dest, const flexfloat_t *a, const flexfloat_t *b, const flexfloat_t *c) {
+    assert((dest->desc.exp_bits == a->desc.exp_bits) && (dest->desc.frac_bits == a->desc.frac_bits) &&
+           (a->desc.exp_bits == b->desc.exp_bits) && (a->desc.frac_bits == b->desc.frac_bits) &&
+           (b->desc.exp_bits == c->desc.exp_bits) && (b->desc.frac_bits == c->desc.frac_bits));
+    #ifdef FLEXFLOAT_ROUNDING
+    // Change the rounding mode according to the error direction if we need to do manual rounding for RNE
+    int mode = fegetround();
+    bool eff_sub = flexfloat_sign(a) ^ flexfloat_sign(b) ^ flexfloat_sign(c);
+    if (a->desc.frac_bits < NUM_BITS_FRAC && mode == FE_TONEAREST) {
+        if (!eff_sub) { // in this case, we need to round away from zero
+            fexcept_t flags;
+            fegetexceptflag(&flags, FE_ALL_EXCEPT); // get accrued flags to not tarnish them here
+            double try = fma(a->value, b->value, c->value);
+            (try >= 0) ? fesetround(FE_UPWARD) : fesetround(FE_DOWNWARD);
+            fesetexceptflag(&flags, FE_ALL_EXCEPT); // restore flags here
+        } else {
+            fesetround(FE_TOWARDZERO); // just truncate
+        }
+    }
+    #endif
+    dest->value = fma(a->value, b->value, c->value); // finally the actual operation
+    #ifdef FLEXFLOAT_TRACKING
+    dest->exact_value = fma(a->exact_value, b->exact_value, c->exact_value);
+    if(dest->tracking_fn) (dest->tracking_fn)(dest, dest->tracking_arg);
+    #endif
+    #ifdef FLEXFLOAT_ROUNDING
+    if (a->desc.frac_bits < NUM_BITS_FRAC && mode == FE_TONEAREST)
+        fesetround(FE_TONEAREST); // restore rounding
+    #endif
+    flexfloat_sanitize(dest);
+    #ifdef FLEXFLOAT_STATS
+    if(StatsEnabled) getOpStats(dest->desc)->fma += 1;
+    #endif
+}
+
+// Relational operators
+
+INLINE bool ff_eq(const flexfloat_t *a, const flexfloat_t *b) {
+    assert((a->desc.exp_bits == b->desc.exp_bits) && (a->desc.frac_bits == b->desc.frac_bits));
+    #ifdef FLEXFLOAT_STATS
+    if(StatsEnabled) getOpStats(a->desc)->cmp += 1;
+    #endif
+    return a->value == b->value;
+}
+
+INLINE bool ff_neq(const flexfloat_t *a, const flexfloat_t *b) {
+        assert((a->desc.exp_bits == b->desc.exp_bits) && (a->desc.frac_bits == b->desc.frac_bits));
+    #ifdef FLEXFLOAT_STATS
+    if(StatsEnabled) getOpStats(a->desc)->cmp += 1;
+    #endif
+    return a->value != b->value;
+}
+
+INLINE bool ff_le(const flexfloat_t *a, const flexfloat_t *b) {
+    assert((a->desc.exp_bits == b->desc.exp_bits) && (a->desc.frac_bits == b->desc.frac_bits));
+    #if defined(FLEXFLOAT_FLAGS) && !defined(FLEXFLOAT_CORRECT_CMP_FLAGS)
+    if (isnan(a->value) || isnan(b->value))
+        feraiseexcept(FE_INVALID);
+    #endif
+    #ifdef FLEXFLOAT_STATS
+    if(StatsEnabled) getOpStats(a->desc)->cmp += 1;
+    #endif
+    return (a->value <= b->value);
+}
+
+INLINE bool ff_lt(const flexfloat_t *a, const flexfloat_t *b) {
+    assert((a->desc.exp_bits == b->desc.exp_bits) && (a->desc.frac_bits == b->desc.frac_bits));
+    #if defined(FLEXFLOAT_FLAGS) && !defined(FLEXFLOAT_CORRECT_CMP_FLAGS)
+    if (isnan(a->value) || isnan(b->value))
+        feraiseexcept(FE_INVALID);
+    #endif
+    #ifdef FLEXFLOAT_STATS
+    if(StatsEnabled) getOpStats(a->desc)->cmp += 1;
+    #endif
+    return (a->value < b->value);
+}
+
+INLINE bool ff_ge(const flexfloat_t *a, const flexfloat_t *b) {
+    assert((a->desc.exp_bits == b->desc.exp_bits) && (a->desc.frac_bits == b->desc.frac_bits));
+    #if defined(FLEXFLOAT_FLAGS) && !defined(FLEXFLOAT_CORRECT_CMP_FLAGS)
+    if (isnan(a->value) || isnan(b->value))
+        feraiseexcept(FE_INVALID);
+    #endif
+    #ifdef FLEXFLOAT_STATS
+    if(StatsEnabled) getOpStats(a->desc)->cmp += 1;
+    #endif
+    return (a->value >= b->value);
+}
+
+INLINE bool ff_gt(const flexfloat_t *a, const flexfloat_t *b) {
+    assert((a->desc.exp_bits == b->desc.exp_bits) && (a->desc.frac_bits == b->desc.frac_bits));
+    #if defined(FLEXFLOAT_FLAGS) && !defined(FLEXFLOAT_CORRECT_CMP_FLAGS)
+    if (isnan(a->value) || isnan(b->value))
+        feraiseexcept(FE_INVALID);
+    #endif
+    #ifdef FLEXFLOAT_STATS
+    if(StatsEnabled) getOpStats(a->desc)->cmp += 1;
+    #endif
+    return (a->value > b->value);
+}
+
+// Collection of statistics
+#ifdef FLEXFLOAT_STATS
+#include <stdlib.h>
+#include <string.h>
+
+bool StatsEnabled = 1;
+HashSlot   op_stats[FLEXFLOAT_STATS_MAX_TYPES];
+HashSlot cast_stats[FLEXFLOAT_STATS_MAX_TYPES*FLEXFLOAT_STATS_MAX_TYPES];
+
+void * ht_search(HashSlot* hashArray, uint32_t hashIndex, uint32_t key, uint32_t arraySize) {
+   hashIndex %= arraySize;
+   while(hashArray[hashIndex].key != 0) {
+      // look for the key
+      if(hashArray[hashIndex].key == key)
+         return hashArray[hashIndex].value;
+      // not found? try the next slot!
+      ++hashIndex;
+      hashIndex %= arraySize;
+   }
+   return 0;
+}
+void ht_insert(HashSlot* hashArray, uint32_t hashIndex, uint32_t key, void *value, uint32_t arraySize) {
+    hashIndex %= arraySize;
+    // look for a free slot
+    while(hashArray[hashIndex].key != 0) {
+        ++hashIndex;
+        hashIndex %= arraySize;
+        assert(hashIndex != key); // No free slots after a full iteration
+   }
+   hashArray[hashIndex].key = key;
+   hashArray[hashIndex].value = value;
+}
+
+OpStats * getOpStats(const flexfloat_desc_t desc)
+{
+    uint32_t hashIndex = precision_hash(desc);
+    void * result  = ht_search(op_stats, hashIndex, hashIndex, FLEXFLOAT_STATS_MAX_TYPES);
+    if(result == 0) {
+        result = malloc(sizeof(OpStats));
+        memset(result, 0, sizeof(OpStats));
+        ht_insert(op_stats, hashIndex, hashIndex, result, FLEXFLOAT_STATS_MAX_TYPES);
+    }
+    return (OpStats *) result;
+}
+
+CastStats * getCastStats(const flexfloat_desc_t desc1, const flexfloat_desc_t desc2)
+{
+    uint32_t hashIndex = precision_hash2(desc1, desc2);
+    void * result  = ht_search(cast_stats, hashIndex, hashIndex, FLEXFLOAT_STATS_MAX_TYPES*FLEXFLOAT_STATS_MAX_TYPES);
+    if(result == 0) {
+        result = malloc(sizeof(CastStats));
+        memset(result, 0, sizeof(CastStats));
+        ht_insert(cast_stats, hashIndex, hashIndex, result, FLEXFLOAT_STATS_MAX_TYPES*FLEXFLOAT_STATS_MAX_TYPES);
+    }
+    return (CastStats *) result;
+}
+
+INLINE void ff_start_stats(void) {
+    StatsEnabled = 1;
+}
+
+INLINE void ff_stop_stats(void) {
+    StatsEnabled = 0;
+}
+
+void ff_clear_stats(void) {
+    int i;
+    for(i=0; i<FLEXFLOAT_STATS_MAX_TYPES; ++i)
+        if(op_stats[i].key != 0) free(op_stats[i].value);
+    memset(op_stats, 0, sizeof(HashSlot) * FLEXFLOAT_STATS_MAX_TYPES);
+    for(i=0; i<FLEXFLOAT_STATS_MAX_TYPES*FLEXFLOAT_STATS_MAX_TYPES; ++i)
+        if(cast_stats[i].key != 0) free(cast_stats[i].value);
+    memset(cast_stats, 0, sizeof(HashSlot) * FLEXFLOAT_STATS_MAX_TYPES*FLEXFLOAT_STATS_MAX_TYPES);
+}
+
+void ff_print_stats(void) {
+    int i;
+    printf("-- OPERATIONS -- \n");
+    for(i=0; i<FLEXFLOAT_STATS_MAX_TYPES; ++i) {
+        uint32_t key = op_stats[i].key;
+        if(key != 0) {
+            KeyStruct skey = *(KeyStruct*)&key;
+            uint8_t exp_bits = skey.exp_bits1;
+            uint8_t frac_bits = skey.frac_bits1;
+            OpStats * stats = (OpStats *) op_stats[i].value;
+
+            printf("flexfloat<%hhu,%hhu>\n", exp_bits, frac_bits);
+            printf("    INV    \t%lu\n", stats->minus);
+            printf("    ADD    \t%lu\n", stats->add);
+            printf("    SUB    \t%lu\n", stats->sub);
+            printf("    MUL    \t%lu\n", stats->mul);
+            printf("    DIV    \t%lu\n", stats->div);
+            printf("  MIN/MAX  \t%lu\n", stats->minmax);
+            printf("    FMA    \t%lu\n", stats->fma);
+            printf("    CMP    \t%lu\n", stats->cmp);
+        }
+    }
+    printf("-- CASTS -- \n");
+    for(i=0; i<FLEXFLOAT_STATS_MAX_TYPES*FLEXFLOAT_STATS_MAX_TYPES; ++i) {
+        uint32_t key = cast_stats[i].key;
+        if(key != 0) {
+            KeyStruct skey = *(KeyStruct*)&key;
+            uint8_t exp_bits1 = skey.exp_bits1;
+            uint8_t frac_bits1 = skey.frac_bits1;
+            uint8_t exp_bits2 = skey.exp_bits2;
+            uint8_t frac_bits2 = skey.frac_bits2;
+            CastStats * stats = (CastStats *) cast_stats[i].value;
+
+            printf("flexfloat<%hhu,%hhu> -> flexfloat<%hhu,%hhu>\n", exp_bits1, frac_bits1, exp_bits2, frac_bits2);
+            printf("    TOTAL    \t%lu\n", stats->total);
+        }
+    }
+}
+
+#endif /* FLEXFLOAT_STATS */
diff --git a/fpu/flexfloat_gvsoc.c b/fpu/flexfloat_gvsoc.c
new file mode 100644
index 0000000000..06424ed44e
--- /dev/null
+++ b/fpu/flexfloat_gvsoc.c
@@ -0,0 +1,794 @@
+/*
+   Copyright 2018 - The OPRECOMP Project Consortium, Alma Mater Studiorum
+   Universit√† di Bologna. All rights reserved.
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
+*/
+
+#include "flexfloat.h"
+// To avoid manually discerning backend-type for calls from math.h
+#include <tgmath.h>
+
+#if defined(FLEXFLOAT_ROUNDING)|| defined(FLEXFLOAT_FLAGS)
+#include <fenv.h>
+#pragma STDC FENV_ACCESS ON
+#endif
+
+#include "assert.h"
+
+int_fast16_t flexfloat_exp(const flexfloat_t *a)
+{
+    int_fast16_t a_exp   = EXPONENT(CAST_TO_INT(a->value));
+
+    int_fast16_t bias    = flexfloat_bias(a->desc);
+
+    if(a_exp == 0 || a_exp == INF_EXP)
+        return a_exp;
+    else
+        return (a_exp - BIAS) + bias;
+}
+
+uint_t flexfloat_frac(const flexfloat_t *a)
+{
+    return (CAST_TO_INT(a->value) & MASK_FRAC) >> (NUM_BITS_FRAC - a->desc.frac_bits);
+}
+
+uint_t flexfloat_denorm_frac(const flexfloat_t *a, int_fast16_t exp)
+{
+    if(EXPONENT(CAST_TO_INT(a->value)) == 0) // Denormalized backend value
+    {
+        return (CAST_TO_INT(a->value) & MASK_FRAC) >> (NUM_BITS_FRAC - a->desc.frac_bits);
+    }
+    else // Denormalized target value (in normalized backend value)
+    {
+        unsigned short shift = NUM_BITS_FRAC - a->desc.frac_bits - exp + 1;
+        if(shift >= NUM_BITS) return 0;
+        return (((CAST_TO_INT(a->value) & MASK_FRAC) | MASK_FRAC_MSB) >> shift);
+    }
+}
+
+// Pack normalized desc-fraction with desc-relative exponent to backend float
+uint_t flexfloat_pack(flexfloat_desc_t desc, bool sign, int_fast16_t exp, uint_t frac)
+{
+    int_fast16_t bias    = flexfloat_bias(desc);
+    int_fast16_t inf_exp = flexfloat_inf_exp(desc);
+
+    if(exp == inf_exp)   // Inf or NaN
+    {
+        exp = INF_EXP;
+    }
+    else
+    {
+        exp = (exp - bias) + BIAS;
+    }
+    return PACK(sign, exp, frac << (NUM_BITS_FRAC - desc.frac_bits));
+}
+
+uint_t flexfloat_denorm_pack(flexfloat_desc_t desc, bool sign, uint_t frac)
+{
+    int_fast16_t bias    = flexfloat_bias(desc);
+    return PACK(sign, 0, frac << (NUM_BITS_FRAC - desc.frac_bits));
+}
+
+uint_t flexfloat_pack_bits(flexfloat_desc_t desc, uint_t bits)
+{
+    bool sign = (bits >> (desc.exp_bits + desc.frac_bits)) & 0x1;
+    int_fast16_t exp = (bits >> desc.frac_bits) & ((0x1<<desc.exp_bits) - 1);
+    uint_t frac = bits & ((UINT_C(1)<<desc.frac_bits) - 1);
+
+    if(exp == 0 && frac == 0)
+    {
+        return PACK(sign, 0, 0);
+    }
+    else if(exp <= 0) // denormal
+    {
+        // printf("[ff_pack_bits] normalizing 0x%016lx, exp %d\n", frac, exp);
+        while (frac && !((frac <<= 1) & (UINT_C(1) << desc.frac_bits))) // normalize
+            exp--;
+        frac &= ((UINT_C(1) << desc.frac_bits) - 1); // remove implicit bit
+        // printf("[ff_pack_bits] done normalizing 0x%016lx, exp %d\n", frac, exp);
+        return flexfloat_pack(desc, sign, exp, frac);
+    }
+    else
+    {
+        return flexfloat_pack(desc, sign, exp, frac);
+    }
+}
+
+void flexfloat_set_bits(flexfloat_t *a, uint_t bits)
+{
+    CAST_TO_INT(a->value) = flexfloat_pack_bits(a->desc, bits);
+}
+
+uint_t flexfloat_get_bits(flexfloat_t *a)
+{
+    int_fast16_t exp = flexfloat_exp(a);
+    uint_t frac = flexfloat_frac(a);
+
+    if(exp == INF_EXP) exp = flexfloat_inf_exp(a->desc);
+    else if(exp <= 0) {
+        frac = flexfloat_denorm_frac(a, exp);
+        exp = 0;
+    }
+
+    return ((uint_t)flexfloat_sign(a) << (a->desc.exp_bits + a->desc.frac_bits))
+           + ((uint_t)exp << a->desc.frac_bits)
+           + frac;
+}
+
+#ifdef FLEXFLOAT_ROUNDING
+
+// get rounding bit from backend value (first bit after represented LSB)
+bool flexfloat_round_bit(const flexfloat_t *a, int_fast16_t exp)
+{
+    if(exp <= 0 && EXPONENT(CAST_TO_INT(a->value)) != 0)
+    {
+        int shift = (- exp + 1);
+        uint_t denorm = 0;
+        if(shift < NUM_BITS)
+          denorm = ((CAST_TO_INT(a->value) & MASK_FRAC | MASK_FRAC_MSB)) >> shift;
+        return denorm & (UINT_C(0x1) << (NUM_BITS_FRAC - a->desc.frac_bits - 1));
+    }
+    else
+    {
+        return CAST_TO_INT(a->value) & (UINT_C(0x1) << (NUM_BITS_FRAC - a->desc.frac_bits - 1));
+    }
+}
+
+// get sticky bit from backend value (logic OR of all bits after represented LSB except the round bit)
+bool flexfloat_sticky_bit(const flexfloat_t *a, int_fast16_t exp)
+{
+    if(exp <= 0 && EXPONENT(CAST_TO_INT(a->value)) != 0)
+    {
+        int shift = (- exp + 1);
+        uint_t denorm = 0;
+        if(shift < NUM_BITS)
+            denorm = ((CAST_TO_INT(a->value) & MASK_FRAC) | MASK_FRAC_MSB) >> shift;
+        return (denorm & (MASK_FRAC >> (a->desc.frac_bits + 1))) ||
+               ( ((denorm & MASK_FRAC) == 0)  && (CAST_TO_INT(a->value)!=0) );
+    }
+    else
+    {
+        return CAST_TO_INT(a->value) & (MASK_FRAC >> (a->desc.frac_bits + 1));
+    }
+}
+
+// check if rounding to nearest is required (the most significant bit of the discarded ones is 1)
+bool flexfloat_nearest_rounding(const flexfloat_t *a, int_fast16_t exp)
+{
+    if (flexfloat_round_bit(a, exp))
+        if (flexfloat_sticky_bit(a, exp)) // > ulp/2 away
+        {
+            return 1;
+        }
+        else // = ulp/2 away, round towards even result, decided by LSB of mantissa
+        {
+            if (exp <= 0) // denormal
+                return flexfloat_denorm_frac(a, exp) & 0x1;
+            return flexfloat_frac(a) & 0x1;
+        }
+    return 0; // < ulp/2 away
+}
+
+// check if rounding to +inf/-inf is required (at least one bit of the discarded ones is 1)
+bool flexfloat_inf_rounding(const flexfloat_t *a, int_fast16_t exp, bool sign, bool plus)
+{
+    if (flexfloat_round_bit(a, exp) || flexfloat_sticky_bit(a, exp))
+        return (plus ^ sign);
+    return 0;
+}
+
+// return a value to sum in order to apply rounding
+int_t flexfloat_rounding_value(const flexfloat_t *a, int_fast16_t exp, bool sign)
+{
+    if(EXPONENT(CAST_TO_INT(a->value)) == 0) // Denorm backend format
+    {
+        return flexfloat_denorm_pack(a->desc, sign, 0x1);
+    }
+    else if(exp <= 0) // Denorm target format
+    {
+        return flexfloat_pack(a->desc, sign, - a->desc.frac_bits + 1 , 0);
+    }
+    else
+    {
+        return flexfloat_pack(a->desc, sign, exp - a->desc.frac_bits , 0);
+    }
+
+}
+
+#endif // FLEXFLOAT_ROUNDING
+
+void flexfloat_sanitize(flexfloat_t *a)
+{
+    bool sign;
+    int_fast16_t exp;
+    int_fast16_t inf_exp;
+    uint_t frac;
+
+    // This case does not require to be sanitized
+    if(a->desc.exp_bits  == NUM_BITS_EXP  &&
+       a->desc.frac_bits == NUM_BITS_FRAC)
+        return;
+
+    // Sign
+    sign = flexfloat_sign(a);
+
+    // Exponent
+    exp = flexfloat_exp(a);
+
+#ifdef FLEXFLOAT_ROUNDING
+    // In these cases no rounding is needed
+    if (!(exp == INF_EXP  || a->desc.frac_bits == NUM_BITS_FRAC))
+    {
+#ifdef FLEXFLOAT_FLAGS
+        // Inexact results raise an exception
+        if(flexfloat_round_bit(a, exp) || flexfloat_sticky_bit(a, exp))
+            feraiseexcept(FE_INEXACT);
+        // As rounding uses FP operations, we don't want to tarnish the accrued flags
+        fexcept_t flags;
+        fegetexceptflag(&flags, FE_ALL_EXCEPT);
+#endif
+        // Rounding mode
+        int mode = fegetround();
+        if(mode == FE_TONEAREST && flexfloat_nearest_rounding(a, exp))
+        {
+            int_t rounding_value = flexfloat_rounding_value(a, exp, sign);
+            a->value +=  CAST_TO_FP(rounding_value);
+        }
+        else if(mode == FE_UPWARD && flexfloat_inf_rounding(a, exp, sign, 1))
+        {
+            int_t rounding_value = flexfloat_rounding_value(a, exp, sign);
+            a->value +=  CAST_TO_FP(rounding_value);
+        }
+        else if(mode == FE_DOWNWARD && flexfloat_inf_rounding(a, exp, sign, 0))
+        {
+            int_t rounding_value = flexfloat_rounding_value(a, exp, sign);
+            a->value +=  CAST_TO_FP(rounding_value);
+        }
+#ifdef FLEXFLOAT_FLAGS
+        // Restore flags from before
+        fesetexceptflag(&flags, FE_ALL_EXCEPT);
+#endif
+        //a->value = a->value;
+        __asm__ __volatile__ ("" ::: "memory");
+
+        // Recompute exponent value after rounding
+        exp = flexfloat_exp(a);
+    }
+#endif
+
+    // Exponent of NaN and Inf (target format)
+    inf_exp = flexfloat_inf_exp(a->desc);
+
+    // Mantissa
+    frac = flexfloat_frac(a);
+
+    if(EXPONENT(CAST_TO_INT(a->value)) == 0) // Denorm backend format - represented format also denormal
+    {
+        CAST_TO_INT(a->value) = flexfloat_denorm_pack(a->desc, sign, frac);
+        return;
+    }
+
+   if(exp <= 0) // Denormalized value in the target format (saved in normalized format in the backend value)
+    {
+#ifdef FLEXFLOAT_FLAGS
+        // Raise the underflow exception
+        feraiseexcept(FE_UNDERFLOW);
+#endif
+        uint_t denorm = flexfloat_denorm_frac(a, exp);
+        if(denorm == 0) // value too low to be represented, return zero
+        {
+            CAST_TO_INT(a->value) = PACK(sign, 0, 0);
+            return;
+        }
+        else if(a->desc.frac_bits < NUM_BITS_FRAC) // Remove additional precision
+        {
+            int shift = - exp + 1;
+            if(shift < NUM_BITS_FRAC)
+            {
+              frac >>= shift;
+              frac <<= shift;
+            }
+            else
+            {
+              frac = UINT_C(0);
+            }
+        }
+    }
+    else if(exp == INF_EXP && (CAST_TO_INT(a->value) & MASK_FRAC)) // NaN
+    {
+        exp  = inf_exp;
+        // Sanitize to canonical NaN (positive sign, quiet bit set)
+        sign = 0;
+        frac = UINT_C(1) << a->desc.frac_bits-1;
+    }
+    else if(exp == INF_EXP) // Inf
+    {
+#ifdef FLEXFLOAT_FLAGS
+        // Raise the proper overflow exception, unless a DIV/0 exception had occured
+        if (!fetestexcept(FE_DIVBYZERO))
+            feraiseexcept(FE_OVERFLOW | FE_INEXACT);
+#endif
+        exp = inf_exp;
+    }
+    else if(exp >= inf_exp) // Out of bounds for target format: set infinity
+    {
+#ifdef FLEXFLOAT_FLAGS
+        // Raise the proper overflow exception
+        feraiseexcept(FE_OVERFLOW | FE_INEXACT);
+#endif
+        exp = inf_exp;
+        frac = UINT_C(0);
+    }
+
+    // printf("ENCODING: %d %d %lu\n", sign, exp, frac);
+    CAST_TO_INT(a->value) = flexfloat_pack(a->desc, sign, exp, frac);
+}
+
+// Constructors
+
+INLINE void ff_init(flexfloat_t *obj, flexfloat_desc_t desc) {
+    obj->value = 0.0;
+    #ifdef FLEXFLOAT_TRACKING
+    obj->exact_value = 0.0;
+    obj->tracking_fn = 0;
+    obj->tracking_arg = 0;
+    #endif
+    obj->desc = desc;
+    // @TODO
+    // flexfloat_sanitize(obj);
+}
+
+INLINE void ff_init_float(flexfloat_t *obj, float value, flexfloat_desc_t desc) {
+    obj->value = (fp_t)value;
+    #ifdef FLEXFLOAT_TRACKING
+    obj->exact_value = (fp_t)value;
+    obj->tracking_fn = 0;
+    obj->tracking_arg = 0;
+    #endif
+    obj->desc = desc;
+    flexfloat_sanitize(obj);
+}
+
+INLINE void ff_init_double(flexfloat_t *obj, double value, flexfloat_desc_t desc) {
+    obj->value = (fp_t)value;
+    #ifdef FLEXFLOAT_TRACKING
+    obj->exact_value = (fp_t)value;
+    obj->tracking_fn = 0;
+    obj->tracking_arg = 0;
+    #endif
+    obj->desc = desc;
+    flexfloat_sanitize(obj);
+}
+
+
+INLINE void ff_init_longdouble(flexfloat_t *obj, long double value, flexfloat_desc_t desc) {
+    obj->value = (fp_t)value;
+    #ifdef FLEXFLOAT_TRACKING
+    obj->exact_value = (fp_t)value;;
+    obj->tracking_fn = 0;
+    obj->tracking_arg = 0;
+    #endif
+    obj->desc = desc;
+    flexfloat_sanitize(obj);
+}
+
+INLINE void ff_init_float128(flexfloat_t *obj, __float128 value, flexfloat_desc_t desc) {
+    obj->value = (fp_t)value;
+    #ifdef FLEXFLOAT_TRACKING
+    obj->exact_value = (fp_t)value;;
+    obj->tracking_fn = 0;
+    obj->tracking_arg = 0;
+    #endif
+    obj->desc = desc;
+    flexfloat_sanitize(obj);
+}
+
+INLINE void ff_init_int(flexfloat_t *obj, int value, flexfloat_desc_t desc) {
+    obj->value = (fp_t)value;
+    #ifdef FLEXFLOAT_TRACKING
+    obj->exact_value = (fp_t)value;
+    obj->tracking_fn = 0;
+    obj->tracking_arg = 0;
+    #endif
+    obj->desc = desc;
+    flexfloat_sanitize(obj);
+}
+
+
+INLINE void ff_init_long(flexfloat_t *obj, long value, flexfloat_desc_t desc) {
+    obj->value = (fp_t)value;
+    #ifdef FLEXFLOAT_TRACKING
+    obj->exact_value = (fp_t)value;
+    obj->tracking_fn = 0;
+    obj->tracking_arg = 0;
+    #endif
+    obj->desc = desc;
+    flexfloat_sanitize(obj);
+}
+
+
+
+INLINE void ff_cast(flexfloat_t *obj, const flexfloat_t *source, flexfloat_desc_t desc ) {
+    obj->value = source->value;
+    #ifdef FLEXFLOAT_TRACKING
+    obj->exact_value = source->exact_value;
+    obj->tracking_fn = 0;
+    obj->tracking_arg = 0;
+    #endif
+    obj->desc  = desc;
+    if(desc.exp_bits != source->desc.exp_bits || desc.frac_bits != source->desc.frac_bits)
+        flexfloat_sanitize(obj);
+    #ifdef FLEXFLOAT_STATS
+    if(StatsEnabled) getCastStats(source->desc, desc)->total += 1;
+    #endif
+}
+
+
+// Casts
+
+INLINE float ff_get_float(const flexfloat_t *obj) {
+    return (float)(*((const fp_t *)(&(obj->value))));
+}
+
+INLINE double ff_get_double(const flexfloat_t *obj) {
+    return (double)(*((const fp_t *)(&(obj->value))));
+}
+
+INLINE long double ff_get_longdouble(const flexfloat_t *obj) {
+    return (long double)(*((const fp_t *)(&(obj->value))));
+}
+
+INLINE __float128 ff_get_float128(const flexfloat_t *obj) {
+    return (__float128)(*((const fp_t *)(&(obj->value))));
+}
+
+
+// Arithmetics
+
+INLINE void ff_inverse(flexfloat_t *dest, const flexfloat_t *a) {
+    assert((dest->desc.exp_bits == a->desc.exp_bits) && (dest->desc.frac_bits == a->desc.frac_bits));
+    dest->value = - a->value;
+    #ifdef FLEXFLOAT_TRACKING
+    dest->exact_value = - a->exact_value;
+    if(dest->tracking_fn) (dest->tracking_fn)(dest, dest->tracking_arg);
+    #endif
+    #ifdef FLEXFLOAT_STATS
+    if(StatsEnabled) getOpStats(dest->desc)->minus += 1;
+    #endif
+}
+
+
+INLINE void ff_add(flexfloat_t *dest, const flexfloat_t *a, const flexfloat_t *b) {
+    assert((dest->desc.exp_bits == a->desc.exp_bits) && (dest->desc.frac_bits == a->desc.frac_bits) &&
+           (a->desc.exp_bits == b->desc.exp_bits) && (a->desc.frac_bits == b->desc.frac_bits));
+    dest->value = a->value + b->value;
+    #ifdef FLEXFLOAT_TRACKING
+    dest->exact_value = a->exact_value + b->exact_value;
+    if(dest->tracking_fn) (dest->tracking_fn)(dest, dest->tracking_arg);
+    #endif
+    flexfloat_sanitize(dest);
+    #ifdef FLEXFLOAT_STATS
+    if(StatsEnabled) getOpStats(dest->desc)->add += 1;
+    #endif
+}
+
+INLINE void ff_sub(flexfloat_t *dest, const flexfloat_t *a, const flexfloat_t *b) {
+    assert((dest->desc.exp_bits == a->desc.exp_bits) && (dest->desc.frac_bits == a->desc.frac_bits) &&
+           (a->desc.exp_bits == b->desc.exp_bits) && (a->desc.frac_bits == b->desc.frac_bits));
+    dest->value = a->value - b->value;
+    #ifdef FLEXFLOAT_TRACKING
+    dest->exact_value = a->exact_value - b->exact_value;
+    if(dest->tracking_fn) (dest->tracking_fn)(dest, dest->tracking_arg);
+    #endif
+    flexfloat_sanitize(dest);
+    #ifdef FLEXFLOAT_STATS
+    if(StatsEnabled) getOpStats(dest->desc)->sub += 1;
+    #endif
+}
+
+INLINE void ff_mul(flexfloat_t *dest, const flexfloat_t *a, const flexfloat_t *b) {
+    assert((dest->desc.exp_bits == a->desc.exp_bits) && (dest->desc.frac_bits == a->desc.frac_bits) &&
+           (a->desc.exp_bits == b->desc.exp_bits) && (a->desc.frac_bits == b->desc.frac_bits));
+    dest->value = a->value * b->value;
+    #ifdef FLEXFLOAT_TRACKING
+    dest->exact_value = a->exact_value * b->exact_value;
+    if(dest->tracking_fn) (dest->tracking_fn)(dest, dest->tracking_arg);
+    #endif
+    flexfloat_sanitize(dest);
+    #ifdef FLEXFLOAT_STATS
+    if(StatsEnabled) getOpStats(dest->desc)->mul += 1;
+    #endif
+}
+
+INLINE void ff_div(flexfloat_t *dest, const flexfloat_t *a, const flexfloat_t *b) {
+    assert((dest->desc.exp_bits == a->desc.exp_bits) && (dest->desc.frac_bits == a->desc.frac_bits) &&
+           (a->desc.exp_bits == b->desc.exp_bits) && (a->desc.frac_bits == b->desc.frac_bits));
+    dest->value = a->value / b->value;
+    #ifdef FLEXFLOAT_TRACKING
+    dest->exact_value = a->exact_value / b->exact_value;
+    if(dest->tracking_fn) (dest->tracking_fn)(dest, dest->tracking_arg);
+    #endif
+    flexfloat_sanitize(dest);
+    #ifdef FLEXFLOAT_STATS
+    if(StatsEnabled) getOpStats(dest->desc)->div += 1;
+    #endif
+}
+
+INLINE void ff_acc(flexfloat_t *dest, const flexfloat_t *a) {
+    assert((dest->desc.exp_bits == a->desc.exp_bits) && (dest->desc.frac_bits == a->desc.frac_bits));
+    dest->value += a->value;
+    #ifdef FLEXFLOAT_TRACKING
+    dest->exact_value += a->exact_value;
+    if(dest->tracking_fn) (dest->tracking_fn)(dest, dest->tracking_arg);
+    #endif
+    flexfloat_sanitize(dest);
+    #ifdef FLEXFLOAT_STATS
+    if(StatsEnabled) getOpStats(dest->desc)->minus += 1;
+    #endif
+}
+
+INLINE void ff_min(flexfloat_t *dest, const flexfloat_t *a, const flexfloat_t *b) {
+    assert((dest->desc.exp_bits == a->desc.exp_bits) && (dest->desc.frac_bits == a->desc.frac_bits) &&
+           (a->desc.exp_bits == b->desc.exp_bits) && (a->desc.frac_bits == b->desc.frac_bits));
+    dest->value = fmin(a->value,b->value);
+    // fmin's zero sign handling is implementation defined! Check for 0 cases and ensure -0 is chosen
+    if ((a->value == 0) && (a->value == b->value))
+        CAST_TO_INT(dest->value) = (UINT_C(0x1) << NUM_BITS-1);
+    #ifdef FLEXFLOAT_TRACKING
+    dest->exact_value = fmin(a->exact_value,b->exact_value);
+    if ((a->exact_value == 0) && (a->exact_value == b->exact_value))
+        CAST_TO_INT(dest->exact_value) = (UINT_C(0x1) << NUM_BITS-1);
+    if(dest->tracking_fn) (dest->tracking_fn)(dest, dest->tracking_arg);
+    #endif
+    flexfloat_sanitize(dest);
+    #ifdef FLEXFLOAT_STATS
+    if(StatsEnabled) getOpStats(dest->desc)->minmax += 1;
+    #endif
+}
+
+INLINE void ff_max(flexfloat_t *dest, const flexfloat_t *a, const flexfloat_t *b) {
+    assert((dest->desc.exp_bits == a->desc.exp_bits) && (dest->desc.frac_bits == a->desc.frac_bits) &&
+           (a->desc.exp_bits == b->desc.exp_bits) && (a->desc.frac_bits == b->desc.frac_bits));
+    dest->value = fmax(a->value,b->value);
+    // fmax' zero sign handling is implementation defined! Check for 0 cases and ensure +0 is chosen
+    if ((a->value == 0) && (a->value == b->value))
+        CAST_TO_INT(dest->value) = 0;
+    #ifdef FLEXFLOAT_TRACKING
+    dest->exact_value = fmax(a->exact_value,b->exact_value);
+    if ((a->exact_value == 0) && (a->exact_value == b->exact_value))
+        CAST_TO_INT(dest->exact_value) = 0;
+    if(dest->tracking_fn) (dest->tracking_fn)(dest, dest->tracking_arg);
+    #endif
+    flexfloat_sanitize(dest);
+    #ifdef FLEXFLOAT_STATS
+    if(StatsEnabled) getOpStats(dest->desc)->minmax += 1;
+    #endif
+}
+
+INLINE void ff_fma(flexfloat_t *dest, const flexfloat_t *a, const flexfloat_t *b, const flexfloat_t *c) {
+    assert((dest->desc.exp_bits == a->desc.exp_bits) && (dest->desc.frac_bits == a->desc.frac_bits) &&
+           (a->desc.exp_bits == b->desc.exp_bits) && (a->desc.frac_bits == b->desc.frac_bits) &&
+           (b->desc.exp_bits == c->desc.exp_bits) && (b->desc.frac_bits == c->desc.frac_bits));
+    #ifdef FLEXFLOAT_ROUNDING
+    // Change the rounding mode according to the error direction if we need to do manual rounding for RNE
+    int mode = fegetround();
+    bool eff_sub = flexfloat_sign(a) ^ flexfloat_sign(b) ^ flexfloat_sign(c);
+    if (a->desc.frac_bits < NUM_BITS_FRAC && mode == FE_TONEAREST) {
+        if (!eff_sub) { // in this case, we need to round away from zero
+            fexcept_t flags;
+            fegetexceptflag(&flags, FE_ALL_EXCEPT); // get accrued flags to not tarnish them here
+            double try = fma(a->value, b->value, c->value);
+            (try >= 0) ? fesetround(FE_UPWARD) : fesetround(FE_DOWNWARD);
+            fesetexceptflag(&flags, FE_ALL_EXCEPT); // restore flags here
+        } else {
+            fesetround(FE_TOWARDZERO); // just truncate
+        }
+    }
+    #endif
+    dest->value = fma(a->value, b->value, c->value); // finally the actual operation
+    #ifdef FLEXFLOAT_TRACKING
+    dest->exact_value = fma(a->exact_value, b->exact_value, c->exact_value);
+    if(dest->tracking_fn) (dest->tracking_fn)(dest, dest->tracking_arg);
+    #endif
+    #ifdef FLEXFLOAT_ROUNDING
+    if (a->desc.frac_bits < NUM_BITS_FRAC && mode == FE_TONEAREST)
+        fesetround(FE_TONEAREST); // restore rounding
+    #endif
+    flexfloat_sanitize(dest);
+    #ifdef FLEXFLOAT_STATS
+    if(StatsEnabled) getOpStats(dest->desc)->fma += 1;
+    #endif
+}
+
+// Relational operators
+
+INLINE bool ff_eq(const flexfloat_t *a, const flexfloat_t *b) {
+    assert((a->desc.exp_bits == b->desc.exp_bits) && (a->desc.frac_bits == b->desc.frac_bits));
+    #ifdef FLEXFLOAT_STATS
+    if(StatsEnabled) getOpStats(a->desc)->cmp += 1;
+    #endif
+    return a->value == b->value;
+}
+
+INLINE bool ff_neq(const flexfloat_t *a, const flexfloat_t *b) {
+        assert((a->desc.exp_bits == b->desc.exp_bits) && (a->desc.frac_bits == b->desc.frac_bits));
+    #ifdef FLEXFLOAT_STATS
+    if(StatsEnabled) getOpStats(a->desc)->cmp += 1;
+    #endif
+    return a->value != b->value;
+}
+
+INLINE bool ff_le(const flexfloat_t *a, const flexfloat_t *b) {
+    assert((a->desc.exp_bits == b->desc.exp_bits) && (a->desc.frac_bits == b->desc.frac_bits));
+    #if defined(FLEXFLOAT_FLAGS) && !defined(FLEXFLOAT_CORRECT_CMP_FLAGS)
+    if (isnan(a->value) || isnan(b->value))
+        feraiseexcept(FE_INVALID);
+    #endif
+    #ifdef FLEXFLOAT_STATS
+    if(StatsEnabled) getOpStats(a->desc)->cmp += 1;
+    #endif
+    return (a->value <= b->value);
+}
+
+INLINE bool ff_lt(const flexfloat_t *a, const flexfloat_t *b) {
+    assert((a->desc.exp_bits == b->desc.exp_bits) && (a->desc.frac_bits == b->desc.frac_bits));
+    #if defined(FLEXFLOAT_FLAGS) && !defined(FLEXFLOAT_CORRECT_CMP_FLAGS)
+    if (isnan(a->value) || isnan(b->value))
+        feraiseexcept(FE_INVALID);
+    #endif
+    #ifdef FLEXFLOAT_STATS
+    if(StatsEnabled) getOpStats(a->desc)->cmp += 1;
+    #endif
+    return (a->value < b->value);
+}
+
+INLINE bool ff_ge(const flexfloat_t *a, const flexfloat_t *b) {
+    assert((a->desc.exp_bits == b->desc.exp_bits) && (a->desc.frac_bits == b->desc.frac_bits));
+    #if defined(FLEXFLOAT_FLAGS) && !defined(FLEXFLOAT_CORRECT_CMP_FLAGS)
+    if (isnan(a->value) || isnan(b->value))
+        feraiseexcept(FE_INVALID);
+    #endif
+    #ifdef FLEXFLOAT_STATS
+    if(StatsEnabled) getOpStats(a->desc)->cmp += 1;
+    #endif
+    return (a->value >= b->value);
+}
+
+INLINE bool ff_gt(const flexfloat_t *a, const flexfloat_t *b) {
+    assert((a->desc.exp_bits == b->desc.exp_bits) && (a->desc.frac_bits == b->desc.frac_bits));
+    #if defined(FLEXFLOAT_FLAGS) && !defined(FLEXFLOAT_CORRECT_CMP_FLAGS)
+    if (isnan(a->value) || isnan(b->value))
+        feraiseexcept(FE_INVALID);
+    #endif
+    #ifdef FLEXFLOAT_STATS
+    if(StatsEnabled) getOpStats(a->desc)->cmp += 1;
+    #endif
+    return (a->value > b->value);
+}
+
+// Collection of statistics
+#ifdef FLEXFLOAT_STATS
+#include <stdlib.h>
+#include <string.h>
+
+bool StatsEnabled = 1;
+HashSlot   op_stats[FLEXFLOAT_STATS_MAX_TYPES];
+HashSlot cast_stats[FLEXFLOAT_STATS_MAX_TYPES*FLEXFLOAT_STATS_MAX_TYPES];
+
+void * ht_search(HashSlot* hashArray, uint32_t hashIndex, uint32_t key, uint32_t arraySize) {
+   hashIndex %= arraySize;
+   while(hashArray[hashIndex].key != 0) {
+      // look for the key
+      if(hashArray[hashIndex].key == key)
+         return hashArray[hashIndex].value;
+      // not found? try the next slot!
+      ++hashIndex;
+      hashIndex %= arraySize;
+   }
+   return 0;
+}
+void ht_insert(HashSlot* hashArray, uint32_t hashIndex, uint32_t key, void *value, uint32_t arraySize) {
+    hashIndex %= arraySize;
+    // look for a free slot
+    while(hashArray[hashIndex].key != 0) {
+        ++hashIndex;
+        hashIndex %= arraySize;
+        assert(hashIndex != key); // No free slots after a full iteration
+   }
+   hashArray[hashIndex].key = key;
+   hashArray[hashIndex].value = value;
+}
+
+OpStats * getOpStats(const flexfloat_desc_t desc)
+{
+    uint32_t hashIndex = precision_hash(desc);
+    void * result  = ht_search(op_stats, hashIndex, hashIndex, FLEXFLOAT_STATS_MAX_TYPES);
+    if(result == 0) {
+        result = malloc(sizeof(OpStats));
+        memset(result, 0, sizeof(OpStats));
+        ht_insert(op_stats, hashIndex, hashIndex, result, FLEXFLOAT_STATS_MAX_TYPES);
+    }
+    return (OpStats *) result;
+}
+
+CastStats * getCastStats(const flexfloat_desc_t desc1, const flexfloat_desc_t desc2)
+{
+    uint32_t hashIndex = precision_hash2(desc1, desc2);
+    void * result  = ht_search(cast_stats, hashIndex, hashIndex, FLEXFLOAT_STATS_MAX_TYPES*FLEXFLOAT_STATS_MAX_TYPES);
+    if(result == 0) {
+        result = malloc(sizeof(CastStats));
+        memset(result, 0, sizeof(CastStats));
+        ht_insert(cast_stats, hashIndex, hashIndex, result, FLEXFLOAT_STATS_MAX_TYPES*FLEXFLOAT_STATS_MAX_TYPES);
+    }
+    return (CastStats *) result;
+}
+
+INLINE void ff_start_stats() {
+    StatsEnabled = 1;
+}
+
+INLINE void ff_stop_stats() {
+    StatsEnabled = 0;
+}
+
+void ff_clear_stats() {
+    int i;
+    for(i=0; i<FLEXFLOAT_STATS_MAX_TYPES; ++i)
+        if(op_stats[i].key != 0) free(op_stats[i].value);
+    memset(op_stats, 0, sizeof(HashSlot) * FLEXFLOAT_STATS_MAX_TYPES);
+    for(i=0; i<FLEXFLOAT_STATS_MAX_TYPES*FLEXFLOAT_STATS_MAX_TYPES; ++i)
+        if(cast_stats[i].key != 0) free(cast_stats[i].value);
+    memset(cast_stats, 0, sizeof(HashSlot) * FLEXFLOAT_STATS_MAX_TYPES*FLEXFLOAT_STATS_MAX_TYPES);
+}
+
+void ff_print_stats() {
+    int i;
+    printf("-- OPERATIONS -- \n");
+    for(i=0; i<FLEXFLOAT_STATS_MAX_TYPES; ++i) {
+        uint32_t key = op_stats[i].key;
+        if(key != 0) {
+            KeyStruct skey = *(KeyStruct*)&key;
+            uint8_t exp_bits = skey.exp_bits1;
+            uint8_t frac_bits = skey.frac_bits1;
+            OpStats * stats = (OpStats *) op_stats[i].value;
+
+            printf("flexfloat<%hhu,%hhu>\n", exp_bits, frac_bits);
+            printf("    INV    \t%lu\n", stats->minus);
+            printf("    ADD    \t%lu\n", stats->add);
+            printf("    SUB    \t%lu\n", stats->sub);
+            printf("    MUL    \t%lu\n", stats->mul);
+            printf("    DIV    \t%lu\n", stats->div);
+            printf("  MIN/MAX  \t%lu\n", stats->minmax);
+            printf("    FMA    \t%lu\n", stats->fma);
+            printf("    CMP    \t%lu\n", stats->cmp);
+        }
+    }
+    printf("-- CASTS -- \n");
+    for(i=0; i<FLEXFLOAT_STATS_MAX_TYPES*FLEXFLOAT_STATS_MAX_TYPES; ++i) {
+        uint32_t key = cast_stats[i].key;
+        if(key != 0) {
+            KeyStruct skey = *(KeyStruct*)&key;
+            uint8_t exp_bits1 = skey.exp_bits1;
+            uint8_t frac_bits1 = skey.frac_bits1;
+            uint8_t exp_bits2 = skey.exp_bits2;
+            uint8_t frac_bits2 = skey.frac_bits2;
+            CastStats * stats = (CastStats *) cast_stats[i].value;
+
+            printf("flexfloat<%hhu,%hhu> -> flexfloat<%hhu,%hhu>\n", exp_bits1, frac_bits1, exp_bits2, frac_bits2);
+            printf("    TOTAL    \t%lu\n", stats->total);
+        }
+    }
+}
+
+#endif /* FLEXFLOAT_STATS */
diff --git a/hw/riscv/sifive_e.c b/hw/riscv/sifive_e.c
index 792d75a1a3..324b1d7837 100644
--- a/hw/riscv/sifive_e.c
+++ b/hw/riscv/sifive_e.c
@@ -40,6 +40,7 @@
 #include "hw/riscv/riscv_hart.h"
 #include "hw/riscv/sifive_plic.h"
 #include "hw/riscv/sifive_clint.h"
+#include "hw/riscv/sifive_test.h"
 #include "hw/riscv/sifive_prci.h"
 #include "hw/riscv/sifive_uart.h"
 #include "hw/riscv/sifive_e.h"
@@ -56,6 +57,7 @@ static const struct MemmapEntry {
     [SIFIVE_E_DEBUG] =    {        0x0,      0x100 },
     [SIFIVE_E_MROM] =     {     0x1000,     0x2000 },
     [SIFIVE_E_OTP] =      {    0x20000,     0x2000 },
+    [SIFIVE_E_TEST] =     {   0x100000,     0x1000 },
     [SIFIVE_E_CLINT] =    {  0x2000000,    0x10000 },
     [SIFIVE_E_PLIC] =     {  0xc000000,  0x4000000 },
     [SIFIVE_E_AON] =      { 0x10000000,     0x8000 },
@@ -71,7 +73,7 @@ static const struct MemmapEntry {
     [SIFIVE_E_QSPI2] =    { 0x10034000,     0x1000 },
     [SIFIVE_E_PWM2] =     { 0x10035000,     0x1000 },
     [SIFIVE_E_XIP] =      { 0x20000000, 0x20000000 },
-    [SIFIVE_E_DTIM] =     { 0x80000000,     0x4000 }
+    [SIFIVE_E_DTIM] =     { 0x80000000,   0x400000 }
 };
 
 static void sifive_mmio_emulate(MemoryRegion *parent, const char *name,
@@ -213,6 +215,7 @@ static void riscv_sifive_e_soc_realize(DeviceState *dev, Error **errp)
         memmap[SIFIVE_E_QSPI2].base, memmap[SIFIVE_E_QSPI2].size);
     sifive_mmio_emulate(sys_mem, "riscv.sifive.e.pwm2",
         memmap[SIFIVE_E_PWM2].base, memmap[SIFIVE_E_PWM2].size);
+    sifive_test_create(memmap[SIFIVE_E_TEST].base);
 
     /* Flash memory */
     memory_region_init_ram(&s->xip_mem, NULL, "riscv.sifive.e.xip",
diff --git a/hw/riscv/sifive_test.c b/hw/riscv/sifive_test.c
index afbb3aaf34..39cc1dccbc 100644
--- a/hw/riscv/sifive_test.c
+++ b/hw/riscv/sifive_test.c
@@ -19,7 +19,7 @@
  */
 
 #include "qemu/osdep.h"
-#include "hw/hw.h"
+#include "qemu/error-report.h"
 #include "hw/sysbus.h"
 #include "qemu/module.h"
 #include "target/riscv/cpu.h"
@@ -39,6 +39,7 @@ static void sifive_test_write(void *opaque, hwaddr addr,
         int code = (val64 >> 16) & 0xffff;
         switch (status) {
         case FINISHER_FAIL:
+            error_report("QEMU: Program exited with code '%d'", code);
             exit(code);
         case FINISHER_PASS:
             exit(0);
diff --git a/hw/riscv/sifive_u.c b/hw/riscv/sifive_u.c
index 9910fa6708..7adf5e672a 100644
--- a/hw/riscv/sifive_u.c
+++ b/hw/riscv/sifive_u.c
@@ -37,6 +37,7 @@
 #include "hw/riscv/riscv_hart.h"
 #include "hw/riscv/sifive_plic.h"
 #include "hw/riscv/sifive_clint.h"
+#include "hw/riscv/sifive_test.h"
 #include "hw/riscv/sifive_uart.h"
 #include "hw/riscv/sifive_prci.h"
 #include "hw/riscv/sifive_u.h"
@@ -57,6 +58,7 @@ static const struct MemmapEntry {
 } sifive_u_memmap[] = {
     [SIFIVE_U_DEBUG] =    {        0x0,      0x100 },
     [SIFIVE_U_MROM] =     {     0x1000,    0x11000 },
+    [SIFIVE_U_TEST] =     {   0x100000,     0x1000 },
     [SIFIVE_U_CLINT] =    {  0x2000000,    0x10000 },
     [SIFIVE_U_PLIC] =     {  0xc000000,  0x4000000 },
     [SIFIVE_U_UART0] =    { 0x10013000,     0x1000 },
@@ -226,6 +228,14 @@ static void create_fdt(SiFiveUState *s, const struct MemmapEntry *memmap,
     qemu_fdt_setprop_cells(fdt, nodename, "reg", 0x0);
     g_free(nodename);
 
+    nodename = g_strdup_printf("/soc/test@%lx",
+        (long)memmap[SIFIVE_U_TEST].base);
+    qemu_fdt_add_subnode(fdt, nodename);
+    qemu_fdt_setprop_string(fdt, nodename, "compatible", "sifive,test0");
+    qemu_fdt_setprop_cells(fdt, nodename, "reg",
+        0x0, memmap[SIFIVE_U_TEST].base,
+        0x0, memmap[SIFIVE_U_TEST].size);
+
     nodename = g_strdup_printf("/soc/uart@%lx",
         (long)memmap[SIFIVE_U_UART0].base);
     qemu_fdt_add_subnode(fdt, nodename);
@@ -385,6 +395,7 @@ static void riscv_sifive_u_soc_realize(DeviceState *dev, Error **errp)
     sifive_clint_create(memmap[SIFIVE_U_CLINT].base,
         memmap[SIFIVE_U_CLINT].size, ms->smp.cpus,
         SIFIVE_SIP_BASE, SIFIVE_TIMECMP_BASE, SIFIVE_TIME_BASE);
+    sifive_test_create(memmap[SIFIVE_U_TEST].base);
 
     for (i = 0; i < SIFIVE_U_PLIC_NUM_SOURCES; i++) {
         plic_gpios[i] = qdev_get_gpio_in(DEVICE(s->plic), i);
diff --git a/include/fpu/axspike.h b/include/fpu/axspike.h
new file mode 100644
index 0000000000..f3c29e278c
--- /dev/null
+++ b/include/fpu/axspike.h
@@ -0,0 +1,232 @@
+#ifndef AXSPIKE_H
+#define AXSPIKE_H
+
+#include <stdint.h>
+
+#include "fpu/flexfloat.h"
+#include "fpu/softfloat.h"
+
+
+#define DEBUG_OUT_CHANNEL stderr
+#define AXSPIKE_INFO(str) fprintf(DEBUG_OUT_CHANNEL, "----------------------------------------------------------------------------\n" \
+                                                     "AxSpike - INFO | " #str "\n"                                                    \
+                                                     "----------------------------------------------------------------------------\n")
+
+#define AXSPIKE_TODO(str) fprintf(DEBUG_OUT_CHANNEL, "----------------------------------------------------------------------------\n" \
+                                                     "AxSpike - @TODO | " #str "\n"                                                   \
+                                                     "----------------------------------------------------------------------------\n")
+
+
+#define FF_INIT_1(a, e, m, original_length) \
+  flexfloat_t ff_a, ff_res; \
+  flexfloat_desc_t env = (flexfloat_desc_t) {e,m}; \
+  ff_init(&ff_a, env); \
+  ff_init(&ff_res, env); \
+  flexfloat_set_bits(&ff_a, a);
+
+#define FF_INIT_1_double(a, e, m) \
+  uint64_t aa = a; \
+  flexfloat_t ff_a, ff_res; \
+  flexfloat_desc_t env = (flexfloat_desc_t) {e,m}; \
+  ff_init_double(&ff_a, *(double *)( &aa ), env); \
+  ff_init_double(&ff_res, 0.0, env);
+
+#define FF_INIT_1_float(a, e, m) \
+  uint32_t aa = a & 0xFFFFFFFF; \
+  flexfloat_t ff_a, ff_res; \
+  flexfloat_desc_t env = (flexfloat_desc_t) {e,m}; \
+  ff_init_float(&ff_a, *(float *)( &aa ), env); \
+  ff_init_float(&ff_res, 0.0f, env);
+
+#define FF_INIT_1_shift(a, e, m, original_length) \
+  uint64_t aa = a; \
+  uint8_t  shift_bits = original_length - 1 - e - m; \
+  aa = (aa >> shift_bits); \
+  flexfloat_t ff_a, ff_res; \
+  flexfloat_desc_t env = (flexfloat_desc_t) {e,m}; \
+  ff_init(&ff_a, env); \
+  ff_init(&ff_res, env); \
+  flexfloat_set_bits(&ff_a, aa);
+
+#define FF_INIT_2(a, b, e, m, original_length) \
+  flexfloat_t ff_a, ff_b, ff_res; \
+  flexfloat_desc_t env = (flexfloat_desc_t) {e,m}; \
+  ff_init(&ff_a, env); \
+  ff_init(&ff_b, env); \
+  ff_init(&ff_res, env); \
+  flexfloat_set_bits(&ff_a, a); \
+  flexfloat_set_bits(&ff_b, b);
+
+#define FF_INIT_2_double(a, b, e, m) \
+  uint64_t aa = a; uint64_t bb = b; \
+  flexfloat_t ff_a, ff_b, ff_res; \
+  flexfloat_desc_t env = (flexfloat_desc_t) {e,m}; \
+  ff_init_double(&ff_a, *(double *)( &aa ), env); \
+  ff_init_double(&ff_b, *(double *)( &bb ), env); \
+  ff_init_double(&ff_res, 0.0, env);
+
+#define FF_INIT_2_float(a, b, e, m) \
+  uint32_t aa = a & 0xFFFFFFFF; uint32_t bb = b & 0xFFFFFFFF; \
+  /* aa = aa & 0xFFFFFFFF */;  /* Floats are stored in the 32 bit LSBs */\
+  /* bb = bb & 0xFFFFFFFF */; /* Floats are stored in the 32 bit LSBs */\
+  flexfloat_t ff_a, ff_b, ff_res; \
+  flexfloat_desc_t env = (flexfloat_desc_t) {e,m}; \
+  ff_init_float(&ff_a, *(float *)( &aa ), env); \
+  ff_init_float(&ff_b, *(float *)( &bb ), env); \
+  ff_init_float(&ff_res, 0.0f, env);
+
+#define FF_INIT_2_shift(a, b, e, m, original_length) \
+  uint64_t aa = a; uint64_t bb = b; \
+  uint8_t  shift_bits = original_length - 1 - e - m; \
+  aa = (aa >> shift_bits); \
+  bb = (bb >> shift_bits); \
+  flexfloat_t ff_a, ff_b, ff_res; \
+  flexfloat_desc_t env = (flexfloat_desc_t) {e,m}; \
+  ff_init(&ff_a, env); \
+  ff_init(&ff_b, env); \
+  ff_init(&ff_res, env); \
+  flexfloat_set_bits(&ff_a, aa); \
+  flexfloat_set_bits(&ff_b, bb);
+
+#define FF_INIT_3(a, b, c, e, m, original_length) \
+  flexfloat_t ff_a, ff_b, ff_c, ff_res; \
+  flexfloat_desc_t env = (flexfloat_desc_t) {e,m}; \
+  ff_init(&ff_a, env); \
+  ff_init(&ff_b, env); \
+  ff_init(&ff_c, env); \
+  ff_init(&ff_res, env); \
+  flexfloat_set_bits(&ff_a, a); \
+  flexfloat_set_bits(&ff_b, b); \
+  flexfloat_set_bits(&ff_c, c);
+
+#define FF_INIT_3_double(a, b, c, e, m) \
+  uint64_t aa =a, bb = b, cc = c; \
+  flexfloat_t ff_a, ff_b, ff_c, ff_res; \
+  flexfloat_desc_t env = (flexfloat_desc_t) {e,m}; \
+  ff_init_double(&ff_a, *(double *)( &aa ), env); \
+  ff_init_double(&ff_b, *(double *)( &bb ), env); \
+  ff_init_double(&ff_c, *(double *)( &cc ), env); \
+  ff_init_double(&ff_res, 0.0, env);
+
+#define FF_INIT_3_float(a, b, c, e, m) \
+  uint32_t aa = a & 0xFFFFFFFF, bb = b& 0xFFFFFFFF, cc = c & 0xFFFFFFFF; \
+  flexfloat_t ff_a, ff_b, ff_c, ff_res; \
+  flexfloat_desc_t env = (flexfloat_desc_t) {e,m}; \
+  ff_init_float(&ff_a, *(float *)( &aa ), env); \
+  ff_init_float(&ff_b, *(float *)( &bb ), env); \
+  ff_init_float(&ff_c, *(float *)( &cc ), env); \
+  ff_init_float(&ff_res, 0.0f, env);
+
+#define FF_INIT_3_shift(a, b, c, e, m, original_length) \
+  uint64_t aa =a, bb = b, cc = c; \
+  uint8_t  shift_bits = original_length - 1 - e - m; \
+  aa = (aa >> shift_bits); \
+  bb = (bb >> shift_bits); \
+  cc = (cc >> shift_bits); \
+  flexfloat_t ff_a, ff_b, ff_c, ff_res; \
+  flexfloat_desc_t env = (flexfloat_desc_t) {e,m}; \
+  ff_init(&ff_a, env); \
+  ff_init(&ff_b, env); \
+  ff_init(&ff_c, env); \
+  ff_init(&ff_res, env); \
+  flexfloat_set_bits(&ff_a, aa); \
+  flexfloat_set_bits(&ff_b, bb); \
+  flexfloat_set_bits(&ff_c, cc);
+
+#define FF_EXEC_1(s, name, a, e, m, original_length) \
+  FF_INIT_(a, e, m, original_length) \
+  feclearexcept(FE_ALL_EXCEPT); \
+  name(&ff_res, &ff_a); \
+  update_fflags_fenv(s); \
+  return flexfloat_get_bits(&ff_res);
+
+#define FF_EXEC_2(s, name, a, b, e, m, original_length) \
+  FF_INIT_2(a, b, e, m, original_length) \
+  feclearexcept(FE_ALL_EXCEPT); \
+  name(&ff_res, &ff_a, &ff_b); \
+  update_fflags_fenv(s); \
+  return flexfloat_get_bits(&ff_res);
+
+#define FF_EXEC_2_double(s, name, a, b, e, m) \
+  FF_INIT_2_double(a, b, e, m) \
+  feclearexcept(FE_ALL_EXCEPT); \
+  name(&ff_res, &ff_a, &ff_b); \
+  update_fflags_fenv(s); \
+  double res_double = ff_get_double(&ff_res); \
+  return (*(uint64_t *)( &res_double ));
+
+#define FF_EXEC_2_float(s, name, a, b, e, m) \
+  FF_INIT_2_float(a, b, e, m) \
+  feclearexcept(FE_ALL_EXCEPT); \
+  name(&ff_res, &ff_a, &ff_b); \
+  update_fflags_fenv(s); \
+  float res_float = ff_get_float(&ff_res); \
+  return (*(uint32_t *)( &res_float ));  
+
+#define FF_EXEC_2_shift(s, name, a, b, e, m, original_length) \
+  FF_INIT_2_shift(a, b, e, m, original_length) \
+  feclearexcept(FE_ALL_EXCEPT); \
+  name(&ff_res, &ff_a, &ff_b); \
+  update_fflags_fenv(s); \
+  return (flexfloat_get_bits(&ff_res) << shift_bits); /* [1|   e  |  m  |  ... zeroes ...] */
+
+#define FF_EXEC_3(s, name, a, b, c, e, m, original_length) \
+  FF_INIT_3(a, b, c, e, m, original_length) \
+  feclearexcept(FE_ALL_EXCEPT); \
+  name(&ff_res, &ff_a, &ff_b, &ff_c); \
+  update_fflags_fenv(s); \
+  return flexfloat_get_bits(&ff_res);
+
+#define FF_EXEC_3_double(s, name, a, b, c, e, m) \
+  FF_INIT_3_double(a, b, c, e, m) \
+  feclearexcept(FE_ALL_EXCEPT); \
+  name(&ff_res, &ff_a, &ff_b, &ff_c); \
+  update_fflags_fenv(s); \
+  double res_double = ff_get_double(&ff_res); \
+  return (*(uint64_t *)( &res_double ));  
+
+#define FF_EXEC_3_float(s, name, a, b, c, e, m) \
+  FF_INIT_3_float(a, b, c, e, m) \
+  feclearexcept(FE_ALL_EXCEPT); \
+  name(&ff_res, &ff_a, &ff_b, &ff_c); \
+  update_fflags_fenv(s); \
+  float res_float = ff_get_float(&ff_res); \
+  return (*(uint32_t *)( &res_float ));  
+
+#define FF_EXEC_3_shift(s, name, a, b, c, e, m, original_length) \
+  FF_INIT_3_shift(a, b, c, e, m, original_length) \
+  feclearexcept(FE_ALL_EXCEPT); \
+  name(&ff_res, &ff_a, &ff_b, &ff_c); \
+  update_fflags_fenv(s); \
+  return (flexfloat_get_bits(&ff_res) << shift_bits); /* [1|   e  |  m  |  ... zeroes ...] */
+
+// FlexFloat decs
+
+uint64_t QEMU_FLATTEN 
+lib_flexfloat_madd_round(uint64_t a, uint64_t b, uint64_t c, CPURISCVState *cpuenv, uint8_t e, uint8_t m, uint8_t original_length);
+uint64_t QEMU_FLATTEN 
+lib_flexfloat_msub_round(uint64_t a, uint64_t b, uint64_t c, CPURISCVState *cpuenv, uint8_t e, uint8_t m, uint8_t original_length);
+uint64_t QEMU_FLATTEN 
+lib_flexfloat_nmsub_round(uint64_t a, uint64_t b, uint64_t c, CPURISCVState *cpuenv, uint8_t e, uint8_t m, uint8_t original_length);
+uint64_t QEMU_FLATTEN 
+lib_flexfloat_nmadd_round(uint64_t a, uint64_t b, uint64_t c, CPURISCVState *cpuenv, uint8_t e, uint8_t m, uint8_t original_length);
+
+uint64_t QEMU_FLATTEN 
+lib_flexfloat_add_round(uint64_t a, uint64_t b, CPURISCVState *cpuenv, uint8_t e, uint8_t m, uint8_t original_length);
+uint64_t QEMU_FLATTEN 
+lib_flexfloat_sub_round(uint64_t a, uint64_t b, CPURISCVState *cpuenv, uint8_t e, uint8_t m, uint8_t original_length);
+
+uint64_t QEMU_FLATTEN 
+lib_flexfloat_mul_round(uint64_t a, uint64_t b, CPURISCVState *cpuenv, uint8_t e, uint8_t m, uint8_t original_length);
+uint64_t QEMU_FLATTEN 
+lib_flexfloat_div_round(uint64_t a, uint64_t b, CPURISCVState *cpuenv, uint8_t e, uint8_t m, uint8_t original_length);
+
+// SQRT for D extension
+uint64_t QEMU_FLATTEN 
+lib_flexfloat_sqrt_round(uint64_t a, CPURISCVState *cpuenv, uint8_t e, uint8_t m, uint8_t original_length);
+
+// SQRT for F extension
+uint64_t QEMU_FLATTEN 
+lib_flexfloat_sqrtf_round(uint64_t a, CPURISCVState *cpuenv, uint8_t e, uint8_t m, uint8_t original_length);
+
+#endif // AXSPIKE_H
\ No newline at end of file
diff --git a/include/fpu/axspike.h_BCKP b/include/fpu/axspike.h_BCKP
new file mode 100644
index 0000000000..659e1059e1
--- /dev/null
+++ b/include/fpu/axspike.h_BCKP
@@ -0,0 +1,48 @@
+#ifndef AXSPIKE_H
+#define AXSPIKE_H
+
+#include <stdint.h>
+
+#include "fpu/flexfloat.h"
+#include "fpu/softfloat.h"
+
+
+#define DEBUG_OUT_CHANNEL stderr
+#define AXSPIKE_INFO(str) fprintf(DEBUG_OUT_CHANNEL, "----------------------------------------------------------------------------\n" \
+                                                     "AxSpike - INFO | " #str "\n"                                                    \
+                                                     "----------------------------------------------------------------------------\n")
+
+#define AXSPIKE_TODO(str) fprintf(DEBUG_OUT_CHANNEL, "----------------------------------------------------------------------------\n" \
+                                                     "AxSpike - @TODO | " #str "\n"                                                   \
+                                                     "----------------------------------------------------------------------------\n")
+
+
+typedef struct
+{
+  uint16_t v;
+} float16_t;
+typedef struct
+{
+  uint32_t v;
+} float32_t;
+typedef struct
+{
+  uint64_t v;
+} float64_t;
+typedef struct
+{
+  uint64_t v[2];
+} float128_t;
+
+
+
+float64_t f64_add_d_custom(float64_t frs1, float64_t frs2, float_status *status);
+float64_t f64_sub_d_custom(float64_t frs1, float64_t frs2, float_status *status);
+float64_t f64_mul_d_custom(float64_t frs1, float64_t frs2, float_status *status);
+
+float64_t f64_madd_d_custom(float64_t frs1, float64_t frs2, float64_t frs3, float_status *status);
+float64_t f64_sqrt_d_custom(float64_t frs1, float_status *status);
+float64_t f64_div_d_custom(float64_t frs1, float64_t frs2, float_status *status);
+
+
+#endif // AXSPIKE_H
\ No newline at end of file
diff --git a/include/fpu/flexfloat.h b/include/fpu/flexfloat.h
new file mode 100644
index 0000000000..da4ce43084
--- /dev/null
+++ b/include/fpu/flexfloat.h
@@ -0,0 +1,345 @@
+/*
+   Copyright 2018 - The OPRECOMP Project Consortium, Alma Mater Studiorum
+   Universit√† di Bologna. All rights reserved.
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
+*/
+
+/* C++ */
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#ifndef flexfloat_h
+#define flexfloat_h 1
+
+#include "flexfloat_config.h"
+
+#include <stdint.h>
+#include <stdbool.h>
+#include <stdio.h>
+
+// If not specified with FLEXFLOAT_NO_ROUNDING flag, rounding is active
+#ifndef FLEXFLOAT_NO_ROUNDING
+#define FLEXFLOAT_ROUNDING
+#endif
+
+// Enable FP environment access for rounding and flags
+#if defined(FLEXFLOAT_ROUNDING) || defined(FLEXFLOAT_FLAGS)
+#include <fenv.h>
+// @TODO This pragma is only supported by C++11
+// #pragma STDC FENV_ACCESS ON
+#endif
+
+#ifndef __STDC_IEC_559__
+#error "Implementation not IEEE compliant"
+#endif
+
+// GCC versions before 8.2 (for sure not on 7.2, don't know when it was fixed) don't raise flags on comparisons correctly
+#if !defined(__GNUC__) || (defined(__GNUC__) && (__GNUC__ >= 8) && (__GNUC_MINOR__ >= 2))
+#define FLEXFLOAT_CORRECT_CMP_FLAGS 1
+#endif
+
+// Backend value precision
+#if !defined(FLEXFLOAT_ON_SINGLE) && !defined(FLEXFLOAT_ON_DOUBLE) && !defined(FLEXFLOAT_ON_QUAD)
+#error "A backend type must be specified (FLEXFLOAT_ON_SINGLE, FLEXFLOAT_ON_DOUBLE or FLEXFLOAT_ON_QUAD)"
+#endif
+
+#ifdef FLEXFLOAT_ON_SINGLE
+#define UINT_C UINT32_C
+#define MASK_FRAC (UINT32_C(0x007FFFFF))
+#define MASK_FRAC_MSB (UINT32_C(0x00800000))
+#define MASK_FRAC_EXCEPT_MSB (UINT32_C(0x003FFFFF))
+#define SMALLEST_NORM_POS (0x00800000)
+#define SMALLEST_NORM_NEG (0x80800000)
+#define INF_EXP (0xFF)
+#define BIAS (127)
+#define NUM_BITS (32)
+#define NUM_BITS_EXP (8)
+#define NUM_BITS_FRAC (23)
+typedef int32_t int_t;
+typedef uint32_t uint_t;
+typedef float fp_t;
+#define PRINTF_FORMAT "%.7f"
+#endif /* FLEXFLOAT_ON_SINGLE */
+
+#ifdef FLEXFLOAT_ON_DOUBLE
+#define UINT_C UINT64_C
+#define MASK_FRAC (UINT64_C(0x000FFFFFFFFFFFFF))
+#define MASK_FRAC_MSB (UINT64_C(0x0010000000000000))
+#define MASK_FRAC_EXCEPT_MSB (UINT64_C(0x0007FFFFFFFFFFFF))
+#define SMALLEST_NORM_POS (0x0010000000000000)
+#define SMALLEST_NORM_NEG (0x8010000000000000)
+#define INF_EXP (0x7FF)
+#define BIAS (1023)
+#define NUM_BITS (64)
+#define NUM_BITS_EXP (11)
+#define NUM_BITS_FRAC (52)
+typedef int64_t int_t;
+typedef uint64_t uint_t;
+typedef double fp_t;
+#define PRINTF_FORMAT "%.18f"
+#endif /* FLEXFLOAT_ON_DOUBLE */
+
+#ifdef FLEXFLOAT_ON_QUAD
+#include <quadmath.h>
+typedef __int128 int128_t;
+typedef unsigned __int128 uint128_t;
+#define UINT_C(c) ((uint128_t)c)
+static uint64_t mask_frac_value[2] = {0xFFFFFFFFFFFFFFFF, 0x0000FFFFFFFFFFFF};
+#define MASK_FRAC (*((uint128_t *)(&(mask_frac_value))))
+static uint64_t mask_frac_msb_value[2] = {0x0000000000000000, 0x0001000000000000};
+#define MASK_FRAC_MSB (*((uint128_t *)(&(mask_frac_msb_value))))
+static uint64_t mask_frac_except_msb_value[2] = {0xFFFFFFFFFFFFFFFF, 0x00007FFFFFFFFFFF};
+#define MASK_FRAC_EXCEPT_MSB (*((uint128_t *)(&(mask_frac_except_msb_value))))
+static uint64_t smallest_norm_pos_value[2] = {0x0000000000000000, 0x0001000000000000};
+#define SMALLEST_NORM_POS (*((uint128_t *)(&(smallest_norm_pos_value))))
+static uint64_t smallest_norm_neg_value[2] = {0x0000000000000000, 0x8001000000000000};
+#define SMALLEST_NORM_NEG (*((uint128_t *)(&(smallest_norm_neg_value))))
+#define INF_EXP (0x7FFF)
+#define BIAS (16383)
+#define NUM_BITS (128)
+#define NUM_BITS_EXP (15)
+#define NUM_BITS_FRAC (112)
+typedef int128_t int_t;
+typedef uint128_t uint_t;
+typedef __float128 fp_t;
+#define PRINTF_FORMAT "%.38Lf"
+#endif /* FLEXFLOAT_ON_QUAD */
+
+// Check support for exception flags if enabled
+#ifdef FLEXFLOAT_FLAGS
+#if FE_ALL_EXCEPT == 0
+#error "Exception flags were enabled with FLEXFLOAT_FLAGS, however the implementation does not support floating-point exceptions"
+#elif !defined(FE_DIVBYZERO)
+#error "Exception flags were enabled with FLEXFLOAT_FLAGS, however the implementation does not support FE_DIVBYZERO"
+#elif !defined(FE_INEXACT)
+#error "Exception flags were enabled with FLEXFLOAT_FLAGS, however the implementation does not support FE_INEXACT"
+#elif !defined(FE_INVALID)
+#error "Exception flags were enabled with FLEXFLOAT_FLAGS, however the implementation does not support FE_INVALID"
+#elif !defined(FE_OVERFLOW)
+#error "Exception flags were enabled with FLEXFLOAT_FLAGS, however the implementation does not support FE_OVERFLOW"
+#elif !defined(FE_UNDERFLOW)
+#error "Exception flags were enabled with FLEXFLOAT_FLAGS, however the implementation does not support FE_UNDERFLOW"
+#endif
+#endif
+
+// Helper macros
+
+#define SIGN( a ) ((bool) ((uint_t) (a)>>(NUM_BITS-1)))
+#define EXPONENT( a ) ((int_fast16_t) ((uint_t) (a)>>NUM_BITS_FRAC) & INF_EXP)
+#define PACK( sign, exp, sig ) ((uint_t) (((uint_t) (sign)<<(NUM_BITS-1)) + ((uint_t) (exp)<<NUM_BITS_FRAC) + (sig)))
+
+#define CAST_TO_INT(d) (*((int_t *)(&(d))))
+#define CAST_TO_UINT(d) (*((uint_t *)(&(d))))
+#define CAST_TO_FP(d) (*((fp_t *)(&(d))))
+
+#ifndef INLINE
+#define INLINE inline
+#endif
+
+
+// Types
+
+struct _flexfloat_t;
+typedef struct _flexfloat_t flexfloat_t;
+typedef void (*ff_function_p)(flexfloat_t *, void *);
+
+typedef struct _flexfloat_desc_t {
+    uint8_t exp_bits;
+    uint8_t frac_bits;
+} flexfloat_desc_t;
+
+struct _flexfloat_t {
+    fp_t value;
+#ifdef FLEXFLOAT_TRACKING
+    fp_t exact_value;
+    ff_function_p tracking_fn;
+    void * tracking_arg;
+#endif
+    flexfloat_desc_t desc;
+};
+
+
+// Helper functions
+
+static inline int_fast16_t flexfloat_inf_exp(const flexfloat_desc_t desc)
+{
+    return (int_fast16_t) (((int_fast16_t)1 << desc.exp_bits) - 1);
+}
+
+static inline int_fast16_t flexfloat_bias(const flexfloat_desc_t desc)
+{
+    return (int_fast16_t) (((int_fast16_t)1 << (desc.exp_bits - 1)) - 1);
+}
+
+static inline bool flexfloat_sign(const flexfloat_t *a)
+{
+    return (CAST_TO_INT(a->value)) >> (NUM_BITS-1);
+}
+
+int_fast16_t flexfloat_exp(const flexfloat_t *a);
+uint_t flexfloat_frac(const flexfloat_t *a);
+uint_t flexfloat_denorm_frac(const flexfloat_t *a, int_fast16_t exp);
+uint_t flexfloat_pack(flexfloat_desc_t desc, bool sign, int_fast16_t exp, uint_t frac);
+void flexfloat_sanitize(flexfloat_t *a);
+
+
+// Bit-level access
+
+uint_t flexfloat_pack_bits(flexfloat_desc_t desc, uint_t bits);
+void flexfloat_set_bits(flexfloat_t *a, uint_t bits);
+uint_t flexfloat_get_bits(flexfloat_t *a);
+uint_t flexfloat_denorm_pack(flexfloat_desc_t desc, bool sign, uint_t frac);
+
+// Constructors
+
+void ff_init(flexfloat_t *obj, flexfloat_desc_t desc);
+void ff_init_float(flexfloat_t *obj, float value, flexfloat_desc_t desc);
+void ff_init_double(flexfloat_t *obj, double value, flexfloat_desc_t desc);
+void ff_init_longdouble(flexfloat_t *obj, long double value, flexfloat_desc_t desc);
+void ff_init_float128(flexfloat_t *obj, __float128 value, flexfloat_desc_t desc);
+void ff_init_int(flexfloat_t *obj, int value, flexfloat_desc_t desc);
+void ff_init_long(flexfloat_t *obj, long value, flexfloat_desc_t desc);
+void ff_cast(flexfloat_t *obj, const flexfloat_t *source, flexfloat_desc_t desc);
+
+// Casts
+
+float ff_get_float(const flexfloat_t *obj);
+double ff_get_double(const flexfloat_t *obj);
+long double ff_get_longdouble(const flexfloat_t *obj);
+__float128 ff_get_float128(const flexfloat_t *obj);
+
+
+// Artihmetic operators
+
+void ff_inverse(flexfloat_t *dest, const flexfloat_t *a);
+void ff_add(flexfloat_t *dest, const flexfloat_t *a, const flexfloat_t *b);
+void ff_sub(flexfloat_t *dest, const flexfloat_t *a, const flexfloat_t *b);
+void ff_mul(flexfloat_t *dest, const flexfloat_t *a, const flexfloat_t *b);
+void ff_div(flexfloat_t *dest, const flexfloat_t *a, const flexfloat_t *b);
+void ff_acc(flexfloat_t *dest, const flexfloat_t *a);
+void ff_min(flexfloat_t *dest, const flexfloat_t *a, const flexfloat_t *b);
+void ff_max(flexfloat_t *dest, const flexfloat_t *a, const flexfloat_t *b);
+void ff_fma(flexfloat_t *dest, const flexfloat_t *a, const flexfloat_t *b, const flexfloat_t *c);
+
+
+// Relational operators
+
+bool ff_eq(const flexfloat_t *a, const flexfloat_t *b);
+bool ff_neq(const flexfloat_t *a, const flexfloat_t *b);
+bool ff_le(const flexfloat_t *a, const flexfloat_t *b);
+bool ff_lt(const flexfloat_t *a, const flexfloat_t *b);
+bool ff_ge(const flexfloat_t *a, const flexfloat_t *b);
+bool ff_gt(const flexfloat_t *a, const flexfloat_t *b);
+
+
+// Collection of statistics
+
+#ifdef FLEXFLOAT_STATS
+
+#ifndef FLEXFLOAT_STATS_MAX_TYPES
+#define FLEXFLOAT_STATS_MAX_TYPES 128
+#endif
+
+typedef struct {
+    uint32_t key;
+    void    *value;
+} HashSlot;
+
+extern bool StatsEnabled;
+extern HashSlot   op_stats[FLEXFLOAT_STATS_MAX_TYPES];
+extern HashSlot cast_stats[FLEXFLOAT_STATS_MAX_TYPES*FLEXFLOAT_STATS_MAX_TYPES];
+
+void * ht_search(HashSlot* hashArray, uint32_t hashIndex, uint32_t key, uint32_t arraySize);
+void ht_insert(HashSlot* hashArray, uint32_t hashIndex, uint32_t key, void *value, uint32_t arraySize);
+
+typedef struct {
+    uint64_t minus;
+    uint64_t add;
+    uint64_t sub;
+    uint64_t mul;
+    uint64_t div;
+    uint64_t minmax;
+    uint64_t fma;
+    uint64_t cmp;
+} OpStats;
+
+typedef struct {
+    uint64_t total;
+} CastStats;
+
+typedef struct __attribute__((__packed__))  {
+    uint8_t exp_bits1;
+    uint8_t frac_bits1;
+    uint8_t exp_bits2;
+    uint8_t frac_bits2;
+} KeyStruct;
+
+static inline uint32_t precision_hash (const flexfloat_desc_t desc)
+{
+    return desc.exp_bits ^ (desc.frac_bits << 8);
+}
+
+static inline uint32_t precision_hash2 (const flexfloat_desc_t desc1, const flexfloat_desc_t desc2)
+{
+    return desc1.exp_bits ^ (desc1.frac_bits << 8) ^ (desc2.exp_bits << 16) ^ (desc2.frac_bits << 24);
+}
+
+OpStats * getOpStats(const flexfloat_desc_t desc);
+CastStats * getCastStats(const flexfloat_desc_t desc1, const flexfloat_desc_t desc2);
+
+void ff_start_stats(void);
+void ff_stop_stats(void);
+void ff_clear_stats(void);
+void ff_print_stats(void);
+
+#endif /* FLEXFLOAT_STATS */
+
+
+// Advanced tracking support
+
+#ifdef FLEXFLOAT_TRACKING
+
+static inline fp_t ff_track_get_exact (const flexfloat_t *a) {
+    return a->exact_value;
+}
+
+static inline fp_t ff_track_get_error (const flexfloat_t *a) {
+    return a->value - a->exact_value;
+}
+
+static inline void ff_track_callback (flexfloat_t *a, ff_function_p fn, void *arg ) {
+    a->tracking_fn = fn;
+    a->tracking_arg = arg;
+}
+
+#endif /* FLEXFLOAT_TRACKING */
+
+// Rounding stuff
+#ifdef FLEXFLOAT_ROUNDING
+
+bool flexfloat_round_bit(const flexfloat_t *a, int_fast16_t exp);
+bool flexfloat_sticky_bit(const flexfloat_t *a, int_fast16_t exp);
+bool flexfloat_nearest_rounding(const flexfloat_t *a, int_fast16_t exp);
+bool flexfloat_inf_rounding(const flexfloat_t *a, int_fast16_t exp, bool sign, bool plus);
+int_t flexfloat_rounding_value(const flexfloat_t *a, int_fast16_t exp, bool sign);
+
+#endif /* FLEXFLOAT_ROUNDING */
+
+#endif
+
+/* C++ */
+#ifdef __cplusplus
+}
+#endif
diff --git a/include/fpu/flexfloat_config.h b/include/fpu/flexfloat_config.h
new file mode 100644
index 0000000000..88d8b4305e
--- /dev/null
+++ b/include/fpu/flexfloat_config.h
@@ -0,0 +1,5 @@
+#define FLEXFLOAT_ON_DOUBLE
+#define FLEXFLOAT_FLAGS
+// #define FLEXFLOAT_STATS
+// #define FLEXFLOAT_TRACKING
+// #define FLEXFLOAT_NO_ROUNDING
diff --git a/include/hw/riscv/sifive_e.h b/include/hw/riscv/sifive_e.h
index 9c868dd7f9..8105626843 100644
--- a/include/hw/riscv/sifive_e.h
+++ b/include/hw/riscv/sifive_e.h
@@ -50,6 +50,7 @@ enum {
     SIFIVE_E_DEBUG,
     SIFIVE_E_MROM,
     SIFIVE_E_OTP,
+    SIFIVE_E_TEST,
     SIFIVE_E_CLINT,
     SIFIVE_E_PLIC,
     SIFIVE_E_AON,
diff --git a/include/hw/riscv/sifive_u.h b/include/hw/riscv/sifive_u.h
index be021ce256..53f4c8fd16 100644
--- a/include/hw/riscv/sifive_u.h
+++ b/include/hw/riscv/sifive_u.h
@@ -49,6 +49,7 @@ typedef struct SiFiveUState {
 enum {
     SIFIVE_U_DEBUG,
     SIFIVE_U_MROM,
+    SIFIVE_U_TEST,
     SIFIVE_U_CLINT,
     SIFIVE_U_PLIC,
     SIFIVE_U_UART0,
diff --git a/include/qemu-common.h b/include/qemu-common.h
index 0235cd3b91..5215962c80 100644
--- a/include/qemu-common.h
+++ b/include/qemu-common.h
@@ -18,7 +18,7 @@
 
 /* Bug reporting information for --help arguments, About dialogs, etc */
 #define QEMU_HELP_BOTTOM \
-    "See <https://qemu.org/contribute/report-a-bug> for how to report bugs.\n" \
+    "For bug reports: https://github.com/sifive/freedom-tools/issues\n" \
     "More information on the QEMU project at <https://qemu.org>."
 
 /* main function, renamed */
diff --git a/linux-user/main.c b/linux-user/main.c
index 560d053f72..3d1c761e0a 100644
--- a/linux-user/main.c
+++ b/linux-user/main.c
@@ -59,6 +59,26 @@ unsigned long mmap_min_addr;
 unsigned long guest_base;
 int have_guest_base;
 
+/*  @AXSPIKE AxSpike-Related information 
+ */
+// ax_mode_t ax_mode;
+#include "fpu/flexfloat.h"
+extern uint8_t exp_bits_d;
+extern uint8_t frac_bits_d;
+extern uint8_t exp_bits_f;
+extern uint8_t frac_bits_f;
+extern FILE    *binary_test_vector_file;
+
+extern uint64_t non_approx_region_start;
+extern uint64_t non_approx_region_size;
+
+extern uint8_t enable_binary_test_vector;
+
+// extern uint8_t shift_bits;
+// uint64_t input_mask;
+// uint64_t output_mask;
+// extern flexfloat_desc_t vpfpu_config_64;
+
 /*
  * When running 32-on-64 we should make sure we can fit all of the possible
  * guest address space into a contiguous chunk of virtual host memory.
@@ -398,6 +418,47 @@ static void handle_arg_abi_call0(const char *arg)
 }
 #endif
 
+#if defined(TARGET_RISCV)
+static void handle_arg_expbits_d(const char *arg)
+{
+    exp_bits_d = (uint8_t)atoi(arg);
+    // shift_bits = 64 - 1 - exp_bits_d - frac_bits_d; // update anyway
+}
+
+static void handle_arg_fracbits_d(const char *arg)
+{
+    frac_bits_d = (uint8_t)atoi(arg);
+    // shift_bits = 64 - 1 - exp_bits_d - frac_bits_d; // update anyway
+}
+
+static void handle_arg_expbits_f(const char *arg)
+{
+    exp_bits_f = (uint8_t)atoi(arg);
+    // shift_bits = 64 - 1 - exp_bits_f - frac_bits_f; // update anyway
+}
+
+static void handle_arg_fracbits_f(const char *arg)
+{
+    frac_bits_f = (uint8_t)atoi(arg);
+    // shift_bits = 64 - 1 - exp_bits_f - frac_bits_f; // update anyway
+}
+
+static void handle_arg_non_approx_region_start(const char *arg)
+{
+    non_approx_region_start = (uint64_t)strtol(arg, NULL, 16); // (arg);
+}
+
+static void handle_arg_non_approx_region_size(const char *arg)
+{
+    non_approx_region_size = (uint64_t)strtol(arg, NULL, 16); //atol(arg);
+}
+
+// static void handle_arg_axmode(const char *arg)
+// {
+//     axmode = (uint8_t)atoi(arg);
+// }
+#endif
+
 struct qemu_argument {
     const char *argv;
     const char *env;
@@ -454,6 +515,20 @@ static const struct qemu_argument arg_table[] = {
 #if defined(TARGET_XTENSA)
     {"xtensa-abi-call0", "QEMU_XTENSA_ABI_CALL0", false, handle_arg_abi_call0,
      "",           "assume CALL0 Xtensa ABI"},
+#endif
+#if defined(TARGET_RISCV)
+    {"expbitsd",          "",         true,  handle_arg_expbits_d,
+     "<EXP_BITS_d>",       "The FPU exponent bit-width for the D extension. Default is 11"},
+    {"fracbitsd",          "",         true,  handle_arg_fracbits_d,
+     "<FRAC_BITS_d>",       "The FPU fraction bit-width for the D extension. Default is 52"},
+    {"expbitsf",          "",         true,  handle_arg_expbits_f,
+     "<EXP_BITS_f>",       "The FPU exponent bit-width for the F extension. Default is 8"},
+    {"fracbitsf",          "",         true,  handle_arg_fracbits_f,
+     "<FRAC_BITS_f>",       "The FPU fraction bit-width for the F extension. Default is 23"},
+    {"non_approx_region_start",          "",         true,  handle_arg_non_approx_region_start,
+     "<@ADDR>",       "The Start address of a non-approximable (.evaluator) region."},
+    {"non_approx_region_size",          "",         true,  handle_arg_non_approx_region_size,
+     "<@ADDR>",       "The Size (in Bytes) of a non-approximable (.evaluator) region."},
 #endif
     {NULL, NULL, false, NULL, NULL, NULL}
 };
@@ -646,6 +721,10 @@ int main(int argc, char **argv, char **envp)
 
     optind = parse_args(argc, argv);
 
+    // @AXSPIKE_TEST Here all the args are supposed to be parsed.
+    // printf("@AXSPIKE_TEST   Expbitsd = %d    Fracbitsd = %d", exp_bits_d, frac_bits_d);
+    // exit(-1);
+
     if (!trace_init_backends()) {
         exit(1);
     }
@@ -836,6 +915,41 @@ int main(int argc, char **argv, char **envp)
 
     target_cpu_copy_regs(env, regs);
 
+    // @AXSPIKE : ensure that exp and frac bit-widths aren't zeroes.
+    if ((!exp_bits_d) || (!frac_bits_d) || (!exp_bits_f) || (!frac_bits_f))
+    {
+        fprintf(stderr, "Exp_Bits_d = %d         Frac_Bits_d = %d\n", exp_bits_d, frac_bits_d);
+        fprintf(stderr, "Exp_Bits_f = %d         Frac_Bits_f = %d\n", exp_bits_f, frac_bits_f);
+        fprintf(stderr, "neither of the FPU parameters should be equal to zero.\n");
+        exit(-1);
+    } else {
+        fprintf(stderr, "# AXQEMU[ linux user mode ]: Exp_Bits_d = %d         Frac_Bits_d = %d\n", exp_bits_d, frac_bits_d);
+        fprintf(stderr, "#                           Exp_Bits_f = %d         Frac_Bits_f = %d\n", exp_bits_f, frac_bits_f);
+    }
+
+    if( enable_binary_test_vector )
+    {
+        char filename[100] = {0};
+        sprintf(filename, "binary_test_vector_expf%02d_fracf%02d_expd%02d_fracd%02d.bin", exp_bits_f, frac_bits_f, exp_bits_d, frac_bits_d);
+        if ((binary_test_vector_file = fopen(filename, "wb")) != NULL) {
+            fprintf(stderr, "# Dumping binary test vectors ACTIVE, output file: < %s > \n", filename);
+        }
+    } else {
+        fprintf(stderr, "# Binary test vector dumping is DEACTIVATED.\n");
+    }
+
+    // @AXSPIKE : ensure that Non-Approximable Regions parameters are non-zeroes.
+    if ((non_approx_region_start == 0) && (non_approx_region_size == 0))
+    {
+        fprintf(stderr, "# No .evaluator region is specified. The approximation will be applied on the whole application.\n");
+    }
+    else {
+        fprintf(stderr, "# Non approximable region defined.\n"
+                        "# Start addr = %016lX\n"
+                        "# End   addr = %016lX\n"
+                        "# Size       = %ld Bytes\n", non_approx_region_start, non_approx_region_start + non_approx_region_size, non_approx_region_size);
+    }
+
     if (gdbstub_port) {
         if (gdbserver_start(gdbstub_port) < 0) {
             fprintf(stderr, "qemu: could not open gdbserver on port %d\n",
diff --git a/qemu-options.hx b/qemu-options.hx
index bbfd936d29..a33109ce01 100644
--- a/qemu-options.hx
+++ b/qemu-options.hx
@@ -3605,6 +3605,38 @@ within gdb and establish the connection via a pipe:
 @end example
 ETEXI
 
+DEF("expbitsd", HAS_ARG, QEMU_OPTION_expbitsd, \
+    "-expbitsd expbitwidthd     Set exponent bitwidth of the FPU to val\n", QEMU_ARCH_RISCV)
+STEXI
+@item -expbitsd @var{expbitwidthd}
+@findex -expbitsd
+Set the exponent bitwidth to @var{expbitwidthd}.
+ETEXI
+
+DEF("fracbitsd", HAS_ARG, QEMU_OPTION_fracbitsd, \
+    "--fracbitsd fracbitwidthd     Set fraction bitwidth of the FPU to val\n", QEMU_ARCH_RISCV)
+STEXI
+@item -fracbitsd @var{fracbitwidthd}
+@findex -fracbitsd
+Set the exponent bitwidth to @var{fracbitwidthd}.
+ETEXI
+
+DEF("expbitsf", HAS_ARG, QEMU_OPTION_expbitsf, \
+    "-expbitsf expbitwidthf     Set exponent bitwidth of the FPU to val\n", QEMU_ARCH_RISCV)
+STEXI
+@item -expbitsf @var{expbitwidthf}
+@findex -expbitsf
+Set the exponent bitwidth to @var{expbitwidthf}.
+ETEXI
+
+DEF("fracbitsf", HAS_ARG, QEMU_OPTION_fracbitsf, \
+    "--fracbitsf fracbitwidthf     Set fraction bitwidth of the FPU to val\n", QEMU_ARCH_RISCV)
+STEXI
+@item -fracbitsf @var{fracbitwidthf}
+@findex -fracbitsf
+Set the exponent bitwidth to @var{fracbitwidthf}.
+ETEXI
+
 DEF("s", 0, QEMU_OPTION_s, \
     "-s              shorthand for -gdb tcp::" DEFAULT_GDBSTUB_PORT "\n",
     QEMU_ARCH_ALL)
diff --git a/scripts/analyze-inclusions b/scripts/analyze-inclusions
index 14806e18c6..2fb10454be 100644
--- a/scripts/analyze-inclusions
+++ b/scripts/analyze-inclusions
@@ -56,6 +56,7 @@ echo $(grep_include -F 'qom/object.h') files include qom/object.h
 echo $(grep_include -F 'block/aio.h') files include block/aio.h
 echo $(grep_include -F 'exec/memory.h') files include exec/memory.h
 echo $(grep_include -F 'fpu/softfloat.h') files include fpu/softfloat.h
+echo $(grep_include -F 'fpu/flexfloat.h') files include fpu/flexfloat.h
 echo $(grep_include -F 'qemu/bswap.h') files include qemu/bswap.h
 echo
 
diff --git a/target/riscv/cpu_bits.h b/target/riscv/cpu_bits.h
index 11f971ad5d..d98bab47db 100644
--- a/target/riscv/cpu_bits.h
+++ b/target/riscv/cpu_bits.h
@@ -48,6 +48,12 @@
 #define CSR_FRM             0x002
 #define CSR_FCSR            0x003
 
+/* User, Non-Standard Variable Precision in Time CSRs */
+#define CSR_FVPT_STATUS     0x800
+#define CSR_FVPT_PREC_F     0x801
+#define CSR_FVPT_PREC_D     0x802
+#define CSR_FVPT_EXEC_MODE  0x803
+
 /* User Timers and Counters */
 #define CSR_CYCLE           0xc00
 #define CSR_TIME            0xc01
diff --git a/target/riscv/csr.c b/target/riscv/csr.c
index e0d4586760..1f40a14a9b 100644
--- a/target/riscv/csr.c
+++ b/target/riscv/csr.c
@@ -176,6 +176,174 @@ static int write_fcsr(CPURISCVState *env, int csrno, target_ulong val)
     return 0;
 }
 
+/* ****************************************************************************************
+    User, Non-Standard Variable Precision in Time CSRs 
+ * ****************************************************************************************/
+extern uint8_t vpt_status;
+extern uint8_t vpt_frac_bits_f;
+extern uint8_t vpt_frac_bits_d;
+extern uint8_t vpt_exec_mode;
+/* VPT capabilities in QEMU */
+extern uint8_t enable_binary_test_vector;
+extern uint8_t enable_instrumentation_vpt_style;
+extern FILE    *binary_test_vector_file;
+
+// Example
+//   102d4:	800797f3          	                    csrrw	a5,0x800,a5
+//      CSR_ADDRESS = bin(0x800)   RS1  FUNCT3    RD     SYSTEM
+//                0b100000000000  01111  001    01111  11_100_11
+//      EMPY ONE
+//                0b100000000000  01111  001    01111  11_100_11
+
+// 0x000797f3 | 0x0800 << 20
+#define OPCODE_VIERGE (0x000797f3)
+
+typedef struct __attribute__((__packed__, scalar_storage_order("big-endian"))) {
+    uint32_t opp; // Opcode of the whole instruction
+    uint64_t updated_vpt_status; // One-hot encoded signal where, the value = 1 << precision_f
+    uint64_t updated_vpt_frac_bits_f; // One-hot encoded signal where, the value = 1 << precision_f
+    uint64_t updated_vpt_frac_bits_d; // One-hot encoded signal where, the value = 1 << precision_d
+    uint64_t updated_vpt_exec_mode;   // One-hot encoded signal where, the value = vpt_exec_mode
+    uint8_t  padding;          // (37 - 4 - 8*3)-byte Padding to arrive to 37 Bytes allignement.
+} vpt_csr_update_t ;
+
+#define TV_STRUCT_SIZE      (sizeof(vpt_csr_update_t))
+
+// This macro performs an update to all the CSRs in the FPU.
+#define LOG_BINARY_TEST_VECTOR_UPDATE_VPT_REGS(csr_address) if(  enable_binary_test_vector && \
+                                                                (enable_instrumentation_vpt_style ? vpt_exec_mode : 0x01)){ \
+                                                                vpt_csr_update_t tv_instance = {0}; \
+                                                                tv_instance.opp = (uint32_t)OPCODE_VIERGE | ((uint32_t)csr_address << 20); \
+                                                                tv_instance.updated_vpt_status      = (uint64_t)(vpt_status); \
+                                                                tv_instance.updated_vpt_frac_bits_f = (uint64_t)((uint64_t)0x01 << vpt_frac_bits_f); \
+                                                                tv_instance.updated_vpt_frac_bits_d = (uint64_t)((uint64_t)0x01 << vpt_frac_bits_d); \
+                                                                tv_instance.updated_vpt_exec_mode   = (uint64_t)vpt_exec_mode; \
+                                                                tv_instance.padding = 0; \
+                                                                fwrite(&tv_instance, TV_STRUCT_SIZE, 1, binary_test_vector_file); \
+                                                                fflush(binary_test_vector_file); \
+                                                            }           
+
+static int read_fvpt_status(CPURISCVState *env, int csrno, target_ulong *val)
+{
+#if !defined(CONFIG_USER_ONLY)
+    if (!env->debugger && !(env->mstatus & MSTATUS_FS)) {
+        return -1;
+    }
+#endif
+
+    // fprintf(stderr, "# FVPT_STATUS READ %d \n", vpt_status);
+    *val = vpt_status;
+    return 0;
+}
+
+static int write_fvpt_status(CPURISCVState *env, int csrno, target_ulong val)
+{
+#if !defined(CONFIG_USER_ONLY)
+    if (!env->debugger && !(env->mstatus & MSTATUS_FS)) {
+        return -1;
+    }
+    env->mstatus |= MSTATUS_FS;
+#endif
+    
+    vpt_status = val;
+    // fprintf(stderr, "# FVPT_STATUS WRITE %d \n", vpt_status);
+    LOG_BINARY_TEST_VECTOR_UPDATE_VPT_REGS(CSR_FVPT_STATUS);
+
+    return 0;
+}
+
+static int read_fvpt_prec_f(CPURISCVState *env, int csrno, target_ulong *val)
+{
+#if !defined(CONFIG_USER_ONLY)
+    if (!env->debugger && !(env->mstatus & MSTATUS_FS)) {
+        return -1;
+    }
+#endif
+
+    // fprintf(stderr, "# read_fvpt_prec_f %d \n", vpt_frac_bits_f);
+    *val = vpt_frac_bits_f;
+    return 0;
+}
+
+static int write_fvpt_prec_f(CPURISCVState *env, int csrno, target_ulong val)
+{
+#if !defined(CONFIG_USER_ONLY)
+    if (!env->debugger && !(env->mstatus & MSTATUS_FS)) {
+        return -1;
+    }
+    env->mstatus |= MSTATUS_FS;
+#endif
+    
+    vpt_frac_bits_f = val;
+    // fprintf(stderr, "# write_fvpt_prec_f %d \n", vpt_frac_bits_f);
+    LOG_BINARY_TEST_VECTOR_UPDATE_VPT_REGS(CSR_FVPT_PREC_F);
+    return 0;
+}
+
+
+static int read_fvpt_prec_d(CPURISCVState *env, int csrno, target_ulong *val)
+{
+#if !defined(CONFIG_USER_ONLY)
+    if (!env->debugger && !(env->mstatus & MSTATUS_FS)) {
+        return -1;
+    }
+#endif
+
+    // fprintf(stderr, "# read_fvpt_prec_d %d \n", vpt_frac_bits_d);
+    *val = vpt_frac_bits_d;
+    return 0;
+}
+
+static int write_fvpt_prec_d(CPURISCVState *env, int csrno, target_ulong val)
+{
+#if !defined(CONFIG_USER_ONLY)
+    if (!env->debugger && !(env->mstatus & MSTATUS_FS)) {
+        return -1;
+    }
+    env->mstatus |= MSTATUS_FS;
+#endif
+    
+    vpt_frac_bits_d = val;
+    // fprintf(stderr, "# write_fvpt_prec_d %d \n", vpt_frac_bits_d);
+    LOG_BINARY_TEST_VECTOR_UPDATE_VPT_REGS(CSR_FVPT_PREC_D);
+    return 0;
+}
+
+
+static int read_fvpt_exec_mode(CPURISCVState *env, int csrno, target_ulong *val)
+{
+#if !defined(CONFIG_USER_ONLY)
+    if (!env->debugger && !(env->mstatus & MSTATUS_FS)) {
+        return -1;
+    }
+#endif
+
+    // fprintf(stderr, "# read_fvpt_exec_mode %d \n", vpt_exec_mode);
+    *val = vpt_exec_mode;
+    return 0;
+}
+
+static int write_fvpt_exec_mode(CPURISCVState *env, int csrno, target_ulong val)
+{
+#if !defined(CONFIG_USER_ONLY)
+    if (!env->debugger && !(env->mstatus & MSTATUS_FS)) {
+        return -1;
+    }
+    env->mstatus |= MSTATUS_FS;
+#endif
+    
+    vpt_exec_mode = val;
+    // fprintf(stderr, "# write_fvpt_exec_mode %d \n", vpt_exec_mode);
+    // LOG_BINARY_TEST_VECTOR_UPDATE_VPT_REGS(CSR_FVPT_EXEC_MODE)
+    return 0;
+}
+
+
+
+/* ****************************************************************************************
+    User, Non-Standard Variable Precision in Time CSRs 
+ * ****************************************************************************************/
+
 /* User Timers and Counters */
 static int read_instret(CPURISCVState *env, int csrno, target_ulong *val)
 {
@@ -874,6 +1042,12 @@ static riscv_csr_operations csr_ops[CSR_TABLE_SIZE] = {
     [CSR_FRM] =                 { fs,   read_frm,         write_frm         },
     [CSR_FCSR] =                { fs,   read_fcsr,        write_fcsr        },
 
+    /* User, Non-Standard Variable Precision in Time CSRs */
+    [CSR_FVPT_STATUS] =         { fs,   read_fvpt_status , write_fvpt_status },
+    [CSR_FVPT_PREC_F] =         { fs,   read_fvpt_prec_f , write_fvpt_prec_f },
+    [CSR_FVPT_PREC_D] =         { fs,   read_fvpt_prec_d , write_fvpt_prec_d },
+    [CSR_FVPT_EXEC_MODE] =      { fs,   read_fvpt_exec_mode , write_fvpt_exec_mode }, 
+
     /* User Timers and Counters */
     [CSR_CYCLE] =               { ctr,  read_instret                        },
     [CSR_INSTRET] =             { ctr,  read_instret                        },
diff --git a/target/riscv/fpu_helper.c b/target/riscv/fpu_helper.c
index 0b79562a69..35ad94c65b 100644
--- a/target/riscv/fpu_helper.c
+++ b/target/riscv/fpu_helper.c
@@ -22,6 +22,180 @@
 #include "exec/exec-all.h"
 #include "exec/helper-proto.h"
 #include "fpu/softfloat.h"
+#include "fpu/axspike.h"
+
+// HAND-MADE Configurations -----------------------------------------------
+
+// Use FlexFloat or GVSoC ------------------------------
+// #define USE_FLEXFLOAT 1
+#define USE_GVSOC_DEF               1
+// -----------------------------------------------------
+
+// WHAT KIND OF DEBUGGING TO ENABLE --------------------
+#define ENABLE_TEXTUAL_TEST_VECTOR          0
+#define ENABLE_BINARY_TEST_VECTOR           1
+#define ENABLE_TEXTUAL_PERF_DEBUG           0
+// -----------------------------------------------------
+
+// HOW THE INSTRUMENTATION IS Activated/Deactivated
+#define INSTRUMENTATION_APPROX_BY_DEFAULT    0
+#define INSTRUMENTATION_VPT_STYLE            1
+// -----------------------------------------------------
+
+// -------------------------------------------------------------------------
+
+
+
+/* User, Non-Standard Variable Precision in Time CSRs */
+/* @TODO : These should be part of the CPU, if we want to operate with several precisions
+           for each core !!!
+*/
+
+#define VPT_ENABLE_BIT_MASK             0x01
+#define VPT_INSTRUMENTATION_BIT_MASK    0x01
+
+uint8_t vpt_status = 0;    /* ENABLE_BIT = 0 --> VPT disabled
+                              ENABLE_BIT = 1 --> VPT enabled
+                            */
+uint8_t vpt_frac_bits_f = 23;
+uint8_t vpt_frac_bits_d = 52;
+uint8_t vpt_exec_mode = 0;
+
+// uint8_t exp_bits_f;
+// uint8_t exp_bits_d;
+
+// Simulation parameters
+extern uint8_t exp_bits_d;
+extern uint8_t frac_bits_d;
+extern uint8_t exp_bits_f;
+extern uint8_t frac_bits_f;
+extern FILE    *binary_test_vector_file;
+
+extern uint64_t non_approx_region_start;
+extern uint64_t non_approx_region_size;
+
+
+uint8_t enable_binary_test_vector        = ENABLE_BINARY_TEST_VECTOR;
+uint8_t enable_instrumentation_vpt_style = INSTRUMENTATION_VPT_STYLE;
+
+
+// #define MARK_APPROXIMATE   ( (((uint32_t)0x00000001) << 26) )
+#define MARK_APPROXIMATE   ((uint32_t)0x00000000)
+
+#if ( ENABLE_TEXTUAL_TEST_VECTOR ) // In this case, Textual is defined, and binary is not
+#define LOG_TEXTUAL_TEST_VECTOR_3(name, nanbox_values)    fprintf(stderr, "%s %X %016lX %016lX %016lX %016lX %X\n", name , \
+                                                                                 (uint8_t)env->fp_status.float_rounding_mode, \
+                                                                                 (nanbox_values ? frs1 | (uint64_t)0xFFFFFFFF00000000 : frs1), \
+                                                                                 (nanbox_values ? frs2 | (uint64_t)0xFFFFFFFF00000000 : frs2), \
+                                                                                 (nanbox_values ? frs3 | (uint64_t)0xFFFFFFFF00000000 : frs3), \
+                                                                                 (nanbox_values ? final_result | (uint64_t)0xFFFFFFFF00000000 : final_result), \
+                                                                                 (uint8_t)env->fp_status.float_exception_flags)
+
+#define LOG_TEXTUAL_TEST_VECTOR_2(name, nanbox_values)    fprintf(stderr, "%s %X %016lX %016lX %s %016lX %X\n", name , \
+                                                                                 (uint8_t)env->fp_status.float_rounding_mode, \
+                                                                                 (nanbox_values ? frs1 | (uint64_t)0xFFFFFFFF00000000 : frs1), \
+                                                                                 (nanbox_values ? frs2 | (uint64_t)0xFFFFFFFF00000000 : frs2), \
+                                                                                 (nanbox_values ? "FFFFFFFF00000000" : "0000000000000000"), \
+                                                                                 (nanbox_values ? final_result | (uint64_t)0xFFFFFFFF00000000 : final_result), \
+                                                                                 (uint8_t)env->fp_status.float_exception_flags)
+
+#define LOG_TEXTUAL_TEST_VECTOR_1(name, nanbox_values)    fprintf(stderr, "%s %X %016lX %s %s %016lX %X\n", name , \
+                                                                                 (uint8_t)env->fp_status.float_rounding_mode, \
+                                                                                 (nanbox_values ? frs1 | (uint64_t)0xFFFFFFFF00000000 : frs1), \
+                                                                                 (nanbox_values ? "FFFFFFFF00000000" : "0000000000000000"), \
+                                                                                 (nanbox_values ? "FFFFFFFF00000000" : "0000000000000000"), \
+                                                                                 (nanbox_values ? final_result | (uint64_t)0xFFFFFFFF00000000 : final_result), \
+                                                                                 (uint8_t)env->fp_status.float_exception_flags)
+
+#define LOG_BINARY_TEST_VECTOR_3(opcode, nanbox_values)    {} 
+#define LOG_BINARY_TEST_VECTOR_2(opcode, nanbox_values)    {}
+#define LOG_BINARY_TEST_VECTOR_1(opcode, nanbox_values)    {}
+
+#elif ( ENABLE_TEXTUAL_PERF_DEBUG ) // Help debugging the executable itself
+
+#define LOG_TEXTUAL_TEST_VECTOR_3(name, nanbox_values)    fprintf(stderr, "%016lX\n", env->pc)
+#define LOG_TEXTUAL_TEST_VECTOR_2(name, nanbox_values)    fprintf(stderr, "%016lX\n", env->pc)
+#define LOG_TEXTUAL_TEST_VECTOR_1(name, nanbox_values)    fprintf(stderr, "%016lX\n", env->pc)
+
+#define LOG_BINARY_TEST_VECTOR_3(opcode, nanbox_values)    {} 
+#define LOG_BINARY_TEST_VECTOR_2(opcode, nanbox_values)    {}
+#define LOG_BINARY_TEST_VECTOR_1(opcode, nanbox_values)    {}
+
+#elif ( ENABLE_BINARY_TEST_VECTOR ) // In this case, Binary is defined, and textual is not
+
+typedef struct __attribute__((__packed__, scalar_storage_order("big-endian"))) {
+    uint32_t opp;
+    uint64_t rs1;
+    uint64_t rs2;
+    uint64_t rs3;
+    uint64_t rd;
+    uint8_t  status;
+} binary_test_vector_t ;
+
+#define TV_STRUCT_SIZE      (sizeof(binary_test_vector_t))
+
+// We don't need the RND_mode, it's incoded in the opcode
+
+#define LOG_BINARY_TEST_VECTOR_3(opcode, nanbox_values)    binary_test_vector_t tv_instance = {0}; \
+                                            tv_instance.opp = opcode; \
+                                            tv_instance.rs1 = (nanbox_values ? frs1 | (uint64_t)0xFFFFFFFF00000000 : frs1); \
+                                            tv_instance.rs2 = (nanbox_values ? frs2 | (uint64_t)0xFFFFFFFF00000000 : frs2); \
+                                            tv_instance.rs3 = (nanbox_values ? frs3 | (uint64_t)0xFFFFFFFF00000000 : frs3); \
+                                            tv_instance.rd  = (nanbox_values ? final_result | (uint64_t)0xFFFFFFFF00000000 : final_result); \
+                                            tv_instance.status = (uint8_t)env->fp_status.float_exception_flags; \
+                                            if ( !(   ( nanbox_values   && (tv_instance.rs1 == (uint64_t)0xFFFFFFFF00000000) && (tv_instance.rs2 == (uint64_t)0xFFFFFFFF00000000) && (tv_instance.rs3 == (uint64_t)0xFFFFFFFF00000000)) \
+                                                   || ((!nanbox_values) && ((tv_instance.rs1 == (uint64_t)0x0000000000000000) && (tv_instance.rs2 == (uint64_t)0x0000000000000000) && (tv_instance.rs3 == (uint64_t)0x0000000000000000))) \
+                                                  ) \
+                                               ){                                                                \
+                                                fwrite(&tv_instance, TV_STRUCT_SIZE, 1, binary_test_vector_file); \
+                                                fflush(binary_test_vector_file);                                    \
+                                            }
+
+#define LOG_BINARY_TEST_VECTOR_2(opcode, nanbox_values)    binary_test_vector_t tv_instance = {0}; \
+                                            tv_instance.opp = opcode; \
+                                            tv_instance.rs1 = (nanbox_values ? frs1 | (uint64_t)0xFFFFFFFF00000000 : frs1); \
+                                            tv_instance.rs2 = (nanbox_values ? frs2 | (uint64_t)0xFFFFFFFF00000000 : frs2); \
+                                            tv_instance.rs3 = (nanbox_values ? (uint64_t)0xFFFFFFFF00000000 : (uint64_t)0x0000000000000000); \
+                                            tv_instance.rd  = (nanbox_values ? final_result | (uint64_t)0xFFFFFFFF00000000 : final_result); \
+                                            tv_instance.status = (uint8_t)env->fp_status.float_exception_flags; \
+                                            if ( !(   ( nanbox_values   && (tv_instance.rs1 == (uint64_t)0xFFFFFFFF00000000) && (tv_instance.rs2 == (uint64_t)0xFFFFFFFF00000000) && (tv_instance.rs3 == (uint64_t)0xFFFFFFFF00000000)) \
+                                                   || ((!nanbox_values) && ((tv_instance.rs1 == (uint64_t)0x0000000000000000) && (tv_instance.rs2 == (uint64_t)0x0000000000000000) && (tv_instance.rs3 == (uint64_t)0x0000000000000000))) \
+                                                  ) \
+                                               ){                                                                \
+                                                fwrite(&tv_instance, TV_STRUCT_SIZE, 1, binary_test_vector_file); \
+                                                fflush(binary_test_vector_file);                                    \
+                                            }
+
+#define LOG_BINARY_TEST_VECTOR_1(opcode, nanbox_values)    binary_test_vector_t tv_instance = {0}; \
+                                            tv_instance.opp = opcode; \
+                                            tv_instance.rs1 = (nanbox_values ? frs1 | (uint64_t)0xFFFFFFFF00000000 : frs1); \
+                                            tv_instance.rs2 = (nanbox_values ? (uint64_t)0xFFFFFFFF00000000 : (uint64_t)0x0000000000000000); \
+                                            tv_instance.rs3 = (nanbox_values ? (uint64_t)0xFFFFFFFF00000000 : (uint64_t)0x0000000000000000); \
+                                            tv_instance.rd  = (nanbox_values ? final_result | (uint64_t)0xFFFFFFFF00000000 : final_result); \
+                                            tv_instance.status = (uint8_t)env->fp_status.float_exception_flags; \
+                                            if ( !(   ( nanbox_values   && (tv_instance.rs1 == (uint64_t)0xFFFFFFFF00000000) && (tv_instance.rs2 == (uint64_t)0xFFFFFFFF00000000) && (tv_instance.rs3 == (uint64_t)0xFFFFFFFF00000000)) \
+                                                   || ((!nanbox_values) && ((tv_instance.rs1 == (uint64_t)0x0000000000000000) && (tv_instance.rs2 == (uint64_t)0x0000000000000000) && (tv_instance.rs3 == (uint64_t)0x0000000000000000))) \
+                                                  ) \
+                                               ){                                                                \
+                                                fwrite(&tv_instance, TV_STRUCT_SIZE, 1, binary_test_vector_file); \
+                                                fflush(binary_test_vector_file);                                    \
+                                            }
+
+#define LOG_TEXTUAL_TEST_VECTOR_3(name, nanbox_values)    {} 
+#define LOG_TEXTUAL_TEST_VECTOR_2(name, nanbox_values)    {}
+#define LOG_TEXTUAL_TEST_VECTOR_1(name, nanbox_values)    {}
+
+#else // Do nothing in this case
+    #define LOG_BINARY_TEST_VECTOR_3(opcode, nanbox_values)    {} 
+    #define LOG_BINARY_TEST_VECTOR_2(opcode, nanbox_values)    {}
+    #define LOG_BINARY_TEST_VECTOR_1(opcode, nanbox_values)    {}
+
+    #define LOG_TEXTUAL_TEST_VECTOR_3(name, nanbox_values)    {} 
+    #define LOG_TEXTUAL_TEST_VECTOR_2(name, nanbox_values)    {}
+    #define LOG_TEXTUAL_TEST_VECTOR_1(name, nanbox_values)    {}
+#endif
+
+
 
 target_ulong riscv_cpu_get_fflags(CPURISCVState *env)
 {
@@ -81,77 +255,320 @@ void helper_set_rounding_mode(CPURISCVState *env, uint32_t rm)
 }
 
 uint64_t helper_fmadd_s(CPURISCVState *env, uint64_t frs1, uint64_t frs2,
-                        uint64_t frs3)
-{
-    return float32_muladd(frs1, frs2, frs3, 0, &env->fp_status);
+                        uint64_t frs3, uint32_t opcode)
+{
+    uint64_t final_result;
+#if defined( USE_GVSOC_DEF )
+  #if (INSTRUMENTATION_APPROX_BY_DEFAULT)
+    if(unlikely(  (non_approx_region_start != 0) && (non_approx_region_size != 0) &&
+                    ((env->pc >= non_approx_region_start) && (env->pc < non_approx_region_start + non_approx_region_size))))
+    {
+  #elif ( INSTRUMENTATION_VPT_STYLE )
+    if( (vpt_exec_mode & VPT_INSTRUMENTATION_BIT_MASK) == 0x00 ){
+  #endif
+        final_result = float32_muladd(frs1, frs2, frs3, 0, &env->fp_status);
+    } else {
+        final_result = lib_flexfloat_madd_round(frs1, frs2, frs3, env, exp_bits_f, (vpt_status & VPT_ENABLE_BIT_MASK)? vpt_frac_bits_f : frac_bits_f, (uint8_t)32);
+        LOG_BINARY_TEST_VECTOR_3(opcode | MARK_APPROXIMATE, 1);
+        LOG_TEXTUAL_TEST_VECTOR_3("FMADD_S", 1);
+    }
+#else
+    final_result = float32_muladd(frs1, frs2, frs3, 0, &env->fp_status);
+#endif
+    return final_result;
 }
 
 uint64_t helper_fmadd_d(CPURISCVState *env, uint64_t frs1, uint64_t frs2,
-                        uint64_t frs3)
-{
-    return float64_muladd(frs1, frs2, frs3, 0, &env->fp_status);
+                        uint64_t frs3, uint32_t opcode)
+{
+    uint64_t final_result;
+#if defined( USE_FLEXFLOAT )
+    float64_t frs1_in; frs1_in.v = frs1;  
+    float64_t frs2_in; frs2_in.v = frs2;
+    float64_t frs3_in; frs3_in.v = frs3;
+    float64_t frs_out;
+    frs_out = f64_madd_d_custom(frs1_in, frs2_in, frs3_in, &env->fp_status);
+    final_result = frs_out.v;
+#elif defined( USE_GVSOC_DEF )
+  #if (INSTRUMENTATION_APPROX_BY_DEFAULT)
+    if(unlikely(  (non_approx_region_start != 0) && (non_approx_region_size != 0) &&
+                    ((env->pc >= non_approx_region_start) && (env->pc < non_approx_region_start + non_approx_region_size))))
+    {
+  #elif ( INSTRUMENTATION_VPT_STYLE )
+    if( (vpt_exec_mode & VPT_INSTRUMENTATION_BIT_MASK) == 0x00 ){
+  #endif
+        // fprintf(stderr, "MADD_D Executed PRECISELY !!!\n");
+        final_result = float64_muladd(frs1, frs2, frs3, 0, &env->fp_status);
+    } else {
+        // fprintf(stderr, "MADD_D Executed APPROXIMATELY  --- @ADDR = %08lX     - prec_d = %d\n", env->pc, (vpt_status & VPT_ENABLE_BIT_MASK)? vpt_frac_bits_d : frac_bits_d);
+        final_result = lib_flexfloat_madd_round(frs1, frs2, frs3, env, exp_bits_d, (vpt_status & VPT_ENABLE_BIT_MASK)? vpt_frac_bits_d : frac_bits_d, (uint8_t)64);
+        LOG_BINARY_TEST_VECTOR_3(opcode | MARK_APPROXIMATE, 0);
+        LOG_TEXTUAL_TEST_VECTOR_3("FMADD_D", 0);
+    }
+#else
+    final_result = float64_muladd(frs1, frs2, frs3, 0, &env->fp_status);
+#endif
+    return final_result;
 }
 
 uint64_t helper_fmsub_s(CPURISCVState *env, uint64_t frs1, uint64_t frs2,
-                        uint64_t frs3)
-{
-    return float32_muladd(frs1, frs2, frs3, float_muladd_negate_c,
-                          &env->fp_status);
+                        uint64_t frs3, uint32_t opcode)
+{
+    uint64_t final_result;
+#if defined( USE_GVSOC_DEF )
+  #if (INSTRUMENTATION_APPROX_BY_DEFAULT)
+    if(unlikely(  (non_approx_region_start != 0) && (non_approx_region_size != 0) &&
+                    ((env->pc >= non_approx_region_start) && (env->pc < non_approx_region_start + non_approx_region_size))))
+    {
+  #elif ( INSTRUMENTATION_VPT_STYLE )
+    if( (vpt_exec_mode & VPT_INSTRUMENTATION_BIT_MASK) == 0x00 ){
+  #endif
+        final_result = float32_muladd(frs1, frs2, frs3, float_muladd_negate_c, &env->fp_status);
+    } else {
+        final_result = lib_flexfloat_msub_round(frs1, frs2, frs3, env, exp_bits_f, (vpt_status & VPT_ENABLE_BIT_MASK)? vpt_frac_bits_f : frac_bits_f, (uint8_t)32);
+        LOG_BINARY_TEST_VECTOR_3(opcode | MARK_APPROXIMATE, 1);
+        LOG_TEXTUAL_TEST_VECTOR_3("FMSUB_S", 1);
+    }
+#else
+    final_result = float32_muladd(frs1, frs2, frs3, float_muladd_negate_c, &env->fp_status);
+#endif
+    return final_result;
 }
 
 uint64_t helper_fmsub_d(CPURISCVState *env, uint64_t frs1, uint64_t frs2,
-                        uint64_t frs3)
-{
-    return float64_muladd(frs1, frs2, frs3, float_muladd_negate_c,
-                          &env->fp_status);
+                        uint64_t frs3, uint32_t opcode)
+{
+    uint64_t final_result;
+#if defined( USE_FLEXFLOAT )
+    float64_t frs1_in; frs1_in.v = frs1;  
+    float64_t frs2_in; frs2_in.v = frs2;
+    float64_t frs3_in; frs3_in.v = frs3; frs3_in.v = frs3_in.v ^ ((uint64_t)1 << 63);
+    float64_t frs_out;
+    frs_out = f64_madd_d_custom(frs1_in, frs2_in, frs3_in, &env->fp_status);
+    final_result = frs_out.v;
+#elif defined( USE_GVSOC_DEF )
+  #if (INSTRUMENTATION_APPROX_BY_DEFAULT)
+    if(unlikely(  (non_approx_region_start != 0) && (non_approx_region_size != 0) &&
+                    ((env->pc >= non_approx_region_start) && (env->pc < non_approx_region_start + non_approx_region_size))))
+    {
+  #elif ( INSTRUMENTATION_VPT_STYLE )
+    if( (vpt_exec_mode & VPT_INSTRUMENTATION_BIT_MASK) == 0x00 ){
+  #endif
+        final_result = float64_muladd(frs1, frs2, frs3, float_muladd_negate_c, &env->fp_status);
+    } else {
+        final_result = lib_flexfloat_msub_round(frs1, frs2, frs3, env, exp_bits_d, (vpt_status & VPT_ENABLE_BIT_MASK)? vpt_frac_bits_d : frac_bits_d, (uint8_t)64);
+        LOG_BINARY_TEST_VECTOR_3(opcode | MARK_APPROXIMATE, 0);
+        LOG_TEXTUAL_TEST_VECTOR_3("FMSUB_D", 0);
+    }
+#else
+    final_result = float64_muladd(frs1, frs2, frs3, float_muladd_negate_c, &env->fp_status);
+#endif
+    return final_result;
 }
 
 uint64_t helper_fnmsub_s(CPURISCVState *env, uint64_t frs1, uint64_t frs2,
-                         uint64_t frs3)
-{
-    return float32_muladd(frs1, frs2, frs3, float_muladd_negate_product,
-                          &env->fp_status);
+                         uint64_t frs3, uint32_t opcode)
+{
+    uint64_t final_result;
+#if defined( USE_GVSOC_DEF )
+  #if (INSTRUMENTATION_APPROX_BY_DEFAULT)
+    if(unlikely(  (non_approx_region_start != 0) && (non_approx_region_size != 0) &&
+                    ((env->pc >= non_approx_region_start) && (env->pc < non_approx_region_start + non_approx_region_size))))
+    {
+  #elif ( INSTRUMENTATION_VPT_STYLE )
+    if( (vpt_exec_mode & VPT_INSTRUMENTATION_BIT_MASK) == 0x00 ){
+  #endif
+        final_result = float32_muladd(frs1, frs2, frs3, float_muladd_negate_product, &env->fp_status);
+    } else {
+        final_result = lib_flexfloat_nmsub_round(frs1, frs2, frs3, env, exp_bits_f, (vpt_status & VPT_ENABLE_BIT_MASK)? vpt_frac_bits_f : frac_bits_f, (uint8_t)32);
+        LOG_BINARY_TEST_VECTOR_3(opcode | MARK_APPROXIMATE, 1);
+        LOG_TEXTUAL_TEST_VECTOR_3("FNMSUB_S", 1);
+    }
+#else
+    final_result = float32_muladd(frs1, frs2, frs3, float_muladd_negate_product, &env->fp_status);
+#endif
+    return final_result;
 }
 
+#define F32_SIGN ((uint32_t)1 << 31)
+#define F64_SIGN ((uint64_t)1 << 63)
+
 uint64_t helper_fnmsub_d(CPURISCVState *env, uint64_t frs1, uint64_t frs2,
-                         uint64_t frs3)
-{
-    return float64_muladd(frs1, frs2, frs3, float_muladd_negate_product,
-                          &env->fp_status);
+                         uint64_t frs3, uint32_t opcode)
+{
+    uint64_t final_result;
+#if defined( USE_FLEXFLOAT )
+    float64_t frs1_in; frs1_in.v = (uint64_t)(frs1 ^ F64_SIGN);
+    float64_t frs2_in; frs2_in.v = frs2;
+    float64_t frs3_in; frs3_in.v = frs3;
+    float64_t frs_out;
+    frs_out = f64_madd_d_custom(frs1_in, frs2_in, frs3_in, &env->fp_status);
+    final_result = frs_out.v;
+#elif defined( USE_GVSOC_DEF )
+  #if (INSTRUMENTATION_APPROX_BY_DEFAULT)
+    if(unlikely(  (non_approx_region_start != 0) && (non_approx_region_size != 0) &&
+                    ((env->pc >= non_approx_region_start) && (env->pc < non_approx_region_start + non_approx_region_size))))
+    {
+  #elif ( INSTRUMENTATION_VPT_STYLE )
+    if( (vpt_exec_mode & VPT_INSTRUMENTATION_BIT_MASK) == 0x00 ){
+  #endif
+        final_result = float64_muladd(frs1, frs2, frs3, float_muladd_negate_product, &env->fp_status);
+    } else {
+        final_result = lib_flexfloat_nmsub_round(frs1, frs2, frs3, env, exp_bits_d, (vpt_status & VPT_ENABLE_BIT_MASK)? vpt_frac_bits_d : frac_bits_d, (uint8_t)64);
+        LOG_BINARY_TEST_VECTOR_3(opcode | MARK_APPROXIMATE, 0);
+        LOG_TEXTUAL_TEST_VECTOR_3("FNMSUB_D", 0);
+    }
+#else
+    final_result = float64_muladd(frs1, frs2, frs3, float_muladd_negate_product, &env->fp_status);
+#endif
+    return final_result;
 }
 
 uint64_t helper_fnmadd_s(CPURISCVState *env, uint64_t frs1, uint64_t frs2,
-                         uint64_t frs3)
-{
-    return float32_muladd(frs1, frs2, frs3, float_muladd_negate_c |
-                          float_muladd_negate_product, &env->fp_status);
+                         uint64_t frs3, uint32_t opcode)
+{
+    uint64_t final_result;
+#if defined( USE_GVSOC_DEF )
+  #if (INSTRUMENTATION_APPROX_BY_DEFAULT)
+    if(unlikely(  (non_approx_region_start != 0) && (non_approx_region_size != 0) &&
+                    ((env->pc >= non_approx_region_start) && (env->pc < non_approx_region_start + non_approx_region_size))))
+    {
+  #elif ( INSTRUMENTATION_VPT_STYLE )
+    if( (vpt_exec_mode & VPT_INSTRUMENTATION_BIT_MASK) == 0x00 ){
+  #endif
+        final_result = float32_muladd(frs1, frs2, frs3, float_muladd_negate_c | float_muladd_negate_product, &env->fp_status);
+    } else {
+        final_result = lib_flexfloat_nmadd_round(frs1, frs2, frs3, env, exp_bits_f, (vpt_status & VPT_ENABLE_BIT_MASK)? vpt_frac_bits_f : frac_bits_f, (uint8_t)32);
+        LOG_BINARY_TEST_VECTOR_3(opcode | MARK_APPROXIMATE, 1);
+        LOG_TEXTUAL_TEST_VECTOR_3("FNMADD_S", 1);
+    }
+#else
+    final_result = float32_muladd(frs1, frs2, frs3, float_muladd_negate_c | float_muladd_negate_product, &env->fp_status);
+#endif
+    return final_result;
 }
 
 uint64_t helper_fnmadd_d(CPURISCVState *env, uint64_t frs1, uint64_t frs2,
-                         uint64_t frs3)
-{
-    return float64_muladd(frs1, frs2, frs3, float_muladd_negate_c |
-                          float_muladd_negate_product, &env->fp_status);
+                         uint64_t frs3, uint32_t opcode)
+{
+    uint64_t final_result;
+#if defined( USE_FLEXFLOAT )
+    float64_t frs1_in; frs1_in.v = frs1; frs1_in.v = frs1_in.v ^ ((uint64_t)1 << 63);
+    float64_t frs2_in; frs2_in.v = frs2;
+    float64_t frs3_in; frs3_in.v = frs3; frs3_in.v = frs3_in.v ^ ((uint64_t)1 << 63);
+    float64_t frs_out;
+    frs_out = f64_madd_d_custom(frs1_in, frs2_in, frs3_in, &env->fp_status);
+    final_result = frs_out.v;
+#elif defined( USE_GVSOC_DEF )
+  #if (INSTRUMENTATION_APPROX_BY_DEFAULT)
+    if(unlikely(  (non_approx_region_start != 0) && (non_approx_region_size != 0) &&
+                    ((env->pc >= non_approx_region_start) && (env->pc < non_approx_region_start + non_approx_region_size))))
+    {
+  #elif ( INSTRUMENTATION_VPT_STYLE )
+    if( (vpt_exec_mode & VPT_INSTRUMENTATION_BIT_MASK) == 0x00 ){
+  #endif
+        final_result = float64_muladd(frs1, frs2, frs3, float_muladd_negate_c | float_muladd_negate_product, &env->fp_status);
+    } else {
+        final_result = lib_flexfloat_nmadd_round(frs1, frs2, frs3, env, exp_bits_d, (vpt_status & VPT_ENABLE_BIT_MASK)? vpt_frac_bits_d : frac_bits_d, (uint8_t)64);
+        LOG_BINARY_TEST_VECTOR_3(opcode | MARK_APPROXIMATE, 0);
+        LOG_TEXTUAL_TEST_VECTOR_3("FNMADD_D", 0);
+    }
+#else
+    final_result = float64_muladd(frs1, frs2, frs3, float_muladd_negate_c | float_muladd_negate_product, &env->fp_status);
+#endif
+    return final_result;
 }
 
-uint64_t helper_fadd_s(CPURISCVState *env, uint64_t frs1, uint64_t frs2)
+uint64_t helper_fadd_s(CPURISCVState *env, uint64_t frs1, uint64_t frs2, uint32_t opcode)
 {
-    return float32_add(frs1, frs2, &env->fp_status);
+    uint64_t final_result;
+#if defined( USE_GVSOC_DEF )
+  #if (INSTRUMENTATION_APPROX_BY_DEFAULT)
+    if(unlikely(  (non_approx_region_start != 0) && (non_approx_region_size != 0) &&
+                    ((env->pc >= non_approx_region_start) && (env->pc < non_approx_region_start + non_approx_region_size))))
+    {
+  #elif ( INSTRUMENTATION_VPT_STYLE )
+    if( (vpt_exec_mode & VPT_INSTRUMENTATION_BIT_MASK) == 0x00 ){
+  #endif
+        final_result = float32_add(frs1, frs2, &env->fp_status);
+    } else {
+        final_result = lib_flexfloat_add_round(frs1, frs2, env, exp_bits_f, (vpt_status & VPT_ENABLE_BIT_MASK)? vpt_frac_bits_f : frac_bits_f, (uint8_t)32);
+        LOG_BINARY_TEST_VECTOR_2(opcode | MARK_APPROXIMATE, 1);
+        LOG_TEXTUAL_TEST_VECTOR_2("FADD_S", 1);
+    }
+#else
+    final_result = float32_add(frs1, frs2, &env->fp_status);
+#endif
+    return final_result;
 }
 
-uint64_t helper_fsub_s(CPURISCVState *env, uint64_t frs1, uint64_t frs2)
+uint64_t helper_fsub_s(CPURISCVState *env, uint64_t frs1, uint64_t frs2, uint32_t opcode)
 {
-    return float32_sub(frs1, frs2, &env->fp_status);
+    uint64_t final_result;
+#if defined( USE_GVSOC_DEF )
+  #if (INSTRUMENTATION_APPROX_BY_DEFAULT)
+    if(unlikely(  (non_approx_region_start != 0) && (non_approx_region_size != 0) &&
+                    ((env->pc >= non_approx_region_start) && (env->pc < non_approx_region_start + non_approx_region_size))))
+    {
+  #elif ( INSTRUMENTATION_VPT_STYLE )
+    if( (vpt_exec_mode & VPT_INSTRUMENTATION_BIT_MASK) == 0x00 ){
+  #endif
+        final_result = float32_sub(frs1, frs2, &env->fp_status);
+    } else {
+        final_result = lib_flexfloat_sub_round(frs1, frs2, env, exp_bits_f, (vpt_status & VPT_ENABLE_BIT_MASK)? vpt_frac_bits_f : frac_bits_f, (uint8_t)32);
+        LOG_BINARY_TEST_VECTOR_2(opcode | MARK_APPROXIMATE, 1);
+        LOG_TEXTUAL_TEST_VECTOR_2("FSUB_S", 1);
+    }
+#else
+    final_result = float32_sub(frs1, frs2, &env->fp_status);
+#endif
+    return final_result;
 }
 
-uint64_t helper_fmul_s(CPURISCVState *env, uint64_t frs1, uint64_t frs2)
+uint64_t helper_fmul_s(CPURISCVState *env, uint64_t frs1, uint64_t frs2, uint32_t opcode)
 {
-    return float32_mul(frs1, frs2, &env->fp_status);
+    uint64_t final_result;
+#if defined( USE_GVSOC_DEF )
+  #if (INSTRUMENTATION_APPROX_BY_DEFAULT)
+    if(unlikely(  (non_approx_region_start != 0) && (non_approx_region_size != 0) &&
+                    ((env->pc >= non_approx_region_start) && (env->pc < non_approx_region_start + non_approx_region_size))))
+    {
+  #elif ( INSTRUMENTATION_VPT_STYLE )
+    if( (vpt_exec_mode & VPT_INSTRUMENTATION_BIT_MASK) == 0x00 ){
+  #endif
+        final_result = float32_mul(frs1, frs2, &env->fp_status);
+    } else {
+        final_result = lib_flexfloat_mul_round(frs1, frs2, env, exp_bits_f, (vpt_status & VPT_ENABLE_BIT_MASK)? vpt_frac_bits_f : frac_bits_f, (uint8_t)32);
+        LOG_BINARY_TEST_VECTOR_2(opcode | MARK_APPROXIMATE, 1);
+        LOG_TEXTUAL_TEST_VECTOR_2("FMUL_S", 1);
+    }
+#else
+    final_result = float32_mul(frs1, frs2, &env->fp_status);
+#endif
+    return final_result;
 }
 
-uint64_t helper_fdiv_s(CPURISCVState *env, uint64_t frs1, uint64_t frs2)
+uint64_t helper_fdiv_s(CPURISCVState *env, uint64_t frs1, uint64_t frs2, uint32_t opcode)
 {
-    return float32_div(frs1, frs2, &env->fp_status);
+    uint64_t final_result;
+#if defined( USE_GVSOC_DEF )
+  #if (INSTRUMENTATION_APPROX_BY_DEFAULT)
+    if(unlikely(  (non_approx_region_start != 0) && (non_approx_region_size != 0) &&
+                    ((env->pc >= non_approx_region_start) && (env->pc < non_approx_region_start + non_approx_region_size))))
+    {
+  #elif ( INSTRUMENTATION_VPT_STYLE )
+    if( (vpt_exec_mode & VPT_INSTRUMENTATION_BIT_MASK) == 0x00 ){
+  #endif
+        final_result = float32_div(frs1, frs2, &env->fp_status);
+    } else {
+        final_result = lib_flexfloat_div_round(frs1, frs2, env, exp_bits_f, (vpt_status & VPT_ENABLE_BIT_MASK)? vpt_frac_bits_f : frac_bits_f, (uint8_t)32);
+        LOG_BINARY_TEST_VECTOR_2(opcode | MARK_APPROXIMATE, 1);
+        LOG_TEXTUAL_TEST_VECTOR_2("FDIV_S", 1);
+    }
+#else
+    final_result = float32_div(frs1, frs2, &env->fp_status);
+#endif
+    return final_result;
 }
 
 uint64_t helper_fmin_s(CPURISCVState *env, uint64_t frs1, uint64_t frs2)
@@ -164,9 +581,27 @@ uint64_t helper_fmax_s(CPURISCVState *env, uint64_t frs1, uint64_t frs2)
     return float32_maxnum(frs1, frs2, &env->fp_status);
 }
 
-uint64_t helper_fsqrt_s(CPURISCVState *env, uint64_t frs1)
+uint64_t helper_fsqrt_s(CPURISCVState *env, uint64_t frs1, uint32_t opcode)
 {
-    return float32_sqrt(frs1, &env->fp_status);
+    uint64_t final_result;
+#if defined( USE_GVSOC_DEF )
+  #if (INSTRUMENTATION_APPROX_BY_DEFAULT)
+    if(unlikely(  (non_approx_region_start != 0) && (non_approx_region_size != 0) &&
+                    ((env->pc >= non_approx_region_start) && (env->pc < non_approx_region_start + non_approx_region_size))))
+    {
+  #elif ( INSTRUMENTATION_VPT_STYLE )
+    if( (vpt_exec_mode & VPT_INSTRUMENTATION_BIT_MASK) == 0x00 ){
+  #endif
+        final_result = float32_sqrt(frs1, &env->fp_status);
+    } else {
+        final_result = lib_flexfloat_sqrtf_round(frs1, env, exp_bits_f, (vpt_status & VPT_ENABLE_BIT_MASK)? vpt_frac_bits_f : frac_bits_f, (uint8_t)32);
+        LOG_BINARY_TEST_VECTOR_1(opcode | MARK_APPROXIMATE, 1);
+        LOG_TEXTUAL_TEST_VECTOR_1("FSQRT_S", 1);
+    }
+#else
+    final_result = float32_sqrt(frs1, &env->fp_status);
+#endif
+    return final_result;
 }
 
 target_ulong helper_fle_s(CPURISCVState *env, uint64_t frs1, uint64_t frs2)
@@ -247,24 +682,120 @@ target_ulong helper_fclass_s(uint64_t frs1)
     }
 }
 
-uint64_t helper_fadd_d(CPURISCVState *env, uint64_t frs1, uint64_t frs2)
-{
-    return float64_add(frs1, frs2, &env->fp_status);
-}
-
-uint64_t helper_fsub_d(CPURISCVState *env, uint64_t frs1, uint64_t frs2)
-{
-    return float64_sub(frs1, frs2, &env->fp_status);
-}
-
-uint64_t helper_fmul_d(CPURISCVState *env, uint64_t frs1, uint64_t frs2)
-{
-    return float64_mul(frs1, frs2, &env->fp_status);
-}
-
-uint64_t helper_fdiv_d(CPURISCVState *env, uint64_t frs1, uint64_t frs2)
-{
-    return float64_div(frs1, frs2, &env->fp_status);
+uint64_t helper_fadd_d(CPURISCVState *env, uint64_t frs1, uint64_t frs2, uint32_t opcode)
+{
+    uint64_t final_result;
+#if defined( USE_FLEXFLOAT )
+    float64_t frs1_in; frs1_in.v = frs1;  
+    float64_t frs2_in; frs2_in.v = frs2;
+    float64_t frs_out;
+    frs_out = f64_add_d_custom(frs1_in, frs2_in, &env->fp_status);
+    final_result = frs_out.v;
+#elif defined( USE_GVSOC_DEF )
+  #if (INSTRUMENTATION_APPROX_BY_DEFAULT)
+    if(unlikely(  (non_approx_region_start != 0) && (non_approx_region_size != 0) &&
+                    ((env->pc >= non_approx_region_start) && (env->pc < non_approx_region_start + non_approx_region_size))))
+    {
+  #elif ( INSTRUMENTATION_VPT_STYLE )
+    if( (vpt_exec_mode & VPT_INSTRUMENTATION_BIT_MASK) == 0x00 ){
+  #endif
+        final_result = float64_add(frs1, frs2, &env->fp_status);
+    } else {
+        final_result = lib_flexfloat_add_round(frs1, frs2, env, exp_bits_d, (vpt_status & VPT_ENABLE_BIT_MASK)? vpt_frac_bits_d : frac_bits_d, (uint8_t)64);
+        LOG_BINARY_TEST_VECTOR_2(opcode | MARK_APPROXIMATE, 0);
+        LOG_TEXTUAL_TEST_VECTOR_2("FADD_D", 0);
+    }
+#else
+    final_result = float64_add(frs1, frs2, &env->fp_status);
+#endif
+    return final_result;
+}
+
+uint64_t helper_fsub_d(CPURISCVState *env, uint64_t frs1, uint64_t frs2, uint32_t opcode)
+{
+    uint64_t final_result;
+#if defined( USE_FLEXFLOAT )
+    float64_t frs1_in; frs1_in.v = frs1;  
+    float64_t frs2_in; frs2_in.v = frs2;
+    float64_t frs_out;
+    frs_out = f64_sub_d_custom(frs1_in, frs2_in, &env->fp_status);
+    final_result = frs_out.v;
+#elif defined( USE_GVSOC_DEF )
+  #if (INSTRUMENTATION_APPROX_BY_DEFAULT)
+    if(unlikely(  (non_approx_region_start != 0) && (non_approx_region_size != 0) &&
+                    ((env->pc >= non_approx_region_start) && (env->pc < non_approx_region_start + non_approx_region_size))))
+    {
+  #elif ( INSTRUMENTATION_VPT_STYLE )
+    if( (vpt_exec_mode & VPT_INSTRUMENTATION_BIT_MASK) == 0x00 ){
+  #endif
+        final_result = float64_sub(frs1, frs2, &env->fp_status);
+    } else {
+        final_result = lib_flexfloat_sub_round(frs1, frs2, env, exp_bits_d, (vpt_status & VPT_ENABLE_BIT_MASK)? vpt_frac_bits_d : frac_bits_d, (uint8_t)64);
+        LOG_BINARY_TEST_VECTOR_2(opcode | MARK_APPROXIMATE, 0);
+        LOG_TEXTUAL_TEST_VECTOR_2("FSUB_D", 0);
+    }
+#else
+    final_result = float64_sub(frs1, frs2, &env->fp_status);
+#endif
+    return final_result;
+}
+
+uint64_t helper_fmul_d(CPURISCVState *env, uint64_t frs1, uint64_t frs2, uint32_t opcode)
+{
+    uint64_t final_result;
+#if defined( USE_FLEXFLOAT )
+    float64_t frs1_in; frs1_in.v = frs1;  
+    float64_t frs2_in; frs2_in.v = frs2;
+    float64_t frs_out;
+    frs_out = f64_mul_d_custom(frs1_in, frs2_in, &env->fp_status);
+    final_result = frs_out.v;
+#elif defined( USE_GVSOC_DEF )
+  #if (INSTRUMENTATION_APPROX_BY_DEFAULT)
+    if(unlikely(  (non_approx_region_start != 0) && (non_approx_region_size != 0) &&
+                    ((env->pc >= non_approx_region_start) && (env->pc < non_approx_region_start + non_approx_region_size))))
+    {
+  #elif ( INSTRUMENTATION_VPT_STYLE )
+    if( (vpt_exec_mode & VPT_INSTRUMENTATION_BIT_MASK) == 0x00 ){
+  #endif
+        final_result = float64_mul(frs1, frs2, &env->fp_status);
+    } else {
+        final_result = lib_flexfloat_mul_round(frs1, frs2, env, exp_bits_d, (vpt_status & VPT_ENABLE_BIT_MASK)? vpt_frac_bits_d : frac_bits_d, (uint8_t)64);
+        LOG_BINARY_TEST_VECTOR_2(opcode | MARK_APPROXIMATE, 0);
+        LOG_TEXTUAL_TEST_VECTOR_2("FMUL_D", 0);
+    }
+#else
+    final_result = float64_mul(frs1, frs2, &env->fp_status);
+#endif
+    return final_result;
+}
+
+uint64_t helper_fdiv_d(CPURISCVState *env, uint64_t frs1, uint64_t frs2, uint32_t opcode)
+{
+    uint64_t final_result;
+#if defined( USE_FLEXFLOAT )
+    float64_t frs1_in; frs1_in.v = frs1;  
+    float64_t frs2_in; frs2_in.v = frs2;
+    float64_t frs_out;
+    frs_out = f64_div_d_custom(frs1_in, frs2_in, &env->fp_status);
+    final_result = frs_out.v;
+#elif defined( USE_GVSOC_DEF )
+  #if (INSTRUMENTATION_APPROX_BY_DEFAULT)
+    if(unlikely(  (non_approx_region_start != 0) && (non_approx_region_size != 0) &&
+                    ((env->pc >= non_approx_region_start) && (env->pc < non_approx_region_start + non_approx_region_size))))
+    {
+  #elif ( INSTRUMENTATION_VPT_STYLE )
+    if( (vpt_exec_mode & VPT_INSTRUMENTATION_BIT_MASK) == 0x00 ){
+  #endif
+        final_result = float64_div(frs1, frs2, &env->fp_status);
+    } else {
+        final_result = lib_flexfloat_div_round(frs1, frs2, env, exp_bits_d, (vpt_status & VPT_ENABLE_BIT_MASK)? vpt_frac_bits_d : frac_bits_d, (uint8_t)64);
+        LOG_BINARY_TEST_VECTOR_2(opcode | MARK_APPROXIMATE, 0);
+        LOG_TEXTUAL_TEST_VECTOR_2("FDIV_D", 0);
+    }
+#else
+    final_result = float64_div(frs1, frs2, &env->fp_status);
+#endif
+    return final_result;
 }
 
 uint64_t helper_fmin_d(CPURISCVState *env, uint64_t frs1, uint64_t frs2)
@@ -287,9 +818,32 @@ uint64_t helper_fcvt_d_s(CPURISCVState *env, uint64_t rs1)
     return float32_to_float64(rs1, &env->fp_status);
 }
 
-uint64_t helper_fsqrt_d(CPURISCVState *env, uint64_t frs1)
-{
-    return float64_sqrt(frs1, &env->fp_status);
+uint64_t helper_fsqrt_d(CPURISCVState *env, uint64_t frs1, uint32_t opcode)
+{
+    uint64_t final_result;
+#if defined( USE_FLEXFLOAT )
+    float64_t frs1_in; frs1_in.v = frs1;  
+    float64_t frs_out;
+    frs_out = f64_sqrt_d_custom(frs1_in, &env->fp_status);
+    final_result = frs_out.v;
+#elif defined( USE_GVSOC_DEF )
+  #if (INSTRUMENTATION_APPROX_BY_DEFAULT)
+    if(unlikely(  (non_approx_region_start != 0) && (non_approx_region_size != 0) &&
+                    ((env->pc >= non_approx_region_start) && (env->pc < non_approx_region_start + non_approx_region_size))))
+    {
+  #elif ( INSTRUMENTATION_VPT_STYLE )
+    if( (vpt_exec_mode & VPT_INSTRUMENTATION_BIT_MASK) == 0x00 ){
+  #endif
+        final_result = float64_sqrt(frs1, &env->fp_status);
+    } else {
+        final_result = lib_flexfloat_sqrt_round(frs1, env, exp_bits_d, (vpt_status & VPT_ENABLE_BIT_MASK)? vpt_frac_bits_d : frac_bits_d, (uint8_t)64);
+        LOG_BINARY_TEST_VECTOR_1(opcode | MARK_APPROXIMATE, 0);
+        LOG_TEXTUAL_TEST_VECTOR_1("FSQRT_D", 0);
+    }
+#else
+    final_result = float64_sqrt(frs1, &env->fp_status);
+#endif
+    return final_result;
 }
 
 target_ulong helper_fle_d(CPURISCVState *env, uint64_t frs1, uint64_t frs2)
diff --git a/target/riscv/helper.h b/target/riscv/helper.h
index debb22a480..beafa97afe 100644
--- a/target/riscv/helper.h
+++ b/target/riscv/helper.h
@@ -1,3 +1,9 @@
+/* AxQEMU-related Defines, for Binary Vector Exportation */
+#define AXQEMU_TEST_VECTOR_PREFIX       TCGv_i32 opp = tcg_temp_new_i32(); \
+                                        tcg_gen_movi_i32(opp, ctx->opcode)
+
+#define AXQEMU_TEST_VECTOR_SUFFIX       tcg_temp_free_i32(opp)  
+
 /* Exceptions */
 DEF_HELPER_2(raise_exception, noreturn, env, i32)
 
@@ -5,23 +11,23 @@ DEF_HELPER_2(raise_exception, noreturn, env, i32)
 DEF_HELPER_FLAGS_2(set_rounding_mode, TCG_CALL_NO_WG, void, env, i32)
 
 /* Floating Point - fused */
-DEF_HELPER_FLAGS_4(fmadd_s, TCG_CALL_NO_RWG, i64, env, i64, i64, i64)
-DEF_HELPER_FLAGS_4(fmadd_d, TCG_CALL_NO_RWG, i64, env, i64, i64, i64)
-DEF_HELPER_FLAGS_4(fmsub_s, TCG_CALL_NO_RWG, i64, env, i64, i64, i64)
-DEF_HELPER_FLAGS_4(fmsub_d, TCG_CALL_NO_RWG, i64, env, i64, i64, i64)
-DEF_HELPER_FLAGS_4(fnmsub_s, TCG_CALL_NO_RWG, i64, env, i64, i64, i64)
-DEF_HELPER_FLAGS_4(fnmsub_d, TCG_CALL_NO_RWG, i64, env, i64, i64, i64)
-DEF_HELPER_FLAGS_4(fnmadd_s, TCG_CALL_NO_RWG, i64, env, i64, i64, i64)
-DEF_HELPER_FLAGS_4(fnmadd_d, TCG_CALL_NO_RWG, i64, env, i64, i64, i64)
+DEF_HELPER_FLAGS_5(fmadd_s, TCG_CALL_NO_RWG, i64, env, i64, i64, i64, i32)
+DEF_HELPER_FLAGS_5(fmadd_d, TCG_CALL_NO_RWG, i64, env, i64, i64, i64, i32)
+DEF_HELPER_FLAGS_5(fmsub_s, TCG_CALL_NO_RWG, i64, env, i64, i64, i64, i32)
+DEF_HELPER_FLAGS_5(fmsub_d, TCG_CALL_NO_RWG, i64, env, i64, i64, i64, i32)
+DEF_HELPER_FLAGS_5(fnmsub_s, TCG_CALL_NO_RWG, i64, env, i64, i64, i64, i32)
+DEF_HELPER_FLAGS_5(fnmsub_d, TCG_CALL_NO_RWG, i64, env, i64, i64, i64, i32)
+DEF_HELPER_FLAGS_5(fnmadd_s, TCG_CALL_NO_RWG, i64, env, i64, i64, i64, i32)
+DEF_HELPER_FLAGS_5(fnmadd_d, TCG_CALL_NO_RWG, i64, env, i64, i64, i64, i32)
 
 /* Floating Point - Single Precision */
-DEF_HELPER_FLAGS_3(fadd_s, TCG_CALL_NO_RWG, i64, env, i64, i64)
-DEF_HELPER_FLAGS_3(fsub_s, TCG_CALL_NO_RWG, i64, env, i64, i64)
-DEF_HELPER_FLAGS_3(fmul_s, TCG_CALL_NO_RWG, i64, env, i64, i64)
-DEF_HELPER_FLAGS_3(fdiv_s, TCG_CALL_NO_RWG, i64, env, i64, i64)
+DEF_HELPER_FLAGS_4(fadd_s, TCG_CALL_NO_RWG, i64, env, i64, i64, i32)
+DEF_HELPER_FLAGS_4(fsub_s, TCG_CALL_NO_RWG, i64, env, i64, i64, i32)
+DEF_HELPER_FLAGS_4(fmul_s, TCG_CALL_NO_RWG, i64, env, i64, i64, i32)
+DEF_HELPER_FLAGS_4(fdiv_s, TCG_CALL_NO_RWG, i64, env, i64, i64, i32)
 DEF_HELPER_FLAGS_3(fmin_s, TCG_CALL_NO_RWG, i64, env, i64, i64)
 DEF_HELPER_FLAGS_3(fmax_s, TCG_CALL_NO_RWG, i64, env, i64, i64)
-DEF_HELPER_FLAGS_2(fsqrt_s, TCG_CALL_NO_RWG, i64, env, i64)
+DEF_HELPER_FLAGS_3(fsqrt_s, TCG_CALL_NO_RWG, i64, env, i64, i32)
 DEF_HELPER_FLAGS_3(fle_s, TCG_CALL_NO_RWG, tl, env, i64, i64)
 DEF_HELPER_FLAGS_3(flt_s, TCG_CALL_NO_RWG, tl, env, i64, i64)
 DEF_HELPER_FLAGS_3(feq_s, TCG_CALL_NO_RWG, tl, env, i64, i64)
@@ -40,15 +46,15 @@ DEF_HELPER_FLAGS_2(fcvt_s_lu, TCG_CALL_NO_RWG, i64, env, tl)
 DEF_HELPER_FLAGS_1(fclass_s, TCG_CALL_NO_RWG_SE, tl, i64)
 
 /* Floating Point - Double Precision */
-DEF_HELPER_FLAGS_3(fadd_d, TCG_CALL_NO_RWG, i64, env, i64, i64)
-DEF_HELPER_FLAGS_3(fsub_d, TCG_CALL_NO_RWG, i64, env, i64, i64)
-DEF_HELPER_FLAGS_3(fmul_d, TCG_CALL_NO_RWG, i64, env, i64, i64)
-DEF_HELPER_FLAGS_3(fdiv_d, TCG_CALL_NO_RWG, i64, env, i64, i64)
+DEF_HELPER_FLAGS_4(fadd_d, TCG_CALL_NO_RWG, i64, env, i64, i64, i32)
+DEF_HELPER_FLAGS_4(fsub_d, TCG_CALL_NO_RWG, i64, env, i64, i64, i32)
+DEF_HELPER_FLAGS_4(fmul_d, TCG_CALL_NO_RWG, i64, env, i64, i64, i32)
+DEF_HELPER_FLAGS_4(fdiv_d, TCG_CALL_NO_RWG, i64, env, i64, i64, i32)
 DEF_HELPER_FLAGS_3(fmin_d, TCG_CALL_NO_RWG, i64, env, i64, i64)
 DEF_HELPER_FLAGS_3(fmax_d, TCG_CALL_NO_RWG, i64, env, i64, i64)
 DEF_HELPER_FLAGS_2(fcvt_s_d, TCG_CALL_NO_RWG, i64, env, i64)
 DEF_HELPER_FLAGS_2(fcvt_d_s, TCG_CALL_NO_RWG, i64, env, i64)
-DEF_HELPER_FLAGS_2(fsqrt_d, TCG_CALL_NO_RWG, i64, env, i64)
+DEF_HELPER_FLAGS_3(fsqrt_d, TCG_CALL_NO_RWG, i64, env, i64, i32)
 DEF_HELPER_FLAGS_3(fle_d, TCG_CALL_NO_RWG, tl, env, i64, i64)
 DEF_HELPER_FLAGS_3(flt_d, TCG_CALL_NO_RWG, tl, env, i64, i64)
 DEF_HELPER_FLAGS_3(feq_d, TCG_CALL_NO_RWG, tl, env, i64, i64)
diff --git a/target/riscv/insn_trans/trans_rvd.inc.c b/target/riscv/insn_trans/trans_rvd.inc.c
index 393fa0248c..cc13d64e5b 100644
--- a/target/riscv/insn_trans/trans_rvd.inc.c
+++ b/target/riscv/insn_trans/trans_rvd.inc.c
@@ -18,6 +18,7 @@
  * this program.  If not, see <http://www.gnu.org/licenses/>.
  */
 
+
 static bool trans_fld(DisasContext *ctx, arg_fld *a)
 {
     TCGv t0 = tcg_temp_new();
@@ -50,109 +51,140 @@ static bool trans_fsd(DisasContext *ctx, arg_fsd *a)
 
 static bool trans_fmadd_d(DisasContext *ctx, arg_fmadd_d *a)
 {
+    AXQEMU_TEST_VECTOR_PREFIX;
+
     REQUIRE_FPU;
     REQUIRE_EXT(ctx, RVD);
     gen_set_rm(ctx, a->rm);
     gen_helper_fmadd_d(cpu_fpr[a->rd], cpu_env, cpu_fpr[a->rs1],
-                       cpu_fpr[a->rs2], cpu_fpr[a->rs3]);
+                       cpu_fpr[a->rs2], cpu_fpr[a->rs3], opp);
     mark_fs_dirty(ctx);
+
+    AXQEMU_TEST_VECTOR_SUFFIX;
     return true;
 }
 
 static bool trans_fmsub_d(DisasContext *ctx, arg_fmsub_d *a)
 {
+    AXQEMU_TEST_VECTOR_PREFIX;
+
     REQUIRE_FPU;
     REQUIRE_EXT(ctx, RVD);
     gen_set_rm(ctx, a->rm);
     gen_helper_fmsub_d(cpu_fpr[a->rd], cpu_env, cpu_fpr[a->rs1],
-                       cpu_fpr[a->rs2], cpu_fpr[a->rs3]);
+                       cpu_fpr[a->rs2], cpu_fpr[a->rs3], opp);
     mark_fs_dirty(ctx);
+
+    AXQEMU_TEST_VECTOR_SUFFIX;
     return true;
 }
 
 static bool trans_fnmsub_d(DisasContext *ctx, arg_fnmsub_d *a)
 {
+    AXQEMU_TEST_VECTOR_PREFIX;
+    
     REQUIRE_FPU;
     REQUIRE_EXT(ctx, RVD);
     gen_set_rm(ctx, a->rm);
     gen_helper_fnmsub_d(cpu_fpr[a->rd], cpu_env, cpu_fpr[a->rs1],
-                        cpu_fpr[a->rs2], cpu_fpr[a->rs3]);
+                        cpu_fpr[a->rs2], cpu_fpr[a->rs3], opp);
     mark_fs_dirty(ctx);
+
+    AXQEMU_TEST_VECTOR_SUFFIX;
     return true;
 }
 
 static bool trans_fnmadd_d(DisasContext *ctx, arg_fnmadd_d *a)
 {
+    AXQEMU_TEST_VECTOR_PREFIX;
+    
     REQUIRE_FPU;
     REQUIRE_EXT(ctx, RVD);
     gen_set_rm(ctx, a->rm);
     gen_helper_fnmadd_d(cpu_fpr[a->rd], cpu_env, cpu_fpr[a->rs1],
-                        cpu_fpr[a->rs2], cpu_fpr[a->rs3]);
+                        cpu_fpr[a->rs2], cpu_fpr[a->rs3], opp);
     mark_fs_dirty(ctx);
+
+    AXQEMU_TEST_VECTOR_SUFFIX;
     return true;
 }
 
 static bool trans_fadd_d(DisasContext *ctx, arg_fadd_d *a)
 {
+    AXQEMU_TEST_VECTOR_PREFIX;
+    
     REQUIRE_FPU;
     REQUIRE_EXT(ctx, RVD);
 
     gen_set_rm(ctx, a->rm);
     gen_helper_fadd_d(cpu_fpr[a->rd], cpu_env,
-                      cpu_fpr[a->rs1], cpu_fpr[a->rs2]);
-
+                      cpu_fpr[a->rs1], cpu_fpr[a->rs2], opp);
     mark_fs_dirty(ctx);
+
+    AXQEMU_TEST_VECTOR_SUFFIX;
     return true;
 }
 
 static bool trans_fsub_d(DisasContext *ctx, arg_fsub_d *a)
 {
+    AXQEMU_TEST_VECTOR_PREFIX;
+    
     REQUIRE_FPU;
     REQUIRE_EXT(ctx, RVD);
 
     gen_set_rm(ctx, a->rm);
     gen_helper_fsub_d(cpu_fpr[a->rd], cpu_env,
-                      cpu_fpr[a->rs1], cpu_fpr[a->rs2]);
-
+                      cpu_fpr[a->rs1], cpu_fpr[a->rs2], opp);
     mark_fs_dirty(ctx);
+
+    AXQEMU_TEST_VECTOR_SUFFIX;
     return true;
 }
 
 static bool trans_fmul_d(DisasContext *ctx, arg_fmul_d *a)
 {
+    AXQEMU_TEST_VECTOR_PREFIX;
+    
     REQUIRE_FPU;
     REQUIRE_EXT(ctx, RVD);
 
     gen_set_rm(ctx, a->rm);
     gen_helper_fmul_d(cpu_fpr[a->rd], cpu_env,
-                      cpu_fpr[a->rs1], cpu_fpr[a->rs2]);
-
+                      cpu_fpr[a->rs1], cpu_fpr[a->rs2], opp);
     mark_fs_dirty(ctx);
+    
+    AXQEMU_TEST_VECTOR_SUFFIX;
     return true;
 }
 
 static bool trans_fdiv_d(DisasContext *ctx, arg_fdiv_d *a)
 {
+    AXQEMU_TEST_VECTOR_PREFIX;
+    
     REQUIRE_FPU;
     REQUIRE_EXT(ctx, RVD);
 
     gen_set_rm(ctx, a->rm);
     gen_helper_fdiv_d(cpu_fpr[a->rd], cpu_env,
-                      cpu_fpr[a->rs1], cpu_fpr[a->rs2]);
-
+                      cpu_fpr[a->rs1], cpu_fpr[a->rs2], opp);
     mark_fs_dirty(ctx);
+
+    AXQEMU_TEST_VECTOR_SUFFIX;
     return true;
 }
 
 static bool trans_fsqrt_d(DisasContext *ctx, arg_fsqrt_d *a)
 {
+    AXQEMU_TEST_VECTOR_PREFIX;
+    
     REQUIRE_FPU;
     REQUIRE_EXT(ctx, RVD);
 
     gen_set_rm(ctx, a->rm);
-    gen_helper_fsqrt_d(cpu_fpr[a->rd], cpu_env, cpu_fpr[a->rs1]);
-
+    gen_helper_fsqrt_d(cpu_fpr[a->rd], cpu_env, cpu_fpr[a->rs1], opp);
     mark_fs_dirty(ctx);
+
+    AXQEMU_TEST_VECTOR_SUFFIX;
     return true;
 }
 
diff --git a/target/riscv/insn_trans/trans_rvf.inc.c b/target/riscv/insn_trans/trans_rvf.inc.c
index 172dbfa919..c7f1d904f3 100644
--- a/target/riscv/insn_trans/trans_rvf.inc.c
+++ b/target/riscv/insn_trans/trans_rvf.inc.c
@@ -58,104 +58,140 @@ static bool trans_fsw(DisasContext *ctx, arg_fsw *a)
 
 static bool trans_fmadd_s(DisasContext *ctx, arg_fmadd_s *a)
 {
+    AXQEMU_TEST_VECTOR_PREFIX;
+
     REQUIRE_FPU;
     REQUIRE_EXT(ctx, RVF);
     gen_set_rm(ctx, a->rm);
     gen_helper_fmadd_s(cpu_fpr[a->rd], cpu_env, cpu_fpr[a->rs1],
-                       cpu_fpr[a->rs2], cpu_fpr[a->rs3]);
+                       cpu_fpr[a->rs2], cpu_fpr[a->rs3], opp);
     mark_fs_dirty(ctx);
+
+    AXQEMU_TEST_VECTOR_SUFFIX;
     return true;
 }
 
 static bool trans_fmsub_s(DisasContext *ctx, arg_fmsub_s *a)
 {
+    AXQEMU_TEST_VECTOR_PREFIX;
+    
     REQUIRE_FPU;
     REQUIRE_EXT(ctx, RVF);
     gen_set_rm(ctx, a->rm);
     gen_helper_fmsub_s(cpu_fpr[a->rd], cpu_env, cpu_fpr[a->rs1],
-                       cpu_fpr[a->rs2], cpu_fpr[a->rs3]);
+                       cpu_fpr[a->rs2], cpu_fpr[a->rs3], opp);
     mark_fs_dirty(ctx);
+
+    AXQEMU_TEST_VECTOR_SUFFIX;
     return true;
 }
 
 static bool trans_fnmsub_s(DisasContext *ctx, arg_fnmsub_s *a)
 {
+    AXQEMU_TEST_VECTOR_PREFIX;
+    
     REQUIRE_FPU;
     REQUIRE_EXT(ctx, RVF);
     gen_set_rm(ctx, a->rm);
     gen_helper_fnmsub_s(cpu_fpr[a->rd], cpu_env, cpu_fpr[a->rs1],
-                        cpu_fpr[a->rs2], cpu_fpr[a->rs3]);
+                        cpu_fpr[a->rs2], cpu_fpr[a->rs3], opp);
     mark_fs_dirty(ctx);
+
+    AXQEMU_TEST_VECTOR_SUFFIX;
     return true;
 }
 
 static bool trans_fnmadd_s(DisasContext *ctx, arg_fnmadd_s *a)
 {
+    AXQEMU_TEST_VECTOR_PREFIX;
+    
     REQUIRE_FPU;
     REQUIRE_EXT(ctx, RVF);
     gen_set_rm(ctx, a->rm);
     gen_helper_fnmadd_s(cpu_fpr[a->rd], cpu_env, cpu_fpr[a->rs1],
-                        cpu_fpr[a->rs2], cpu_fpr[a->rs3]);
+                        cpu_fpr[a->rs2], cpu_fpr[a->rs3], opp);
     mark_fs_dirty(ctx);
+
+    AXQEMU_TEST_VECTOR_SUFFIX;
     return true;
 }
 
 static bool trans_fadd_s(DisasContext *ctx, arg_fadd_s *a)
 {
+    AXQEMU_TEST_VECTOR_PREFIX;
+    
     REQUIRE_FPU;
     REQUIRE_EXT(ctx, RVF);
 
     gen_set_rm(ctx, a->rm);
     gen_helper_fadd_s(cpu_fpr[a->rd], cpu_env,
-                      cpu_fpr[a->rs1], cpu_fpr[a->rs2]);
+                      cpu_fpr[a->rs1], cpu_fpr[a->rs2], opp);
     mark_fs_dirty(ctx);
+    
+    AXQEMU_TEST_VECTOR_SUFFIX;
     return true;
 }
 
 static bool trans_fsub_s(DisasContext *ctx, arg_fsub_s *a)
 {
+    AXQEMU_TEST_VECTOR_PREFIX;
+    
     REQUIRE_FPU;
     REQUIRE_EXT(ctx, RVF);
 
     gen_set_rm(ctx, a->rm);
     gen_helper_fsub_s(cpu_fpr[a->rd], cpu_env,
-                      cpu_fpr[a->rs1], cpu_fpr[a->rs2]);
+                      cpu_fpr[a->rs1], cpu_fpr[a->rs2], opp);
     mark_fs_dirty(ctx);
+    
+    AXQEMU_TEST_VECTOR_SUFFIX;
     return true;
 }
 
 static bool trans_fmul_s(DisasContext *ctx, arg_fmul_s *a)
 {
+    AXQEMU_TEST_VECTOR_PREFIX;
+    
     REQUIRE_FPU;
     REQUIRE_EXT(ctx, RVF);
 
     gen_set_rm(ctx, a->rm);
     gen_helper_fmul_s(cpu_fpr[a->rd], cpu_env,
-                      cpu_fpr[a->rs1], cpu_fpr[a->rs2]);
+                      cpu_fpr[a->rs1], cpu_fpr[a->rs2], opp);
     mark_fs_dirty(ctx);
+    
+    AXQEMU_TEST_VECTOR_SUFFIX;
     return true;
 }
 
 static bool trans_fdiv_s(DisasContext *ctx, arg_fdiv_s *a)
 {
+    AXQEMU_TEST_VECTOR_PREFIX;
+    
     REQUIRE_FPU;
     REQUIRE_EXT(ctx, RVF);
 
     gen_set_rm(ctx, a->rm);
     gen_helper_fdiv_s(cpu_fpr[a->rd], cpu_env,
-                      cpu_fpr[a->rs1], cpu_fpr[a->rs2]);
+                      cpu_fpr[a->rs1], cpu_fpr[a->rs2], opp);
     mark_fs_dirty(ctx);
+    
+    AXQEMU_TEST_VECTOR_SUFFIX;
     return true;
 }
 
 static bool trans_fsqrt_s(DisasContext *ctx, arg_fsqrt_s *a)
 {
+    AXQEMU_TEST_VECTOR_PREFIX;
+    
     REQUIRE_FPU;
     REQUIRE_EXT(ctx, RVF);
 
     gen_set_rm(ctx, a->rm);
-    gen_helper_fsqrt_s(cpu_fpr[a->rd], cpu_env, cpu_fpr[a->rs1]);
+    gen_helper_fsqrt_s(cpu_fpr[a->rd], cpu_env, cpu_fpr[a->rs1], opp);
     mark_fs_dirty(ctx);
+    
+    AXQEMU_TEST_VECTOR_SUFFIX;
     return true;
 }
 
diff --git a/target/riscv/translate.c b/target/riscv/translate.c
index adeddb85f6..3211d3f432 100644
--- a/target/riscv/translate.c
+++ b/target/riscv/translate.c
@@ -811,7 +811,7 @@ static void riscv_tr_tb_stop(DisasContextBase *dcbase, CPUState *cpu)
 static void riscv_tr_disas_log(const DisasContextBase *dcbase, CPUState *cpu)
 {
     qemu_log("IN: %s\n", lookup_symbol(dcbase->pc_first));
-    log_target_disas(cpu, dcbase->pc_first, dcbase->tb->size);
+    log_target_disas(cpu, dcbase->pc_first, dcbase->tb->size);  
 }
 
 static const TranslatorOps riscv_tr_ops = {
diff --git a/vl.c b/vl.c
index 630f5c5e9c..0787024cdf 100644
--- a/vl.c
+++ b/vl.c
@@ -133,6 +133,16 @@ int main(int argc, char **argv)
 
 #define MAX_VIRTIO_CONSOLES 1
 
+/*  @AXSPIKE AxSpike-Related information 
+ */
+// ax_mode_t ax_mode;
+#include "fpu/flexfloat.h"
+extern uint8_t exp_bits_d;
+extern uint8_t frac_bits_d;
+extern uint8_t exp_bits_f;
+extern uint8_t frac_bits_f;
+// extern flexfloat_desc_t vpfpu_config_64;
+
 static const char *data_dir[16];
 static int data_dir_idx;
 const char *bios_name = NULL;
@@ -2339,6 +2349,35 @@ static void add_device_config(int type, const char *cmdline)
     QTAILQ_INSERT_TAIL(&device_configs, conf, next);
 }
 
+// @AXSPIKE @TODO
+// #if defined(TARGET_RISCV)
+static void handle_arg_expbits_d(const char *arg)
+{
+    exp_bits_d = (uint8_t)atoi(arg);
+}
+
+static void handle_arg_fracbits_d(const char *arg)
+{
+    frac_bits_d = (uint8_t)atoi(arg);
+}
+
+static void handle_arg_expbits_f(const char *arg)
+{
+    exp_bits_f = (uint8_t)atoi(arg);
+}
+
+static void handle_arg_fracbits_f(const char *arg)
+{
+    frac_bits_f = (uint8_t)atoi(arg);
+}
+
+// static void handle_arg_axmode(const char *arg)
+// {
+//     axmode = (uint8_t)atoi(arg);
+// }
+
+// #endif
+
 static int foreach_device_config(int type, int (*func)(const char *cmdline))
 {
     struct device_config *conf;
@@ -3184,11 +3223,7 @@ int main(int argc, char **argv, char **envp)
             case QEMU_OPTION_h:
                 help(0);
                 break;
-            case QEMU_OPTION_version:
-                version();
-                exit(0);
-                break;
-            case QEMU_OPTION_m:
+            case QEMU_OPTION_version: version(); fflush(stdout); if (argc < 3) { exit(0); } break; case QEMU_OPTION_m:
                 opts = qemu_opts_parse_noisily(qemu_find_opts("memory"),
                                                optarg, true);
                 if (!opts) {
@@ -3226,6 +3261,20 @@ int main(int argc, char **argv, char **envp)
             case QEMU_OPTION_gdb:
                 add_device_config(DEV_GDB, optarg);
                 break;
+// #if defined(TARGET_RISCV)
+            case QEMU_OPTION_expbitsd:
+                handle_arg_expbits_d(optarg);
+                break;
+            case QEMU_OPTION_fracbitsd:
+                handle_arg_fracbits_d(optarg);
+                break;
+            case QEMU_OPTION_expbitsf:
+                handle_arg_expbits_f(optarg);
+                break;
+            case QEMU_OPTION_fracbitsf:
+                handle_arg_fracbits_f(optarg);
+                break;
+// #endif
             case QEMU_OPTION_L:
                 if (is_help_option(optarg)) {
                     list_data_dirs = true;
@@ -3851,6 +3900,23 @@ int main(int argc, char **argv, char **envp)
             }
         }
     }
+
+    // @AXSPIKE_TEST Here all the args are supposed to be parsed.
+    // printf("@AXSPIKE_TEST   Expbits = %d    Fracbits = %d", exp_bits_d, frac_bits_d);
+    // exit(-1);
+    // @AXSPIKE : ensure that exp and frac bit-widths aren't zeroes.
+    if ((!exp_bits_d) || (!frac_bits_d) || (!exp_bits_f) || (!frac_bits_f))
+    {
+        fprintf(stderr, "Exp_Bits_d = %d         Frac_Bits_d = %d\n", exp_bits_d, frac_bits_d);
+        fprintf(stderr, "Exp_Bits_f = %d         Frac_Bits_f = %d\n", exp_bits_f, frac_bits_f);
+        fprintf(stderr, "neither of the FPU parameters should be equal to zero.\n");
+        exit(-1);
+    }
+    else {
+        fprintf(stderr, "AXQEMU[ softmmu mode ]: Exp_Bits_d = %d         Frac_Bits_d = %d\n", exp_bits_d, frac_bits_d);
+        fprintf(stderr, "                        Exp_Bits_f = %d         Frac_Bits_f = %d\n", exp_bits_f, frac_bits_f);
+    }
+
     /*
      * Clear error location left behind by the loop.
      * Best done right after the loop.  Do not insert code here!
